<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>协同过滤算法</title>
      <link href="2021/08/05/suan-fa-bi-ji/xie-tong-guo-lu/"/>
      <url>2021/08/05/suan-fa-bi-ji/xie-tong-guo-lu/</url>
      
        <content type="html"><![CDATA[<p>推荐系统的核心任务是准确捕获用户偏好和项目属性，以正确预测用户是否会喜欢给定项目。 协同过滤 (CF) 方法利用过去的用户-项目交互数据来驱动推荐。</p><p>最近的研究主要集中在隐式反馈设置上，因为隐式交互通常可以以更大的数量和低成本收集。 CF 的一个突出方向是潜在模型，它学习用户和项目的紧凑表示，然后使用这些表示之间的距离来推断偏好。 最流行的潜在 CF 方法是矩阵分解，其中用户 - 项目交互矩阵由两个低秩矩阵的乘积近似，这些矩阵作为用户和项目表示。 另一个方向是将交互矩阵视为二部图，边表示用户和项目节点之间的交互。 然后可以应用基于图的方法沿边传递消息并学习总结每个节点的邻域信息的表示。</p><p>面向图的方法的一个关键优势是能够对用户和项目之间的高阶关系（邻居的邻居）进行建模。 最近将图卷积网络 (GCN) 应用于 CF 的工作证明了探索用户-项目建模的高阶关系的重要性。 这些方法通过在图卷积设置下应用多级邻域聚合来生成最终表示，在许多公共基准测试中取得了最先进的性能。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>近期踩坑</title>
      <link href="2021/08/05/tuo-keng-ji-lu/jin-qi-cai-keng/"/>
      <url>2021/08/05/tuo-keng-ji-lu/jin-qi-cai-keng/</url>
      
        <content type="html"><![CDATA[<h1>1. PyCharm远程</h1><pre><code class="language-shell">sudo ldconfig /usr/local/cuda/lib64</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Inductive Matrix Completion Based on Graph Neural Networks</title>
      <link href="2021/08/05/lun-wen-bi-ji/recommender-system/2020-iclr-inductive-matrix-completion-based-on-graph-neural-networks/"/>
      <url>2021/08/05/lun-wen-bi-ji/recommender-system/2020-iclr-inductive-matrix-completion-based-on-graph-neural-networks/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2020 ICLR <a href="https://arxiv.org/abs/1904.12058">Inductive Matrix Completion Based on Graph Neural Networks</a></p><p>Implement code <a href="https://github.com/muhanzhang/IGMC">IGMC</a></p></blockquote><p>本文提出了一种基于归纳图的矩阵完成（IGMC）模型，它不使用任何边信息，通过将（评级）矩阵分解为行（用户）和列（物品）的低维潜在嵌入的乘积。 IGMC 训练一个图神经网络 (GNN)，它完全基于从评分矩阵生成的（用户、项目）对周围的 1 跳子图，并将这些子图映射到它们相应的评分。</p><p>该工作表明：</p><ol><li>可以在不使用辅助信息的情况下训练归纳矩阵完成模型，同时获得与最先进的转导方法相似或更好的性能；</li><li>围绕（用户，项目）对的局部图模式是该用户对项目的评价的有效预测器；</li><li>建模推荐系统可能不需要长期依赖。</li></ol><h1>1 .IGMC</h1><p><img src="http://note.lizhihao999.cn/notes/20210805004425.png" alt="图1"></p><p>如图1，IGMC围绕每个评分（深绿色）提取局部封闭子图，并训练 GNN 将子图映射到评分。 每个封闭子图由与目标评分相关联的用户和物品以及它的$h$​-跳邻居（这里 h=1）诱导。 从子图中，GNN 可以学习对评级预测有用的混合图模式（例如平均评级、路径等）。 最后使用经过训练的 GNN 来补全缺失的条目。</p><table><thead><tr><th style="text-align:center">符号</th><th style="text-align:center">表示</th><th style="text-align:center">解释</th></tr></thead><tbody><tr><td style="text-align:center">$\mathrm{R}$</td><td style="text-align:center">评分矩阵</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$G$</td><td style="text-align:center">无向二部图</td><td style="text-align:center">从给定的评分矩阵$\mathrm{R}$构造，节点为用户$u$或者物品$v$</td></tr><tr><td style="text-align:center">$u$</td><td style="text-align:center">用户</td><td style="text-align:center">$G$中的节点，$\mathrm{R}$一行</td></tr><tr><td style="text-align:center">$v$</td><td style="text-align:center">物品</td><td style="text-align:center">$G$​中的节点，$\mathrm{R}$​中的一列</td></tr><tr><td style="text-align:center">$(u,v)$</td><td style="text-align:center">图中的边</td><td style="text-align:center">只有用户和物品之间有边，用户与用户、物品与物品之间没有边</td></tr><tr><td style="text-align:center">$r=\mathrm{R}_{u,v}$</td><td style="text-align:center">边$(u,v)$的值</td><td style="text-align:center">表示用户$u$给物品$v$的评分</td></tr><tr><td style="text-align:center">$R$</td><td style="text-align:center">所有可能分数的集合</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$N_{r}(u)$</td><td style="text-align:center">用户$u$的所有邻居集合</td><td style="text-align:center">通过类型为$r$的边连接到$u$</td></tr></tbody></table><h2 id="1-1-ENCLOSING-SUBGRAPH-EXTRACTION-提取封闭子图">1.1 ENCLOSING SUBGRAPH EXTRACTION 提取封闭子图</h2><p>首先，对于每个观察到的评分$\mathrm{R}_{u,v}$，从$G$中提取一个围绕$(u,v)$的$h$-跳的封闭子图。算法 1 描述了用于提取$h$​-跳封闭子图的 BFS过程。</p><p><img src="http://note.lizhihao999.cn/notes/20210804235022.png" alt="算法1"></p><p>这些封闭的子图将提供给 GNN 并对其评分进行回归。 然后，对于每个测试$(u,v)$对，再次从$G$中提取其$h$-跳封闭子图，并使用经过训练的GNN模型来预测其评分。需要注意的是，在为$(u,v)$提取训练封闭子图后，应该删除边$(u,v)$，因为它是要预测的目标。</p><h2 id="1-2-NODE-LABELING-节点标注">1.2 NODE LABELING 节点标注</h2><p>IGMC 的第二部分是节点标注。 在将封闭子图提供给 GNN 之前，首先对其应用节点标注，为子图中的每个节点提供一个整数标签。目的是使用不同的标签来标记节点在子图中的不同角色。 理想情况下的节点标签应该能够：</p><ol><li>区分目标用户和目标评分所在的目标物品；</li><li>区分用户类型节点和物品类型节点。</li></ol><p>否则，GNN 无法区分哪个用户和物品来预测评分，并且可能会丢失节点类型信息。</p><p>为了满足这些条件，提出了如下的节点标签方法：</p><ol><li>分别为目标用户和目标物品赋予标签 0 和 1；</li><li>根据算法 1 中子图中包含的其他节点的标签来确定其他节点的标签：<ol><li>如果第 i 跳包含一个用户类型节点，给予标签$2i$；</li><li>如果第 i 跳包含一个项目类型节点，给予标签$2i+1$。</li></ol></li></ol><p>这样的节点标记可以充分区分：</p><ol><li>目标节点与“上下文”节点；</li><li>用户与物品（用户总是有偶数标签）；</li><li>与目标评分不同距离的节点。</li></ol><p>当送到 GNN 时，这些节点标签的 one-hot 编码将被视为子图的初始节点特征$x^{0}$。节点标签完全在每个封闭子图中确定，因此独立于全局二部图。 给定一个新的封闭子图，即使它的所有节点都来自不同的二部图，也可以预测它的评分，因为 IGMC 纯粹依赖于局部封闭子图中的图模式，而没有利用任何特定于二部图的全局信息。</p><h2 id="1-3-GRAPH-NEURAL-NETWORK-ARCHITECTURE-图神经网络架构">1.3 GRAPH NEURAL NETWORK ARCHITECTURE 图神经网络架构</h2><p>IGMC 的第三部分是训练图神经网络 (GNN) 模型，从封闭的子图中预测评分。 IGMC 将图级 GNN 应用于$(u,v)$周围的封闭子图，并将子图映射到评分。因此，GNN 中有两个组件：</p><ol><li>消息传递层，为子图中的每个节点提取特征向量；</li><li>一个池化层，用于从节点特征中总结子图表示。</li></ol><p>为了学习不同边类型引入的丰富图模式，我们采用关系图卷积算子（R-GCN）作为 GNN 的消息传递层，其形式如下：</p><p><img src="http://note.lizhihao999.cn/notes/20210805001248.png" alt=""></p><table><thead><tr><th style="text-align:center">符号</th><th style="text-align:center">表示</th></tr></thead><tbody><tr><td style="text-align:center">$x_{i}^{l}$</td><td style="text-align:center">节点$i$在第$l$层的特征向量</td></tr><tr><td style="text-align:center">$W_{0}^{l},\lbrace W_{r}^{l}</td><td style="text-align:center">r\in R\rbrace$</td></tr></tbody></table><p>由于连接到$i$的具有不同边类型$r$的邻居$j$由不同的参数矩阵$W_{r}^{l}$处理，所以能够在边类型内部学习大量丰富的图模式，例如目标用户对物品的平均评分，目标物品接收到的平均评分，以及两个目标节点通过哪些路径连接等。</p><p>堆叠$L$个消息传递层，并在两层之间用$tanh$激活。节点$i$来自不同层的特征向量被连接起来作为其最终表示$h_{i}$：</p><p><img src="http://note.lizhihao999.cn/notes/20210805002129.png" alt=""></p><p>接下来，将节点表示池化为图级特征向量。 在这项工作中，使用一个不同的池化层连接目标用户和目标物品的最终表示来作为图形表示：</p><p><img src="http://note.lizhihao999.cn/notes/20210805002427.png" alt=""></p><p>其中，$h_{u},h_{v}$分别代表目标用户和目标物品的最终表示。这样选择是由于这两个目标节点与其他上下文节点相比具有额外的重要性。</p><p>在获得最终的图形表示后，使用 MLP 来输出预测的评分：</p><p><img src="http://note.lizhihao999.cn/notes/20210805002715.png" alt=""></p><p>其中，$W,w$是$MLP$的参数，将图形表示$g$映射到标量评分$\hat{r}$；$\sigma$是激活函数（$ReLU$）。</p><h2 id="1-4-MODEL-TRAINING-模型训练">1.4 MODEL TRAINING 模型训练</h2><h3 id="Loss-Function">Loss Function</h3><p>最小化预测和真实评分之间的均方误差 (MSE)：</p><p><img src="http://note.lizhihao999.cn/notes/20210805003112.png" alt=""></p><p>其中，$R_{u,v},\hat{R}_{u,v}$分别表示$(u,v)$的真实评分和预测评分；$\Omega$是一个 0/1 掩码矩阵，表示评分矩阵$\mathrm{R}$的观察项。</p><h3 id="Adjacent-Rating-Regularization">Adjacent Rating Regularization</h3><p>GNN 中使用的 R-GCN 层针对不同的评级类型具有不同的参数$W_{r}$​​。 这里的一个缺点是它没有考虑评级的大小。 例如，MovieLens 的评分 4 和评分 5 都表示用户喜欢这部电影，而评分 1 表示用户不喜欢这部电影。理想情况下，希望模型意识到 4 比 1 更类似于 5 的事实。 然而在 RGCN 中，评级 1、4 和 5 仅被视为三种独立的边缘类型——评级的大小和顺序信息完全丢失。</p><p>为了解决这个问题，提出了一种相邻评级正则化 (ARR) 技术，该技术鼓励彼此相邻的评级具有相似的参数矩阵。假设$R$中的评分表现出一个排序$r_{1},r_{2},…,r_{|R|}$​，这表明用户对物品的偏好越来越高。因此，ARR正则化为：</p><p><img src="http://note.lizhihao999.cn/notes/20210805003845.png" alt=""></p><p>其中，$||\cdot||_{F}$​表示矩阵的 Frobenius 范数。</p><p>上述正则化器抑制了相邻评分的参数矩阵差异过大，这不仅考虑了评分的顺序，而且还通过从相邻评分中转移知识来帮助优化那些不频繁的评分。</p><p>最终的损失函数由下式给出：</p><p><img src="http://note.lizhihao999.cn/notes/20210805004301.png" alt=""></p><p>$\lambda$在MSE损失和ARR正则化之间进行平衡。</p><h1>2. 实验</h1><p>对所有数据集使用 1 跳封闭子图，并发现它们足够好。 虽然使用 2 跳或更多跳可以稍微提高性能，但需要更长的训练时间。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> Recommender System </tag>
            
            <tag> ICRL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lorentzian Graph Convolutional Networks</title>
      <link href="2021/08/05/lun-wen-bi-ji/gnn/2021-www-lorentzian-graph-convolutional-networks/"/>
      <url>2021/08/05/lun-wen-bi-ji/gnn/2021-www-lorentzian-graph-convolutional-networks/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2021 WWW <a href="https://arxiv.org/abs/2104.07477">Lorentzian Graph Convolutional Networks</a></p></blockquote><p>大多数 GCN 学习欧几里德几何中的节点表示，但在嵌入具有无标度或分层结构的图的情况下，这可能会产生很大的失真。最近，提出了一些 GCN 来处理非欧几何中的这个问题，例如双曲几何。 尽管双曲 GCN 取得了不错的性能，但现有的双曲图操作（指数、对数映射）实际上不能严格遵循双曲几何，这可能会限制双曲几何的能力，从而损害双曲 GCN 的性能。</p><p>为解决以上问题，本文提出一种名为洛伦兹图卷积网络 (LGCN) 的新型双曲 GCN，它在双曲空间的双曲面模型上设计了统一的图操作框架，严格保证学习到的节点特征遵循双曲几何。具体来说，使用洛伦兹重建双曲 GCN 的图操作，例如特征转换和非线性激活。 此外，基于洛伦兹距离的质心设计了一种优雅的邻域聚合方法。 本文提出的图操作在不同类型的双曲几何中是等效的，这也从根本上表明了它们的正确性。</p><h1>1. Preliminaries</h1><h2 id="1-1-Hyperbolic-geometry">1.1 Hyperbolic geometry</h2><p>双曲几何是具有恒定负曲率的非欧几何。 双曲面（洛伦兹）模型作为一种典型的能很好地描述双曲几何的等效模型，被广泛使用。洛伦兹标量积定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730113554.png" alt=""></p><p>$n$维双曲面流形的定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730113639.png" alt=""></p><p>洛伦兹标量积满足：</p><p><img src="http://note.lizhihao999.cn/notes/20210730113720.png" alt=""></p><p>$x$处的切线空间定义为一个$n$维向量空间，近似于$x$周围的$H^{n,\beta}$：</p><p><img src="http://note.lizhihao999.cn/notes/20210730113830.png" alt=""></p><p>方程（4）具有 Lorentzian 标量积的约束。 切线空间的黎曼度量张量定义为：$g_{x}^{\beta}(v,w):=&lt;v,w&gt;_{L}$。</p><p>双曲空间和切线空间之间的映射可以通过指数映射和对数映射来完成：</p><p><img src="http://note.lizhihao999.cn/notes/20210730114353.png" alt=""></p><p>其中两点间的内在距离函数定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730114455.png" alt=""></p><h2 id="1-2-Hyperbolic-graph-convolutional-networks">1.2 Hyperbolic graph convolutional networks</h2><p>本文使用HGCN，将欧几里得图卷积扩展到双曲面模型，作为典型例子来说明双曲GCN的基本框架。HGCN 的消息传递规则包含特征变换：</p><p><img src="http://note.lizhihao999.cn/notes/20210730115019.png" alt=""></p><p>和邻域聚合：</p><p><img src="http://note.lizhihao999.cn/notes/20210730115111.png" alt=""></p><p>正如方程（8）所示，特征通过对数映射从双曲空间转换到切线空间。然而，因为$&lt;M\log_{0}^{\beta}(h_{i}^{k,\beta}),0&gt;<em>{L}\ne0,0=(\sqrt{\beta},0,…,0)\in H^{k,\beta}$，所以无法满足方程（4）中切线空间$&lt;v,x&gt;</em>{L}=0$的基本约束。因此，通过指数映射将节点特征投影回双曲面流形后，节点特征将超出双曲空间，这不严格满足双曲几何。</p><p>回到欧几里得空间，其中进行的节点特征聚合有如下数学意义：</p><blockquote><p><strong>Remark 3.1</strong></p><p>给定一个节点，邻域聚合本质上是其局部邻域特征的加权算术平均值。 此外，聚合的特征是几何中邻域特征的质心。</p></blockquote><p>因此，方程（9）中的邻域聚合也应与双曲空间中的欧几里得聚合具有相同的含义。 但是HGCN 中的方程(9) 仅在切线空间而不是双曲空间中满足这些含义，这可能会导致特征失真。 综上所述，上述问题表明现有的双曲线图操作根本不遵循数学，这可能会导致潜在的不可信问题。</p><h1>2. LGCN</h1><p>为了解决现有双曲 GCN 的问题，本文提出了 LGCN，它设计了图操作来保证双曲空间中的数学意义。 具体来说，LGCN 首先将输入节点特征映射到双曲线空间，然后通过精心设计的洛伦兹矩阵向量乘法进行特征变换。 此外，提出了基于质心的洛伦兹聚合来聚合特征，聚合权重通过自注意力机制学习。 最后，遵循洛伦兹逐点非线性激活以获得输出节点特征。LGCN中曲率$-\frac{1}{\beta}$同样为可学习的参数。</p><h2 id="2-1-Mapping-feature-with-different-curvature">2.1 Mapping feature with different curvature</h2><p>LGCN 的输入节点特征可以存在于欧几里得空间或双曲空间中。如果原始特征存在于欧几里得空间中，则需要将它们映射到双曲空间中，此时需要在$h^{k,E}$的第一个坐标处添加一个“0”元素以满足方程（4）约束$&lt;(0,h^{k,E}),0&gt;_{L}=0$，然后再映射到双曲空间：</p><p><img src="http://note.lizhihao999.cn/notes/20210730140018.png" alt=""></p><p>如果输入特征$h^{k,\beta’}$​已经在双曲空间中（例如，前一个 LGCN 层的输出），但它的曲率$-\frac{1}{\beta’}$​可能与现有流形的曲率并不同，需要将其转化为具有特定曲率$-\frac{1}{\beta}$​的双曲面模型：</p><p><img src="http://note.lizhihao999.cn/notes/20210730141043.png" alt=""></p><h2 id="2-2-Lorentzian-feature-transformation">2.2 Lorentzian feature transformation</h2><p>双曲空间并不是向量空间，这意味着欧几里得空间中的运算不能应用于双曲空间。 为了确保变换后的特征满足双曲几何，在双曲面模型中定义一些规范变换至关重要，因此定义：</p><p><strong>Definition 2.1 (Lorentzian version).</strong></p><p>不同维度之间的映射：</p><p><img src="http://note.lizhihao999.cn/notes/20210730141810.png" alt=""></p><p>洛伦兹版本利用对数和指数映射来投影双曲空间和切线空间之间的特征。由于切线空间是向量空间并且与$R^{n}$同构，因此欧几里得变换可以应用于切线空间。与之前方法不同的是，洛伦兹版本只利用了切线空间中最后$n$个坐标$(v_{1},…,v_{n})$上的欧几里德变换，并且将第一个坐标$v_{0}$置为“0”以满足方程（ 4）中的约束。因此，此操作可以确保变换后的特征严格遵循双曲几何。</p><p>为了在双曲面模型上应用线性变换，遵循洛伦兹版本，可以导出洛伦兹矩阵向量乘法：</p><p><strong>Definition 2.2 (Lorentzian matrix-vector multiplication).</strong></p><p><img src="http://note.lizhihao999.cn/notes/20210730142714.png" alt=""></p><p>洛伦兹矩阵向量乘法与双曲面模型上的其他矩阵向量乘法之间的一个主要区别是矩阵 M 的大小。假设需要将$ 𝑛 $维特征转换为$m$维特征，矩阵 M 的大小应该是$m\times n$，这是洛伦兹矩阵-向量乘法所满足的。然而，对于其他方法，如方程（8），矩阵M的大小为$(m+1)\times (n+1)$，导致不能满足切线空间的约束$&lt;M\log_{0}^{\beta}(h_{i}^{k,\beta}),0&gt;_{L}\ne0$，所以转换后的特征将超出双曲空间。 此外，洛伦兹矩阵向量乘法具有以下性质：</p><blockquote><p><strong>Theorem 2.1.</strong></p><p>给定双曲空间中的一个点，双曲面模型表示为$x^{n,\beta}\in H^{n,\beta}$，庞加莱球模型表示为$x^{n,\alpha}\in D^{n,\alpha}$。令$M$为一个$m\times n$的矩阵，双曲面模型中的洛伦兹矩阵向量乘法$M\otimes^{\beta}x^{n,\beta}$与庞加莱球模型中的莫比乌斯矩阵向量乘法$M\otimes^{\alpha}x^{n,\alpha}$​是等价的。</p></blockquote><p>这个属性优雅地桥接了双曲面模型和庞加莱球模型之间矩阵向量乘法的关系。 可以使用洛伦兹矩阵向量乘法对双曲面模型进行特征变换为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730165319.png" alt=""></p><h2 id="2-3-Lorentzian-neighborhood-aggregation">2.3 Lorentzian neighborhood aggregation</h2><p>与 Remark3.1一样，在欧几里得空间中，邻域聚合是计算其邻域特征的权重算术平均值或质心（也称为质心），如图1（a）所示。</p><p><img src="http://note.lizhihao999.cn/notes/20210730171404.png" alt="图1（a）"></p><p>LGCN目标是聚合双曲线空间中的邻域特征并遵循这些含义。 Fréchet 均值提供了一种可行的方法来计算黎曼流形中的质心。 此外，算术平均值也可以解释为一种 Fréchet 平均值。 因此，Fréchet mean 符合邻域聚合的含义。 Fréchet 均值的主要思想是最小化一组点的（平方）距离的期望。 然而，Fréchet mean 没有一个关于双曲空间中的内在距离$d_{H}^{\beta}$​​的封闭形式的解，它必须通过梯度下降进行低效计算。 因此，本文提出了一种优雅的基于平方洛伦兹距离的质心的邻域聚合方法，可以很好地平衡数学意义和效率：</p><blockquote><p><strong>Theorem 2.2 (Lorentzian aggregation via centroid of squared Lorentzian distance).</strong></p><p>对于一个节点特征$h_{i}^{d,\beta}\in H^{d,\beta}$，其一组邻域节点$N(i)$，对应聚合权重为$w_{ij}$，邻域聚合包含在节点的质心$c^{d,\beta}$​中，这将问题最小化：</p><p><img src="http://note.lizhihao999.cn/notes/20210730170051.png" alt=""></p><p>这个问题有封闭形式的解决方案：</p><p><img src="http://note.lizhihao999.cn/notes/20210730170942.png" alt=""></p></blockquote><p>其中用到的平方洛伦兹距离公式定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730171042.png" alt=""></p><p>图 1(b) 说明了通过质心的洛伦兹聚合。 类似于 Fréchet/Karcher 均值，由洛伦兹聚合计算的节点特征是平方洛伦兹距离的期望值的最小值。 此外，洛伦兹邻域聚合中的聚合特征是几何中双曲面模型中的质心 。</p><p><img src="http://note.lizhihao999.cn/notes/20210730171445.png" alt="图1（b）"></p><p>另一方面，一些双曲 GCNs聚合了切线空间中的邻域（如图 1© 所示），只能在切线空间中视为质心或算术平均值，而不是在双曲线空间。 因此，通过平方洛伦兹距离的质心进行洛伦兹聚合是一种很有前途的方法，与其他双曲 GCN 相比，它满足更优雅的数学含义。</p><p><img src="http://note.lizhihao999.cn/notes/20210730171735.png" alt="图1（c）"></p><p>如方程（16）所示，有一个聚合权重$w_{ij}$表示邻域对于中心节点的重要性。 这里提出了一种自注意力机制来学习聚合权重$w_{ij}$​。对于两个节点特征，注意力系数$\mu_{ij}$表示节点$i\to j$的重要程度，计算公式为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730172504.png" alt=""></p><p>其中𝐴𝑇𝑇(·)表示计算注意力系数的函数，而𝑑×𝑑矩阵$M_{att}$是将节点特征转化为基于注意力的特征。考虑一个较大的注意系数$\mu_{ij}$表示$i,j$节点的高度相似性, 基于洛伦兹距离的平方定义𝐴𝑇𝑇 (·)：</p><p><img src="http://note.lizhihao999.cn/notes/20210730225121.png" alt=""></p><p>对于所有的邻居𝑁 (𝑖) 节点的𝑖 (包括其本身），使用softmax函数对其进行规范化，以计算聚合权重：</p><p><img src="http://note.lizhihao999.cn/notes/20210731003129.png" alt=""></p><h2 id="2-4-Lorentzian-pointwise-non-linear-activation">2.4 Lorentzian pointwise non-linear activation</h2><p>非线性激活是GCN不可缺少的一部分。与特征转换类似，双曲面模型上现有的非线性激活也会使特征脱离双曲面模型。这里根据洛伦兹版本推导出洛伦兹点态非线性激活：</p><p><img src="http://note.lizhihao999.cn/notes/20210731003435.png" alt=""></p><p>洛伦兹点态非线性激活不仅保证了变换后的特征仍然存在于双曲空间中，而且具有如下性质。</p><blockquote><p>Theorem 4.3.</p><p>双曲面模型中的洛伦兹点态非线性$\sigma^{\otimes^{\beta}}(x^{n,\beta})$等价于庞加莱球模型中的莫比乌斯点态非线性$\sigma^{\otimes^{\alpha}}(x^{n,\alpha})$，𝜎(·) 表示某些特定的非线性激活，例如Relu、LEKLYRELU。</p></blockquote><p>这一特性也在两个模型中架起了点态非线性的桥梁。洛伦兹点态非线性激活后，LGCN层的输出为：</p><p><img src="http://note.lizhihao999.cn/notes/20210731004006.png" alt=""></p><p>这可用于下游任务，如链路预测和节点分类。</p><h1>3. 总结</h1><p>这篇文章提出的LGCN模型的思路和之前的HGCN思路大致相同，都是采用双曲-切线-双曲的模式，本文的不同在于改进了双曲-切线之间的映射函数，使其不违背双曲约束，能够保留双曲特征。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> Hyperbolic </tag>
            
            <tag> WWW </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lorentzian Distance Learning for Hyperbolic Representations</title>
      <link href="2021/08/05/lun-wen-bi-ji/knowledge-representation/2019-icml-lorentzian-distance-learning-for-hyperbolic-representations/"/>
      <url>2021/08/05/lun-wen-bi-ji/knowledge-representation/2019-icml-lorentzian-distance-learning-for-hyperbolic-representations/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2019 ICML Oral <a href="http://proceedings.mlr.press/v97/law19a.html">Lorentzian Distance Learning for Hyperbolic Representations</a></p></blockquote><p>本文的主要贡献是对洛伦兹距离的研究。本文解释了为什么平方洛伦兹距离是比庞加莱度量更好的选择。 一个分析论点依赖于黎曼质心的雅可比场 (Lee, 2006) 特性（也称为“Karcher 均值”，尽管 Karcher (2014) 强烈反对使用该术语）。 另一个有趣的特性是，与平方洛伦兹距离相关的质心可以写成封闭形式，这种质心的欧几里得范数随着双曲空间曲率的减小而减小。此属性适合表示层次结构，其中父节点与其后代的距离最小，并且欧几里得范数小于其子节点。</p><p>文章表明用一组点解释平方洛伦兹距离等效于用它们的质心解释距离，同时还研究了质心与一些超参数的相关性，特别是流形的曲率，它会影响其欧几里得范数，该范数用作层次结构中的深度代理。</p><h1>1. Hyperbolic Background</h1><h2 id="1-1-Poincare-Ball">1.1 Poincare Ball</h2><p>庞加莱球$P^{d}$被定义为欧几里得范数小于 1 的$d$维向量集：$P^{d}=\lbrace x\in R^{d}:||x||&lt;1\rbrace$.</p><h2 id="1-2-Hyperboloid-Model">1.2 Hyperboloid Model</h2><p>双曲面模型$H^{d,\beta}\in R^{d+1}$也叫洛伦兹模型，定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210729141119.png" alt=""></p><p>平方洛伦兹范数源自洛伦兹内积：</p><p><img src="http://note.lizhihao999.cn/notes/20210729143403.png" alt=""></p><p>当$\beta=1$时，双曲面模型称为单位双曲面，可以表示为$H^{d}$，也是文献中考虑的主要双曲面模型。</p><h2 id="1-3-Optimizing-the-Poincare-Distance-Metric">1.3 Optimizing the Poincare Distance Metric</h2><p>大多数双曲线表示的方法都考虑庞加莱距离度量：</p><p><img src="http://note.lizhihao999.cn/notes/20210729144815.png" alt=""></p><p>使用方程（3）中的距离公式直接优化问题的庞加莱模型在数值上不稳定，主要有两个原因：</p><ol><li>分母取决于示例的范数，因此当 c 和 d 的任何一个范数接近 1 时对其进行优化会导致数值不稳定；</li><li>元素必须在每次迭代时以固定的最大范数重新投影到庞加莱球上；</li></ol><p>此外，方程（3）当 $c = d$​ 时不可微。</p><p>为了获得更好的求解器数值稳定性，Nickel &amp; Kiela (2018) 建议在单位双曲面模型中使用$d_{P}$的等效公式。他们利用存在可逆映射$h:H^{d,\beta}\to P^{d}$的事实：</p><p><img src="http://note.lizhihao999.cn/notes/20210729150034.png" alt=""></p><p>当$\beta=1,a\in H^{d},b\in H^{d}$时，有如下的等价式：</p><p><img src="http://note.lizhihao999.cn/notes/20210729150339.png" alt=""></p><p>Nickel &amp; Kiela (2018) 表明，（5）中的优化方程在数值上更稳定。</p><h2 id="1-5-Duality-between-Spherical-and-Hyperbolic-geometries-二元性">1.5 Duality between Spherical and Hyperbolic geometries 二元性</h2><p>从方程（5）可以看出，保持Poincare距离的顺序等同于保持Lorentzian内积的逆序，因为$\mathrm{cosh}^{-1}$函数在其域$[1,+\infin]$上单调递增。当$p,q$由于这些几何之间的二元性而位于单位超球面$S^{d}$时，庞加莱度量与洛伦兹内积的关系其实类似于测地距离$\cos^{-1}(&lt;p,q&gt;)$与余弦$&lt;p,q&gt;$​的关系。</p><p>双曲面$H^{d,\beta}$可以看作是一个虚半径为$i\sqrt{\beta}$​的半超球面。 与将 Hilbert 空间中的内积视为相似性度量的核方法相同，本文中考虑洛伦兹内积及其诱导距离。</p><h1>2. Lorentzian Distance Learning</h1><p>当表示为双曲时，给出了洛伦兹质心的公式，并表明其欧几里得范数（用作层次结构中的深度代理）取决于曲率$-\frac{1}{\beta}$​。</p><h2 id="2-1-Lorentzian-Distance-and-Mappings">2.1 Lorentzian Distance and Mappings</h2><p>首先给出平方洛伦兹公式的定义：</p><p><img src="http://note.lizhihao999.cn/notes/20210729164424.png" alt=""></p><p>除了三角不等式，它满足距离度量的所有公理。</p><h3 id="Mapping-映射">Mapping 映射</h3><p>由于我们的方法不一定考虑 β = 1，我们考虑可逆映射$g_{\beta}:F^{d}\to H^{d,\beta}$，称为$H^{d,\beta}$的本地参数化：</p><p><img src="http://note.lizhihao999.cn/notes/20210729164911.png" alt=""></p><p>通过平方洛伦兹公式可以比较两个样例$f_{1},f_{2}\in F^{d}$：</p><p><img src="http://note.lizhihao999.cn/notes/20210729165043.png" alt=""></p><h3 id="Preserved-order-of-Euclidean-norms-欧几里得范数的保留顺序">Preserved order of Euclidean norms 欧几里得范数的保留顺序</h3><p>示例的欧几里得范数的顺序沿三个空间保留，可由以下定理给出：</p><p><img src="http://note.lizhihao999.cn/notes/20210729165450.png" alt=""></p><p>总之，示例的欧几里得范数可以在任何空间中等价地进行比较，如果想研究质心的欧几里得范数，这特别有用。</p><h2 id="2-2-Centroid-Properties-质心属性">2.2 Centroid Properties 质心属性</h2><p>质心是 (Frechet, 1948) 中提出的统计概念，用于估计一组点的某些统计离散度（例如方差），它是一组点的（平方）距离期望的最小值，并在 (Grove &amp; Karcher, 1973) 中扩展到黎曼流形。研究平方洛伦兹距离的质心，在理想情况下，希望节点表示的质心是（接近）其最低共同祖先的表示。</p><p><img src="http://note.lizhihao999.cn/notes/20210729170121.png" alt=""></p><p>公式 (11) 中的质心公式概括了 （Galperin, 1993; Ratcliffe, 2006）中给出的质心公式，适用于任何数量的点和任何恒定曲率 -1/β 的值。</p><p><img src="http://note.lizhihao999.cn/notes/20210729170318.png" alt=""></p><p>质心 μ 的公式可用于执行硬聚类，其中假设对聚类中的数据采用统一度量。可以看到，一个示例的质心就是示例本身。</p><p><img src="http://note.lizhihao999.cn/notes/20210729180838.png" alt=""></p><p>图 1 说明了一组 10 个不同点的质心的二维庞加莱球表示。不同 β &gt; 0 值的庞加莱距离和平方洛伦兹距离。可以看到质心庞加莱度量没有更小的范数。 另一方面，洛伦兹质心的欧几里得范数确实随着 β 的减小而减小，然后可以通过选择 β &gt; 0 的较低值来强制使其变小。</p><p><img src="http://note.lizhihao999.cn/notes/20210729212228.png" alt="图1"></p><p>下面提供了一些有助于理解洛伦兹距离的旁注。</p><p><img src="http://note.lizhihao999.cn/notes/20210729213000.png" alt=""></p><p>该定理表明，一组点的距离只能与作为质心的一个点进行比较。</p><p>此外，根据柯西-施瓦茨不等式，当 β 趋于 0 时，方程 (9) 中的洛伦兹距离到$f_{1}$的任何向量$f_{2}$都趋于 0，其可写为$f_{2}=\tau f_{1}$且$\tau\ge 0$​，否则距离更大。因此，具有一组点的洛伦兹距离沿着包含可以写为τμ的元素的射线趋于更小，其中τ ≥ 0且 μ 是它们的质心。<br>$$<br>(\sum_{k=1}^{n}{a_{k}\cdot b_{k}})^{2}\le (\sum_{k=1}^{n}{a_{k}^{2}})(\sum_{k=1}^{n}{b_{k}^{2}})\<br>$$</p><h3 id="Curvature-adaption-曲率适应">Curvature adaption 曲率适应</h3><p>根据雅可比场性质，当所选度量是单位双曲面$H^{d}$上的庞加莱度量$d_{H}$时，$d_{H}$的Hessian沿径向具有特征值0。然而，Hessian 的特征值是水平面的主曲率。 由于矢量场更重要并且为了获得“更好的曲率适应”（Karcher，2014）（即非零特征值），Karcher (1987) 建议使用“修正距离”$(-1+\cosh(d_{H}))$，它在$H^{d}$上等于$\frac{1}{2}d_{L}^{2}$.</p><h3 id="Hyperbolic-centroids-in-the-literature-双曲质心">Hyperbolic centroids in the literature 双曲质心</h3><p>有另外两篇论文利用了双曲质心。 首先是萨拉等人 (2018) 使用与 Poincare 度量相关的质心，但没有封闭形式的解决方案，因此他们通过梯度下降来计算它。 古尔切尔等人 (2019) 优化了一个基于庞加莱度量的问题，但利用了属于另一种双曲几何类型的陀螺质心 (Ungar, 2014)。 当该集合仅包含 2 个点时，它是使用陀螺三角不等式将其与该集合的两个点之间的陀螺距离进行爱因斯坦加法的最小值。 否则，可以将其视为保留左回旋平移的点。 陀螺质心的一个限制是它不能被视为距离期望的最小值（与 Frechet 均值不同），因为爱因斯坦加法不是可交换的。</p><h2 id="2-3-Optimization-and-solver">2.3 Optimization and solver</h2><p>$d_{H}$的方向导数缺乏合适的向量空间结构，无法使用标准优化器。另一方面，平方洛伦兹距离仅依赖于方程（2）中洛伦兹内积的公式，该公式对于任何对都是明确且平滑的。通过尝试减少向量空间中的洛伦兹距离，标准 SGD 也减少了测地距离。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hyperbolic </tag>
            
            <tag> Knowledge Representaion </tag>
            
            <tag> ICML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Hyperbolic-to-Hyperbolic Graph Convolutional Network</title>
      <link href="2021/08/05/lun-wen-bi-ji/gnn/2021-cvpr-a-hyperbolic-to-hyperbolic-graph-convolutional-network/"/>
      <url>2021/08/05/lun-wen-bi-ji/gnn/2021-cvpr-a-hyperbolic-to-hyperbolic-graph-convolutional-network/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2021 CVPR Oral <a href="https://arxiv.org/abs/2104.06942">A Hyperbolic-to-Hyperbolic Graph Convolutional Network</a></p></blockquote><p>双曲线图卷积网络 (GCN) 展示了对具有层次结构的图进行建模的强大表示能力。现有的双曲 GCN 求助于切线空间来实现双曲流形上的图卷积，该过程遵循流形-切线-流形方案，如图 1(a) 所示。然而，流形和切线空间之间的映射只是局部微分同胚，这可能会扭曲双曲流形的全局结构，尤其是大量使用切线空间近似之后。</p><p><img src="http://note.lizhihao999.cn/notes/20210729232119.png" alt="图1（a）"></p><p>本文提出了一种直接作用于双曲流形的双曲线到双曲线图卷积网络（H2H-GCN），H2H-GCN 避免了由切线空间近似引起的失真并保持全局双曲结构。具体来说，如图1（b）所示，H2H-GCN是一个保留流形的图卷积，它由双曲特征变换和双曲邻域聚合组成。 双曲特征变换作为双曲流形上的线性变换起作用，它通过对变换子矩阵施加正交约束来确保变换后的节点表示仍然位于双曲流形上。 对于双曲线邻域聚合，通过爱因斯坦中点作为邻居节点的加权消息来更新每个节点表示。</p><p><img src="http://note.lizhihao999.cn/notes/20210729232532.png" alt="图1（b）"></p><h1>1. Preliminaries</h1><h2 id="1-1-Hyperbolic-Spaces">1.1 Hyperbolic Spaces</h2><p>一个$n$维双曲空间的洛伦兹模型定义为$L=\lbrace x=[x_{0},x_{1},…,x_{n}]\in R^{n+1}:&lt;x,x&gt;<em>{L}=-1,x</em>{0}&gt;0\rbrace$，度量张量为$g=\mathrm{diag}([-1,1_{n}^{\top}])$。由$g$诱导的洛伦兹内积为：</p><p><img src="http://note.lizhihao999.cn/notes/20210729233312.png" alt=""></p><p>接下来是一些必要操作的定义。</p><h3 id="距离-Distance">距离 Distance</h3><p>两个点之间的测地线距离（最短距离）：</p><p><img src="http://note.lizhihao999.cn/notes/20210729233410.png" alt=""></p><h3 id="指数、对数映射-Exponential-and-logarithmic-maps">指数、对数映射 Exponential and logarithmic maps</h3><p>通过指数映射和对数映射实现双曲空间和正切空间之间的切换：</p><p><img src="http://note.lizhihao999.cn/notes/20210729233520.png" alt=""></p><h3 id="等距同构-Isometric-isomorphism">等距同构 Isometric isomorphism</h3><p>另外两个常见双曲模型为庞加莱模型和克莱因模型。洛伦兹模型和庞加莱模型之间的双射：</p><p><img src="http://note.lizhihao999.cn/notes/20210729233818.png" alt=""></p><p>洛伦兹模型和克莱因模型之间的双射：</p><p><img src="http://note.lizhihao999.cn/notes/20210729233848.png" alt=""></p><p>图2给出三种模型之间的几何关系。</p><p><img src="http://note.lizhihao999.cn/notes/20210729233938.png" alt="图2"></p><h2 id="1-2-GCNs">1.2 GCNs</h2><p>在 GCN 的第$l$层，图卷积可以分为两个步骤。</p><h3 id="特征变换-Feature-Transformation">特征变换 Feature Transformation</h3><p><img src="http://note.lizhihao999.cn/notes/20210729234241.png" alt=""></p><h3 id="邻域聚合-Neighborhood-Aggregation">邻域聚合 Neighborhood Aggregation</h3><p><img src="http://note.lizhihao999.cn/notes/20210729234322.png" alt=""></p><p>通过堆叠多个图卷积层，特征转换使 GCN 能够为目标任务学习理想的节点嵌入；邻域聚合使 GCN 能够利用图拓扑结构。</p><h1>2. Hyperbolic-to-Hyperbolic GCN</h1><p>H2H-GCN 直接对双曲流形进行图卷积以保持全局双曲结构。</p><h2 id="2-1-Hyperbolic-Node-Representations">2.1 Hyperbolic Node Representations</h2><p>H2H-GCN 使用方程（3）中定义的指数映射在洛伦兹模型上生成双曲线节点表示：</p><p><img src="http://note.lizhihao999.cn/notes/20210730001229.png" alt=""></p><p>可以合理地认为$[0,x_{i}^{E}]$作为原点 o 处切空间上的节点。</p><h2 id="2-2-Hyperbolic-Feature-Transformation">2.2 Hyperbolic Feature Transformation</h2><p>等式（7）中定义的（欧几里德）GCN 中的特征变换是通过矩阵向量乘法实现的线性变换。尽管如此，在将矩阵向量乘法应用于双曲节点表示时，它将打破双曲流形约束，使变换后的节点不位于双曲流形上，可以通过洛伦兹线性变换来解决这个问题。</p><h3 id="定义1-洛伦兹线性变换">定义1. 洛伦兹线性变换</h3><p>对于$\forall x\in L$，洛伦兹变换定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730010335.png" alt=""></p><p>其中$W$​为变换矩阵，$\hat{W}$​是变换子矩阵，$0$代表为零的列向量，$I$代表单位矩阵。</p><p>利用洛伦兹线性变换作为 H2H-GCN 中的双曲特征变换。在第$l$层，前一层的节点表示$h_{i}^{l-1,L}$和变换矩阵$W^{l}$作为输入。第$i$个节点的中间表示：</p><p><img src="http://note.lizhihao999.cn/notes/20210730013600.png" alt=""></p><p>对于第0层，$h_{i}^{0,L}=x_{i}^{L}$​.</p><h2 id="2-3-Hyperbolic-Neighborhood-Aggregation">2.3 Hyperbolic Neighborhood Aggregation</h2><p>双曲空间中欧几里得均值聚合的推广是 Frechet 均值。 然而，Frechet 均值很难应用，因为它没有封闭形式的解决方案。 所以采用爱因斯坦中点作为 H2H-GCN 中的双曲邻域聚合。在这种情况下，双曲邻域聚合具有两个理想的特性：</p><ol><li>平移不变性</li><li>旋转不变性。</li></ol><p>聚合双曲线平均对于将输入节点集沿共同方向平移相同距离是不变的，并且对于将输入节点集绕原点旋转相同角度是不变的。</p><p><img src="http://note.lizhihao999.cn/notes/20210730014456.png" alt="图3"></p><p>爱因斯坦中点采用克莱因模型中的形式，如图 3 所示。所以，首先需要将洛伦兹模型的中间节点表示投影到克莱因模型，然后通过爱因斯坦中点计算双曲线平均值，最后Klein 模型上的聚合双曲线平均值被投影回 Lorentz 模型。形式上定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210730014606.png" alt=""></p><p>非线性激活在 GCN 中起着重要作用，它可以防止多层网络崩溃成单层网络。然而，在洛伦兹表示上应用常用的非线性激活函数（例如，ReLU）将打破洛伦兹模型的流形约束。 因为 Poincare 球模型上的非线性激活是保持流形的，所以将双曲线平均值$m_{i}^{l,L}$​投影到 Poincare 球模型以应用非线性激活，然后将结果投影回洛伦兹模型：</p><p><img src="http://note.lizhihao999.cn/notes/20210730014908.png" alt=""></p><h2 id="2-4-H2H-GCN-Architecture">2.4 H2H-GCN Architecture</h2><p>总结H2H-GCN嵌入生成算法如算法1所示：给定图$G=(V,E)$：</p><ol><li>将欧几里得特征映射到双曲空间；</li><li>初始化后的双曲节点特征再通过多层的H2H-GCN；</li><li>对于第$l$层：<ol><li>对输入的节点特征进行<strong>双曲特征变换</strong>；</li><li>进行<strong>双曲邻域聚合</strong>；</li><li>通过非线性激活函数。</li></ol></li><li>经过$L$​层后，得到最终的H2H-GCN节点嵌入。</li></ol><p><img src="http://note.lizhihao999.cn/notes/20210730015453.png" alt="算法1"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> Hyperbolic </tag>
            
            <tag> CVPR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hyperbolic Temporal Knowledge Graph Embeddings with Relational and Time Curvatures</title>
      <link href="2021/07/28/lun-wen-bi-ji/knowledge-graph-embedding/2021-acl-hyperbolic-temporal-knowledge-graph-embeddings-with-relational-and-time-curvatures/"/>
      <url>2021/07/28/lun-wen-bi-ji/knowledge-graph-embedding/2021-acl-hyperbolic-temporal-knowledge-graph-embeddings-with-relational-and-time-curvatures/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/abs/2106.04311">论文地址</a></p></blockquote><p>通过简单地增加负样本的数量，最近提出的 ATTH 模型可以在 Temporal KGs (TKGs) 上实现具有竞争力甚至更好的性能，尽管它是非时间性的。 本文进一步提出了 HERCULES，这是 ATTH 模型（2020 ACL）的时间感知扩展，它将黎曼流形的曲率定义为关系和时间的乘积，这是第一次尝试利用流形的曲率来强制时间感知表示。</p><h1 id="1-问题定义"><a href="#1-问题定义" class="headerlink" title="1. 问题定义"></a>1. 问题定义</h1><p>考虑一个有效的四元组$&lt;s,p,o,t&gt;\in S\subset E\times R\times E\times T$，其中$E,R,T,S$分别表示实体集合、关系集合、时间戳集合和事实集合。打分函数$f:E\times R\times E\times T\to R$要求对$\in S$的四元组实现$f(s,p,o,t)$最大化，$\notin S$的四元组最小化。在上述约束的优化过程中，实体、关系和时间的表示被相应地学习，然后，生成的嵌入可以捕获多关系图结构。因此，$f$衡量实体$s$在时间$t$通过关系$p$连接到实体$o$的概率。</p><h1 id="2-双曲几何"><a href="#2-双曲几何" class="headerlink" title="2. 双曲几何"></a>2. 双曲几何</h1><p>欧几里得空间的曲率为零，因此称为平坦空间；双曲几何具有恒定的负曲率。当在双曲空间中表示直线时，直线会变成曲线，称为测地线（如图 1）。</p><p><img src="http://note.lizhihao999.cn/notes/20210726222051.png" alt="图一"></p><p>本文同之前在双曲空间进行知识图谱嵌入的模型一样，在庞加莱球中进行。同样通过指数映射和对数映射在双曲空间和正切空间之间进行切换。</p><p><img src="http://note.lizhihao999.cn/notes/20210726222408.png"></p><p>同样为了替换欧几里得加法，本文使用满足流形边界约束的莫比乌斯加法：</p><p><img src="http://note.lizhihao999.cn/notes/20210726222732.png"></p><p>进而使用通过莫比乌斯加法定义的双曲距离公式：</p><p><img src="http://note.lizhihao999.cn/notes/20210726222817.png"></p><h1 id="3-从ATTH到HERCULES"><a href="#3-从ATTH到HERCULES" class="headerlink" title="3. 从ATTH到HERCULES"></a>3. 从ATTH到HERCULES</h1><h2 id="3-1-ATTH"><a href="#3-1-ATTH" class="headerlink" title="3.1 ATTH"></a>3.1 ATTH</h2><p>ATTH 使用特定关系的嵌入、旋转、反射和曲率。 曲率定义为取决于所涉及的对应关系$p$​。准确地说，关系$ p $被赋予一个单独的参数曲率$c_{p}$：</p><p><img src="http://note.lizhihao999.cn/notes/20210726223205.png"></p><p>其中$\mu_{p}$是可训练的参数，$\sigma$是ReLU激活函数的平滑逼近。</p><p>通过这种方法，可以学习流形的几何形状，从而针对特定谓词进行修改。 曲率决定了流形的形状， 改变流形的曲率意味着改变投影点的位置。 这意味着对于不同的关系，由于每个关系的不同几何形状，同一实体将具有不同的位置。</p><p>为了学习旋转和反射，ATTH使用$2\times 2$​的Givens变换矩阵。这些变换在双曲空间中保持相对距离，因此可以直接应用于双曲嵌入（等距）。我们表示$W_{\Theta_{p}}^{rot},W_{\Phi_{p}}^{ref}$​为块对角矩阵，​对角线上的元素分别通过$G^{+}(\theta_{p,i}),G^{-}(\phi_{p,i})$给出，其中$i$表示对角线中的第$i$个元素：</p><p><img src="http://note.lizhihao999.cn/notes/20210726225225.png"></p><p>旋转和反射仅应用于主体嵌入：</p><p><img src="http://note.lizhihao999.cn/notes/20210726225320.png"></p><p>此外，为了表示可以混合旋转和反射的复杂关系，ATTH 使用了双曲线注意力机制。通过指数映射，在正切空间计算注意力分数$\alpha^{p}<em>{q</em>{rot}^{H}},\alpha^{p}<em>{q</em>{ref}^{H}}$​​；ATTH通过切线空间平均来实现典型的加权平均，之后再通过指数映射回到双曲空间：</p><p><img src="http://note.lizhihao999.cn/notes/20210726230202.png"></p><p>ATTH 最终将一个双曲关系嵌入$r_{p}^{H}$的平移应用到生成的注意力向量上，平移有助于在层次结构的不同级别之间移动。</p><p><img src="http://note.lizhihao999.cn/notes/20210726230527.png"></p><p>最终的得分函数定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210726230629.png"></p><h2 id="3-2-HERCULES"><a href="#3-2-HERCULES" class="headerlink" title="3.2 HERCULES"></a>3.2 HERCULES</h2><p>在ATTH的基础上进一步提出HERCULES，将流形的曲率重新定义为关系和时间的乘积。</p><p><img src="http://note.lizhihao999.cn/notes/20210726231454.png"></p><p>HERCULES 的主要思路是关系和时间都直接调整流形的几何形状，使得投影实体的位置与关系和时间相关。 这是有利的，因为不需要每个实体的附加时间参数。 由于整个几何结构针对特定关系和时间发生了变化，因此该流形上的所有未来投影都将与相应的关系和时间戳对齐。 </p><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><p>整篇文章读下来感觉是，重新读了一遍ACL 2020的<strong>Low-Dimensional Hyperbolic Knowledge Graph Embeddings</strong>，唯一的改进点在于将流形的曲率与关系和时间挂钩，而这篇文章的问题仍然在于没有考虑“时序”，只是将时间戳作为一个特征。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ACL </tag>
            
            <tag> Knowledge Graph Embedding </tag>
            
            <tag> Hyperbolic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HGCF - Hyperbolic Graph Convolution Networks for Collaborative Filtering</title>
      <link href="2021/07/28/lun-wen-bi-ji/recommender-system/2021-www-hgcf-hyperbolic-graph-convolution-networks-for-collaborative-filtering/"/>
      <url>2021/07/28/lun-wen-bi-ji/recommender-system/2021-www-hgcf-hyperbolic-graph-convolution-networks-for-collaborative-filtering/</url>
      
        <content type="html"><![CDATA[<p>本文提出用于协同过滤的双曲GCN 模型，模型可以通过边际排名损失有效地学习，并表明双曲空间在边界排序设置下具有理想的属性，称为双曲协同过滤 (HGCF)。</p><p>HGCF 通过 GCN 模块在参考点的切线空间上聚合邻域信息，从而学习双曲空间中的用户和物品表示，使用基于黎曼梯度下降优化的双曲距离的边界排序损失来有效学习。</p><h1>问题描述</h1><p>考虑标准隐式协同过滤设置：$m$​​个用户$U=\lbrace u_{1},…,u_{m}\rbrace$​​和$n$​​个物品$I=\lbrace i_{1},…,i_{n}\rbrace$​​。用户和物品之间的交互在一个稀疏的$m\times n$​​二元交互矩阵$R$​​中给出，其中当用户$u$​和物品$i$有交互时，$R_{ui}=1$​，否则$R_{ui}=0$。</p><p>定义$N_{u}=\lbrace i\in I:R_{ui}=1\rbrace$为用户邻域，表示与用户$u$有交互的项目集；类似可以定义$N_{i}=\lbrace u\in U:R_{ui}=1\rbrace$为物品邻域。</p><h1>模型总述</h1><p>图1总结了 HGCF 架构，为了应用 HGCF，首先为双曲空间中的所有用户和物品初始化嵌入。然后，给定具有相应嵌入$\theta_{u}\in H^{d}$的用户$u$，我们将$\theta_{u}$映射到参考点的切线空间，在切线空间中通过多层图卷积。更新后带有编码邻域信息的嵌入，被映射回$H^{d}$​，在双曲空间中应用双曲边界排序损失。损失中的信号被反向传播以更新相关参数并重复该过程。类似的过程应用于项目嵌入。</p><p><img src="http://note.lizhihao999.cn/notes/20210727143044.png" alt="图1"></p><h1>双曲嵌入</h1><p>HGCF对用户和项目嵌入都使用洛伦兹表示。固定原点为$o=(\sqrt{k},0,…,0)\in H^{d}$​​并作为参考点。请注意，$k=-1/c$​是曲率$c$​的倒数，此处被视为超参数并根据经验设置。</p><p>嵌入是通过从参考点$o$​​的切线空间上的高斯分布采样来初始化的。形式上，给定用户$u$​和项目$i$，首先从多元高斯中采样：<br>$$<br>\theta_{u}’,\theta_{i}’\sim N(0,\sigma I_{d\times d})<br>$$<br>然后设置<br>$$<br>\theta_{u}’’=[0;\theta_{u}’]\quad \theta_{i}’’=[0;\theta_{i}’]<br>$$<br>其中满足$&lt;\theta_{u}’’,o&gt;<em>{L}=0,&lt;\theta</em>{i}’’,o&gt;<em>{L}=0$​，都属于正切空间$T</em>{o}H^{d}$​。为了在$H^{d}$​​中获得相应的嵌入，通过指数映射投影到双曲空间$\exp_{o}:T_{o}H^{d}\to H^{d}$​：</p><p><img src="http://note.lizhihao999.cn/notes/20210729141330.png" alt=""></p><p>之后便可以得到用户和物品在双曲空间中的嵌入：</p><p><img src="http://note.lizhihao999.cn/notes/20210727144209.png" alt=""></p><p>以上的双曲嵌入用于为所有用户和物品初始化模型。</p><h1>Skip-connected 图卷积网络</h1><p>GCN的主要思想是通过迭代聚合来自多跳邻居的本地信息来学习图中的节点表示。聚合过程通常涉及每个阶段的特征转换和非线性激活。然而最近的工作发现，与更简单的均值聚合方法相比，特征变换和非线性带来的收益是最小的。 此外，非线性为模型增加了相当大的表示能力，并可能导致对高度稀疏的CF数据集的导致过度拟合。 鉴于这些发现，HGCF选择去除特征变换和非线性，以降低模型复杂性并加快训练和推理速度。</p><p>HGCF在正切空间执行聚合操作，首先将嵌入通过对数映射投影到正切空间：</p><p><img src="http://note.lizhihao999.cn/notes/20210727145110.png" alt=""></p><p>输出向量作为第一个 GCN 层的输入，分别表示为：</p><p><img src="http://note.lizhihao999.cn/notes/20210727145226.png" alt=""></p><p>给定用户邻域和物品邻域，每一层图卷积层都是通过聚合来自前一层的邻域表示来计算的：</p><p><img src="http://note.lizhihao999.cn/notes/20210727145408.png" alt=""></p><p>每一层都聚集在越来越高阶的邻居上，允许对用户和物品之间的长期关系进行明确建模。</p><p>为了充分利用高阶关系，需要将多个图卷积层堆叠在一起。为了减轻深度的限制，本文探索了包含由残差网络和深度 GCN 相关工作激发的跳跃连接（Skip-connected）的架构，如图2所示。</p><p><img src="http://note.lizhihao999.cn/notes/20210727145743.png" alt="图2"></p><p>这里，PlainGCN 是原始模型，SkipGCN、ResGCN 和 DenseGCN 具有不同的跳过连接结构。 SkipGCN 包含从每一层到最后一层的跳过连接，ResGCN 具有连续层之间的残差连接，而 DenseGCN 结合了 SkipGCN 和 ResGCN。 根据经验，SkipGCN 在双曲空间设置中表现最好，将这种架构用于 HGCF。</p><p>在 SkipGCN 下，最后一层聚合来自所有中间层的表示，每个用户和项目的最终嵌入是通过应用指数映射将 SkipGCN 的输出投影回双曲空间来获得：</p><p><img src="http://note.lizhihao999.cn/notes/20210729141945.png" alt=""></p><p>更新后的嵌入现在编码了丰富的邻域信息，可以通过双曲距离$d_{L}(\Psi_{u},\Psi_{i})$来估计用户-物品对之间的相似性。</p><h1>Hyperbolic Margin Ranking Loss 双曲边界排序损失</h1><p>边界排序损失已被证明对基于距离的推荐模型非常有效，这种损失旨在将正负用户-物品对分离到给定的边界。一旦达到边界，这些用户-用品对就被认为是分离良好的，不再造成损失。 这使优化能够不断地重新关注违反边界的“困难”对。HGCF模型中采用这种损失并优化双曲空间中的边界分离。</p><p>形式上，对于每个用户$u$​采样一个正样例物品$i,R_{ui}=1$​和一个负样例物品$j,R_{uj}=0$​，目标是通过​两个物品$i,j$到用户$u$的距离来分离这两个物品：</p><p><img src="http://note.lizhihao999.cn/notes/20210727150850.png" alt=""></p><p>其中，$m$即为边界。一旦差异$d_{L}(\Psi_{u},\Psi_{i})^{2}-d_{L}(\Psi_{u},\Psi_{j})^{2}$大于边际，损失就变为0，物品对停止对梯度做出贡献。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> Hyperbolic </tag>
            
            <tag> Recommender System </tag>
            
            <tag> WWW </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Semi-Riemannian Graph Convolutional Networks</title>
      <link href="2021/07/22/lun-wen-bi-ji/gnn/2021-nips-semi-riemannian-graph-convolutional-networks/"/>
      <url>2021/07/22/lun-wen-bi-ji/gnn/2021-nips-semi-riemannian-graph-convolutional-networks/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/abs/2106.03134">NeurIPS 2021 Semi-Riemannian Graph Convolutional Networks</a></p><p><a href="https://github.com/QGCN/QGCN">QGCN代码</a></p></blockquote><p>该论文推导出一个有理论支撑的半黎曼 GCN，它在图神经网络的上下文中对恒定非零曲率的半黎曼流形中的数据进行建模。 论文方法提供了足够灵活的几何归纳偏置，可以对混合异构拓扑进行建模，例如具有循环的分层图。</p><p>比起黎曼流形，配备不定度量的半黎曼流形构成了更大的几何类别。 恒定非零曲率的半黎曼流形不仅概括了双曲流形和球面流形，而且还包含它们的子流形，从而提供特定于这些几何的归纳偏置。</p><p><img src="http://note.lizhihao999.cn/notes/20210721170804.png" alt="图1"></p><blockquote><p>具有两个时间维度的-1曲率四维伪双曲面的不同子流形。 通过固定一个时间维度$x_{0}$，诱导的子流形包括 ：(a)一个单层双曲面，(b) 双锥体，和 © 一个两层双曲面。</p></blockquote><h1>1. 基础定义 Preliminaries</h1><h2 id="1-1-Semi-Riemannian-manifolds-半黎曼流形">1.1 Semi-Riemannian manifolds 半黎曼流形</h2><p>半黎曼流形（Semi-Riemannian manifolds），也称为伪黎曼流形（pseudo-Riemannian manifolds）其上有一光滑、对称、点点非退化的$(0,2)$​张量。此张量称为伪黎曼度量或伪度量张量。</p><p>伪黎曼流形与黎曼流形的区别是它不需要正定（通常要求非退化）。因为每个正定形式都是非退化的，所以黎曼度量也是一个伪黎曼度量，亦即黎曼流形是伪黎曼流形的一种特例。</p><h2 id="1-2-Pseudo-hyperboloid-伪双曲面">1.2 Pseudo-hyperboloid 伪双曲面</h2><p>伪双曲面被定义为周围伪欧几里得空间$R^{s,t+1}$​​​​​​中的子流形，维数为$ d = s + t + 1$​​​​​​，使用方程（1）中的标量积。可以用该标量诱导的范数$||x||^{2}_t=&lt;x,x&gt;<em>t$​​​​​来定义伪双曲面$Q</em>{\beta}^{s,t}$​​​​​ ：</p><p><img src="http://note.lizhihao999.cn/notes/20210721170453.png" alt=""></p><p>其中，$\beta$是曲率的非零实数参数：</p><ul><li>$\beta&gt;0$：伪球面</li><li>$\beta&lt;0$：伪双曲面</li></ul><p>因为$Q_{\beta}^{s,t}$和$Q_{-\beta}^{t+1,s-1}$之间是可互换的，所以只用考虑伪双曲面$Q_{-\beta}^{t+1,s-1}$一种情况即可。根据狭义相对论，$Q_{\beta}^{s,t}$中的一个点$x$可以解释为一个事件，其中最开始的$t+1$维是时间维度，后$s-1$维是空间维度。</p><p>双曲流形和球面流形可以分别定义为伪双曲面的特殊情况，方法是将除第1维之外的所有时间维度设置为零得到双曲面流形，将所有空间维度设置为零得到球面流形，即<br>$$<br>H_{\beta}=Q_{\beta}^{s,1},S_{-\beta}=Q_{\beta}^{0,t}<br>$$</p><h2 id="1-3-Geodesical-connectedness-测地连通性">1.3 Geodesical connectedness 测地连通性</h2><p>半黎曼流形 M 是连通的，当 M 的任意两点都可以通过分段（断开的）测地线连接，每条测地线都是平滑测地线。 流形是测地连通(g-连通)的，如果任意两点都可以通过测地线平滑连接，其中这两个点称为 g-连通，否则称为 g-断开。</p><p>伪双曲面是测地线完备但不是g-连通的流形，其中存在不能通过测地线平滑连接的点。</p><h1>2. 伪双曲面上的测地线工具 Geodesic Tools on Pseudo-Hyperboloid</h1><h2 id="2-1-Diffeomorphism-of-Pseudo-Hyperboloid-伪双曲面的微分同胚">2.1 Diffeomorphism of Pseudo-Hyperboloid 伪双曲面的微分同胚</h2><p>解决微分几何中的难点的一种标准方法是对其更容易操作的微分同胚流形执行操作。</p><p>对于半黎曼流形，遵循微分同胚可以将伪双曲面分解为单位球体和欧几里得空间的乘积流形。</p><p><img src="http://note.lizhihao999.cn/notes/20210721175135.png" alt=""></p><p>受此启发，我们提出了两个对偶微分同胚，将 x 映射到曲率为$-1/\beta$的球体和欧几里得空间的乘积流形。</p><p><img src="http://note.lizhihao999.cn/notes/20210721173617.png" alt=""></p><p>定理 3.2 和定理 3.3 分别产生球面投影（用$\psi_{S}$​表示）和双曲投影（用$\psi_{H}$​​表示），并且映射点仍然位于伪双曲面的表面上，如图2(a)。</p><p><img src="http://note.lizhihao999.cn/notes/20210721184808.png" alt="图2"></p><blockquote><p>(a) 双曲投影（青色）和球面投影（绿色）分别将点 x（红色）映射到切向量$v_{s+1}$和$v_{t}$​；</p><p>(b) 平行传输$P_{x\to y}^{\beta}(\xi)$​​沿正切方向$\xi$​​将正切向量$\zeta\in T_{x}Q_{\beta}^{s,t}$​​移动到正切空间$T_{y}Q_{\beta}^{s,t}$​​​；</p><p>© 分段测地距离（绿色、青色和黑色）和近似部分（灰色）。</p></blockquote><p>事实上，通过推广定理 3.2 和定理 3.3，我们提出了一个更灵活的微分同胚，将伪双曲面分解为乘积流形：</p><p><img src="http://note.lizhihao999.cn/notes/20210721174932.png" alt=""></p><p>在这种情况下，定理 3.2 和定理 3.3 可以看作是两个特例，分别设置$a=0,b=t$和$a=s,b=1$。当测地线工具在伪双曲面中没有明确定义时，定理 3.4 提供了可分解性作为分析和操作测地线的替代方法。</p><p>定理 3.5 表明，并非定理 3.4 中的所有微分流形都是 g-连通的：</p><p><img src="http://note.lizhihao999.cn/notes/20210721175415.png" alt=""></p><p>如图1©所示，空间维度将导致包含两个孤立的表的双曲子流形，这显然是不连接的。所以，我们必须将所有空间维度都投影到欧几里得空间$R$​中。</p><h2 id="2-2-Geodesic-Tools-for-G-disconnected-Pseudo-hyperboloid-用于G-不连通伪双曲面的测地线工具">2.2 Geodesic Tools for G-disconnected Pseudo-hyperboloid 用于G-不连通伪双曲面的测地线工具</h2><h3 id="Exponential-and-Logarithmic-Map-指数映射和对数映射">Exponential and Logarithmic Map 指数映射和对数映射</h3><p>如上所述，伪双曲面$Q_{\beta}^{s,t}$是g-不连通的，我们将指数映射和对数映射应用到两个微分同胚流形中：</p><p><img src="http://note.lizhihao999.cn/notes/20210721180317.png" alt=""></p><p>零空间维参考点 x 处的微分同胚映射运算是内在（intrinsic）的，这意味着它们是从伪双曲面上的点到由 x 引起的切线空间的双射函数，由定理 3.6 断言：</p><p><img src="http://note.lizhihao999.cn/notes/20210721180528.png" alt=""></p><p>值得注意的是，微分同胚运算的内在性使它们保留了伪双曲面的几何表现力。 这与独立操纵每个组件中的切向量的乘积流形不同。</p><h3 id="Tangential-Operations-切向操作">Tangential Operations 切向操作</h3><p>通过以上定义的映射操作实现伪双曲面的切向操作：</p><p><img src="http://note.lizhihao999.cn/notes/20210721180817.png" alt=""></p><p>其中$x$为参考点。</p><h3 id="Parallel-Transport-平行传输">Parallel Transport 平行传输</h3><p>伪双曲面中的平行传输可以定义为黎曼平行传输的组合。但是，当$ x $和$ y $​之间不存在测地线时，无法定义平行传输。 换句话说，$x $引起的切向量不能传递到正交邻域$U_{x}$​之外的点的切空间。 直观地，正交邻域满足以下性质：</p><p><img src="http://note.lizhihao999.cn/notes/20210721181344.png" alt=""></p><p>这可以保证，如果一个点$y\notin U_{x}$，则它的对映点（antipodal point）$-y\in U_{x}$。又因为$T_{y}M$和$T_{-y}M$之间是平行的，所以对于不连通的点，$P_{x\to y}^{\beta}$可以定义为$P_{x\to -y}^{\beta}$。</p><h3 id="Geodesic-Distance-测地距离">Geodesic Distance 测地距离</h3><p>伪双曲面中两个点$x,y$​之间的诱导测地距离定义为测地线$\gamma(\tau)$​的弧长$d_{\gamma}=\sqrt{||\log_{x}(y)||<em>{t}^{2}}$；对于$\log</em>{x}(y)$​无法定义的情况，可以使用近似。如下：</p><p><img src="http://note.lizhihao999.cn/notes/20210721182058.png" alt=""></p><h1>3. 半黎曼GCN Semi-Riemannian GCNs</h1><p>GCN 可以解释为在对每一层的节点特征进行线性变换后执行邻域聚合。我们通过在伪双曲面$Q_{\beta}^{(s,t)}$​中使用开发的测地线工具导出相应的操作来呈现半黎曼 GCN(Q-GCN)。</p><h2 id="3-1-Feature-Initialization-特征初始化">3.1 Feature Initialization 特征初始化</h2><p>首先，将欧氏空间中的特征映射到伪双曲面中。然后，我们通过执行由定理3.2或3.3组成的可微映射$\varphi:R_{*}^{t+1}\times R^{s}\to Q_{\beta}^{s,t}$来初始化节点特征。</p><h2 id="3-2-Tangential-Transformation-正切变换">3.2 Tangential Transformation 正切变换</h2><p>我们通过利用等式(3)中定义的指数映射和对数映射对切线空间执行欧几里德变换。具体来说，首先通过对数映射将隐藏特征映射到正切空间，然后执行欧几里得矩阵乘法，最后通过指数映射回到原来的流形中。</p><p>每一层都执行以上过程，可定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210721183543.png" alt=""></p><h2 id="3-3-Bias-Translation-偏置平移">3.3 Bias Translation 偏置平移</h2><p>为了避免模型崩溃，我们在正切变换后执行偏置平移。通过伪双曲面并行传输，可以通过将切向量平行传输到感兴趣点的切线空间来执行偏置平移。最后再通过指数映射回到原始流形。偏置平移操作可定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210721183811.png" alt=""></p><h2 id="3-4-Tangential-Aggregation-正切聚合">3.4 Tangential Aggregation 正切聚合</h2><p>邻域特征的线性组合被提升到切线空间，这是微分流形中的一个内在操作。具体来说，Q-GCN在参考点$o$​的正切空间中聚合领域嵌入，再通过一个正切激活函数，最后将更新后的表示投影回流形。</p><p>在每一层$l$，每个节点$i$的更新特征定义为：</p><p><img src="http://note.lizhihao999.cn/notes/20210721184201.png" alt=""></p><p>将双曲空间中的逐层可训练曲率推广到伪双曲面，以捕获每层嵌入的正确比例。 最后一层的伪双曲面嵌入可用于下游任务，例如预测节点属性或链接。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> NeurIPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Geometry Interaction Learning</title>
      <link href="2021/07/21/lun-wen-bi-ji/gnn/2020-nips-graph-geometry-interaction-learning/"/>
      <url>2021/07/21/lun-wen-bi-ji/gnn/2020-nips-graph-geometry-interaction-learning/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/abs/2010.12135">NeurIPS 2020 Graph Geometry Interaction Learning</a></p><p><a href="https://github.com/CheriseZhu/GIL">GIL code</a></p></blockquote><p>这篇文章提出一种新颖的图形几何交互学习 (GIL) 方法，这是一种非常适合且有效的替代方法，可以利用欧几里得几何和双曲几何的优势，用于学习图形中丰富的几何属性。此外，该方法通过灵活的双特征交互学习和概率组合机制赋予每个节点自由度来确定每种几何空间的重要性。</p><p>许多真实的复杂图表现出非欧几何的特征，例如无标度或层次结构。现有双曲空间的工作中，一般假设图中的所有节点共享相同的空间曲率，而不同空间之间没有交互。 与之前方法不同，本文尝试以一种新的交互学习方式将图同时嵌入到欧几里得空间和双曲空间中，希望这两组嵌入可以相互增强，为下游任务提供更有效的表示。GIL 不仅考虑如何交互不同的几何空间，还保证了每个空间的共形不变性。</p><p><img src="http://note.lizhihao999.cn/notes/20210721201519.png" alt="图1"></p><blockquote><p>具有双曲线和欧几里德结构的图示</p><p>欧几里得空间（左）适合表示低维规则结构的蓝点，而层次结构的黄点更适合表示双曲线空间（右）。</p></blockquote><h1 id="1-基础定义-Notation-and-Preliminaries"><a href="#1-基础定义-Notation-and-Preliminaries" class="headerlink" title="1. 基础定义 Notation and Preliminaries"></a>1. 基础定义 Notation and Preliminaries</h1><h2 id="1-1-双曲几何"><a href="#1-1-双曲几何" class="headerlink" title="1.1 双曲几何"></a>1.1 双曲几何</h2><p>该方法在庞加莱模型中进行双曲嵌入，并通过指数变换和对数变换在双曲空间和正切空间之间进行切换。</p><p><img src="http://note.lizhihao999.cn/notes/20210720224124.png"></p><p>双曲空间中的基本操作为莫比乌斯加法，需要通过定义莫比乌斯加法实现以上操作：</p><p><img src="http://note.lizhihao999.cn/notes/20210720224217.png"></p><p>基于莫比乌斯变换，进一步定义在双曲空间中的莫比乌斯标量乘法和莫比乌斯矩阵乘法：</p><p><img src="http://note.lizhihao999.cn/notes/20210720224055.png"></p><h2 id="1-2-图注意力网络"><a href="#1-2-图注意力网络" class="headerlink" title="1.2 图注意力网络"></a>1.2 图注意力网络</h2><p>图注意力网络（GAT）可以解释为在节点上执行注意力消息传播和更新。每一层通过注意力邻居信息对节点特征$h_{i}$进行更新，得到$h_{i}’$：</p><p><img src="http://note.lizhihao999.cn/notes/20210720224702.png"></p><p>其中$N_{i}$表示节点$i$的单跳邻居，$W$为需要训练的参数。</p><p>注意力系数$\alpha_{ij}$通过以下方式计算：</p><p><img src="http://note.lizhihao999.cn/notes/20210720224717.png"></p><p>$a$为参数化注意力的权重向量。</p><h1 id="2-Graph-Geometry-Interaction-Learning"><a href="#2-Graph-Geometry-Interaction-Learning" class="headerlink" title="2. Graph Geometry Interaction Learning"></a>2. Graph Geometry Interaction Learning</h1><p>GIL方法通过特征交互方案利用不同的几何空间，在此基础上进一步开发概率组装以整合最终预测的类别概率。</p><p><img src="http://note.lizhihao999.cn/notes/20210721002157.png" alt="GIL架构示意图"></p><p>模型GIL分为三个主要部分：</p><ol><li>几何消息传播(Geometry Message Propagation)：通过距离感知注意机制在欧几里得空间和双曲线空间中同时传播邻居信息。 在双曲线空间中，消息通过切线空间上的距离引导的自注意力机制进行聚合；</li><li>双特征交互(Dual Feature Interaction)：节点特征根据距离相似度从双特征空间进行自适应调整； </li><li> 概率组合(Probability Assembling)：在训练阶段使用来自每个空间的分类概率的加权和来获得最终的分类结果。</li></ol><p>该方法是端到端训练的。</p><h2 id="2-1-Geometry-Feature-Interaction-几何特征交互"><a href="#2-1-Geometry-Feature-Interaction-几何特征交互" class="headerlink" title="2.1 Geometry Feature Interaction 几何特征交互"></a>2.1 Geometry Feature Interaction 几何特征交互</h2><h2 id="2-1-1-几何消息传播"><a href="#2-1-1-几何消息传播" class="headerlink" title="2.1.1 几何消息传播"></a>2.1.1 几何消息传播</h2><p>GNN通过消息传播来学习节点嵌入。在欧氏空间中，可以直接使用GAT来进行信息传播。而在双曲空间中，由于莫比乌斯加法不满足交换律和结合律，所以无法直接使用GAT。可以映射到正切空间后，在正切空间中执行以上操作。</p><p>对于输入的欧几里得空间的图和节点特征，首先通过指数映射将其映射到双曲空间并进行初始化。初始化得到$h^{(0)}$之后，再通过对数映射到正切空间，进行后续的消息传播。</p><p><img src="http://note.lizhihao999.cn/notes/20210720232831.png"></p><p>映射到切线空间后，消息通过节点$j$特征的归一化注意力$\alpha_{ij}^{(k)}$缩放到节点$i$（方程10）。 $\alpha_{ij}^{(k)}$是基于距离感知的注意力：</p><p><img src="http://note.lizhihao999.cn/notes/20210721003118.png"></p><h2 id="2-1-2-双特征交互"><a href="#2-1-2-双特征交互" class="headerlink" title="2.1.2 双特征交互"></a>2.1.2 双特征交互</h2><p>基于图拓扑进行消息传播后，节点嵌入将从双特征空间进行自适应调整，以促进不同几何空间之间的交互。具体来说，通过将双曲嵌入映射到正切空间，欧式嵌入映射到双曲空间来进行交互：</p><p><img src="http://note.lizhihao999.cn/notes/20210720234810.png"></p><p>其中，$h’<em>{D</em>{c}}$和$h’_{R}$就是融合之后的节点嵌入。</p><p>在特征融合后，因为嵌入仍然回到对应的原始空间中，所以节点嵌入不仅通过交互学习整合了不同的几何特征，而且还保持了原始空间的属性和结构。 </p><h2 id="2-2-双曲逻辑回归和概率组合"><a href="#2-2-双曲逻辑回归和概率组合" class="headerlink" title="2.2 双曲逻辑回归和概率组合"></a>2.2 双曲逻辑回归和概率组合</h2><h2 id="2-2-1-双曲面逻辑回归"><a href="#2-2-1-双曲面逻辑回归" class="headerlink" title="2.2.1 双曲面逻辑回归"></a>2.2.1 双曲面逻辑回归</h2><p>为了在双曲空间上执行多类逻辑回归，我们通过引入仿射超平面作为决策边界，将欧几里得 softmax 推广到双曲 softmax。 类别概率通过节点到超平面的距离来衡量：</p><p><img src="http://note.lizhihao999.cn/notes/20210720235402.png"></p><p>要在双曲空间中定义超平面，需要找出法向量，超平面的方向完全由它决定。由于切线空间是欧几里得空间，因此可以在该空间中直观地定义法向量和内积。</p><p><img src="http://note.lizhihao999.cn/notes/20210721000315.png"></p><p>向量$\vec{x}$到超平面$\tilde{H}_{u,p}^{c}$的距离为：</p><p><img src="http://note.lizhihao999.cn/notes/20210721000545.png"></p><h2 id="2-2-2-概率组合"><a href="#2-2-2-概率组合" class="headerlink" title="2.2.2 概率组合"></a>2.2.2 概率组合</h2><p>最直观和自然的做法是，将不同的几何特征连接起来，然后将单个特征输入一个分类器。 然而，由于几何空间的不同操作，共形不变性的其中之一需要舍弃，要么保留欧几里得方程的空间形式，要么保留双曲线方程的形式：</p><p><img src="http://note.lizhihao999.cn/notes/20210721000908.png"></p><p>希望同时保持每个空间的特征，并尽可能多地保留空间属性。 所以需要找出对每个节点来说，哪个几何嵌入更重要，然后为相应的概率分配更多权重：</p><p><img src="http://note.lizhihao999.cn/notes/20210721001332.png"></p><p>其中对应的权重$\lambda_{0},\lambda_{1}\in R^{N}$表示不同几何概率的节点级权重，通过沿维度1对串联$[\lambda_{0},\lambda_{1}]$进行 L2 归一化来满足归一化条件。分别通过具有相应节点嵌入输入的全连接层进行计算：</p><p><img src="http://note.lizhihao999.cn/notes/20210721001801.png"></p><p>两个空间概率对最终概率的贡献由对应空间中的节点特征决定，即节点本身决定了哪个概率对于下游任务更可靠。</p><h1 id="3-模型总结"><a href="#3-模型总结" class="headerlink" title="3. 模型总结"></a>3. 模型总结</h1><p>本文提出了用于图形的几何交互学习 (GIL)，这是一种利用双曲和欧几里得拓扑特征的综合几何表示学习方法。 GIL 为不同的几何结构推导出一种新的距离感知传播和交互学习方案，并以自适应方式为每个节点的不同几何嵌入分配不同的重要性权重。 </p><p>作者使用端到端架构实现GIL方法，如GIL架构示意图所示。图中左侧面板显示了两个空间之间的消息传播和交互。 对于每一层，局部消息在整个图中扩散，然后节点特征被自适应地合并以根据对偶几何信息进行自我调整。 在堆叠多层使几何特征深度交互后，GIL 应用概率组合得到可靠的最终结果，如图右侧所示。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> NeurIPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tmux实现Linux下的终端复用</title>
      <link href="2021/07/19/tuo-keng-ji-lu/tmux-shi-xian-linux-xia-de-zhong-duan-fu-yong/"/>
      <url>2021/07/19/tuo-keng-ji-lu/tmux-shi-xian-linux-xia-de-zhong-duan-fu-yong/</url>
      
        <content type="html"><![CDATA[<p>当通过SHH远程连接服务器训练模型或者运行程序时，如果断开SSH连接，当前操作也会停止运行，这样的操作很不优雅，我们可以通过<code>tmux</code>实现断开连接后仍然继续执行当前窗口的操作。<code>tmux</code>实际为一个终端复用软件，主要可以实现以下功能：</p><ol><li>分屏</li><li>保护现场</li><li>会话共享</li></ol><h1 id="1-安装tmux"><a href="#1-安装tmux" class="headerlink" title="1. 安装tmux"></a>1. 安装tmux</h1><p>ubuntu环境下可通过以下命令进行安装：</p><pre><code class="shell">sudo apt-get install tmux</code></pre><h1 id="2-常用命令"><a href="#2-常用命令" class="headerlink" title="2. 常用命令"></a>2. 常用命令</h1><h2 id="2-1-新建会话"><a href="#2-1-新建会话" class="headerlink" title="2.1 新建会话"></a>2.1 新建会话</h2><p>新建时需要指定会话名称：</p><pre><code class="shell">tmux new -s &lt;session-name&gt;</code></pre><p>之后会直接进入新建的会话当中，并且新会话默认停留在当前目录。之后即使断开SSH连接，当前会话中的程序仍然会继续运行，不会停止。</p><h2 id="2-2-重回会话"><a href="#2-2-重回会话" class="headerlink" title="2.2 重回会话"></a>2.2 重回会话</h2><p>当我们重新连接SSH后，可以重新进入之前的会话查看运行情况：</p><pre><code class="shell">tmux attach -t &lt;session-name&gt;tmux a -t &lt;session-name&gt;</code></pre><h2 id="2-3-退出当前会话"><a href="#2-3-退出当前会话" class="headerlink" title="2.3 退出当前会话"></a>2.3 退出当前会话</h2><p>可以显示输入：</p><pre><code class="shell">exit</code></pre><p>或者快捷键<code>Ctrl+d</code>。</p><h2 id="2-4-查看所有会话"><a href="#2-4-查看所有会话" class="headerlink" title="2.4 查看所有会话"></a>2.4 查看所有会话</h2><p>有两条命令均可查看：</p><pre><code class="shell">tmux list-sessiontmux ls</code></pre><h2 id="2-5-关闭会话"><a href="#2-5-关闭会话" class="headerlink" title="2.5 关闭会话"></a>2.5 关闭会话</h2><p>会话中所有操作结束后需要关闭会话，可以指定关闭特定会话：</p><pre><code class="shell">tmux kill-session -t &lt;session-name&gt;</code></pre><p>也可以直接关闭所有会话：</p><pre><code class="shell">tmux kill-server</code></pre><h2 id="2-6-切换会话"><a href="#2-6-切换会话" class="headerlink" title="2.6 切换会话"></a>2.6 切换会话</h2><p><code>tmux switch</code>命令用于切换会话，可以通过编号或者名称进行指定：</p><pre><code class="shell">tmux switch -t &lt;session-id&gt;tmux switch -t &lt;session-name&gt;</code></pre><p>后续更新进阶功能的配置</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>struc2vec Learning Node Representations from Structural Identity</title>
      <link href="2021/07/15/lun-wen-bi-ji/graph-embedding/2017-kdd-struc2vec-learning-node-representations-from-structural-identity/"/>
      <url>2021/07/15/lun-wen-bi-ji/graph-embedding/2017-kdd-struc2vec-learning-node-representations-from-structural-identity/</url>
      
        <content type="html"><![CDATA[<p>STRUC2VEC的目的是捕捉网络中节点的结构信息（潜在表示）：</p><ol><li>结构相似节点的表示应该相似（距离近）；结构不同的节点表示应该不同（距离远）；</li><li>节点结构的潜在表示不依赖于节点、边的标签等属性，只与节点在网络中的“位置有关”。</li></ol><h1 id="1-结构相似度-Structural-Similarity"><a href="#1-结构相似度-Structural-Similarity" class="headerlink" title="1. 结构相似度 Structural Similarity"></a>1. 结构相似度 Structural Similarity</h1><p>直观上，两个度（degree）相同的节点在结构上相似。令$G=(V,E)$表示无向、无权重的网络，其中节点集$V$，节点数量为$n=|V|$，边集$E$，$k^{*}$表示网络的直径。令$R_{k}(u)$表示距离节点$u;k$跳的节点集合。$s(S)$表示集合$S\subset V$的有序度序列。</p><p>通过比较距离 $u$ 和$v$为$k$的环的有序度序列，我们可以施加层次结构来测量结构相似性。令$f_{k}(u,v)$表示$u,v$之间的结构距离（structural distance），考虑$k$跳的距离（距离小于或等于$k$的所有节点以及其中的所有边）。</p><p><img src="http://note.lizhihao999.cn/notes/20210714140322.png"></p><p>其中$g(D_{1},D_{2})\ge0$表示有序度序列$D_{1},D_{2}$之间的距离，$f_{-1}=0$. 如果$ u $和$ v $的$ k $跳邻域是同构的，并且将$ u $映射到$ v$，则$f_{k-1}(u,v)=0$.</p><p>最后还需要定义比较两个度序列之间的函数。两个序列的长度可能不同，其中的元素是$[0,n-1]$之间的随机数。所以可以使用动态时间规整（DTW, Dynamic Time Warping）算法，DTW找出两个序列 A 和 B 之间的最佳比对，定义其中的距离函数：</p><p><img src="http://note.lizhihao999.cn/notes/20210714150723.png"></p><p>保证当$a=b$的时候$d(a,b)=0$。</p><h1 id="2-构建上下文图-Constructing-the-context-graph"><a href="#2-构建上下文图-Constructing-the-context-graph" class="headerlink" title="2. 构建上下文图 Constructing the context graph"></a>2. 构建上下文图 Constructing the context graph</h1><p>构建了一个多层加权图，对节点之间的结构相似性进行编码。令$M$表示多层图，每一层$k$通过节点的$k$跳邻域定义。</p><p>每层$k=0,…,k^{*}$通过一个有权无向完全图进行构造，两点间的边权重为：</p><p><img src="http://note.lizhihao999.cn/notes/20210715012301.png"></p><p>通过有向边连接每层，每个顶点都连接到其上下层中的相应顶点（层许可）。即第$k$层中$u\in V$与$k-1,k+1$层连接的边权重为：</p><p><img src="http://note.lizhihao999.cn/notes/20210715012336.png"></p><p>其中$\Gamma_{k}(u)$表示与 u 相关且权重大于第$ k $层中完整图的平均边权重的边数。即：</p><p><img src="http://note.lizhihao999.cn/notes/20210715012346.png"></p><p>所以，$\Gamma_{k}(u)$可以测量节点$ u $与第$ k $层其他节点的相似度</p><h1 id="3-为节点生成上下文-Generating-context-for-nodes"><a href="#3-为节点生成上下文-Generating-context-for-nodes" class="headerlink" title="3. 为节点生成上下文 Generating context for nodes"></a>3. 为节点生成上下文 Generating context for nodes</h1><p>$M$完全不使用标签信息来捕获 G 中节点之间结构相似性的结构。struct2vec使用随机游走生成节点序列来确定给定节点的上下文。 我们考虑在$ M $周围移动的有偏见的随机游走，根据$ M $的权重做出随机选择。</p><p>给定留在当前层的概率$p$，每一步游走之前需要决定是否移动到其他层还是继续在当前层游走。</p><h2 id="1-当前层"><a href="#1-当前层" class="headerlink" title="1. 当前层"></a>1. 当前层</h2><p>在第$ k $层从节点$ u $步进到节点$ v $的概率由下式给出：</p><p><img src="http://note.lizhihao999.cn/notes/20210715012400.png"></p><p>其中，$Z_{k}(u)$是第$ k $层顶点$ u $的归一化因子：</p><p><img src="http://note.lizhihao999.cn/notes/20210715012408.png"></p><p>随机游走会更喜欢步入到结构上与当前顶点更相似的节点，避免与当前顶点结构不太相似的节点。因此，节点$u\in V$的上下文可能具有结构相似的节点，独立于它们在原始网络$ G $中的标签和位置。</p><h2 id="2-改变层"><a href="#2-改变层" class="headerlink" title="2. 改变层"></a>2. 改变层</h2><p>如果决定移动到其他层的对应节点，还需要决定是移动到上一层还是下一层，概率为：</p><p><img src="http://note.lizhihao999.cn/notes/20210715012415.png"></p><p>每次 walker 步入一个层时，它都会将当前顶点作为其上下文的一部分，独立于该层。因此，顶点$ u $可能在第$ k $层具有给定的上下文（由该层的结构相似性确定），但在第$ k + 1 $层具有该上下文的子集，因为结构相似性不会随着我们移动到更高层而增加。</p><p>最后，对于每个节点$u\in V$，我们在其对应的第0层顶点开始随机游走。随机游走具有固定且相对较短的长度（步数），并且该过程重复一定次数，从而产生到多个独立的步行（即节点$ u $的多个上下文）。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph Embedding </tag>
            
            <tag> KDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态时间规整(DTW)算法</title>
      <link href="2021/07/14/suan-fa-bi-ji/dong-tai-shi-jian-gui-zheng/"/>
      <url>2021/07/14/suan-fa-bi-ji/dong-tai-shi-jian-gui-zheng/</url>
      
        <content type="html"><![CDATA[<p>时间序列数据存在多种相似或距离函数，其中最突出的是动态时间规整。在大部分的学科中，时间序列是数据的一种常见表示形式。对于时间序列处理来说，一个普遍的任务就是比较两个序列的相似性。在时间序列中，需要比较相似性的两段时间序列的<strong>长度可能并不相等</strong>，在语音识别领域表现为不同人的语速不同。</p><p><img src="http://note.lizhihao999.cn/notes/20210714142246.png"></p><p>动态时间规整在60年代由日本学者Itakura提出，把未知量伸长或缩短(压扩)，直到与参考模板的长度一致，在这一过程中，未知单词的时间轴会产生扭曲或弯折，以便其特征量与标准模式对应。即可以把序列某个时刻的点跟另一时刻多个连续时刻的点相对应。</p><h1 id="1-算法描述"><a href="#1-算法描述" class="headerlink" title="1. 算法描述"></a>1. 算法描述</h1><p>给定两个时间序列$X$和$Y$ ，他们的长度分别是$n$和$m$：<br>$$<br>X=[x_{1},x_{2},…,x_{n}]\<br>Y=[y_{1},y_{2},…,y_{m}]<br>$$<br>在$m\ne n$的情况下，为了对齐这两个序列，首先构建一个$n\times m$的矩阵网格，矩阵$(i,j)$处的元素表示$x_{i},y_{j}$之间的距离$d(x_{i},y_{j})$，不同情况下距离公式的选择不同，最简单可以使用欧氏距离。然后，寻找一条从矩阵左上角元素到右下角的路径，使得路径上的元素和最小，可以通过<strong>动态规划</strong>解决。</p><h1 id="2-规整路径-Warp-Path"><a href="#2-规整路径-Warp-Path" class="headerlink" title="2. 规整路径 Warp Path"></a>2. 规整路径 Warp Path</h1><p>该路径称为规整路径$W$：<br>$$<br>W=w_{1},w_{2},…,w_{k},…,w_{K}\<br>\max(m,n)\le K&lt;m+n-1<br>$$<br>第$k$个元素为$W_{k}=(i,j)_{k}$，$i,j$分别表示$X,Y$中的坐标，路径长度为路径上的元素和。</p><p>路径需要满足以下条件：</p><h2 id="边界条件"><a href="#边界条件" class="headerlink" title="边界条件"></a>边界条件</h2><p>各序列先后次序不可能改变，所以所选的路径必定是从左下角出发，在右上角结束。即：<br>$$<br>w_{1}=(1,1)\<br>w_{K}=(m,n)<br>$$</p><h2 id="连续性、单调性"><a href="#连续性、单调性" class="headerlink" title="连续性、单调性"></a>连续性、单调性</h2><p>连续性保保证$X$和$Y$中的每个坐标都在$W$中出现，即不可能跨过某个点去匹配，只能和自己相邻的点对齐。单调性限制$W$上面的点必须是随着时间单调进行。综合两个条件：<br>$$<br>w_{k}=(i,j),w_{k+1}=(i’,j’)\<br>i\le i’\le i+1,j\le j’\le j+1<br>$$<br>其中，$i\le i’$保证单调性，$i’\le i+1$保证连续性。如下图所示，对于格点$(i,j)$，下一个格点$(i’,j’)$的可能位置为：<br>$$<br>(i+1,j)\<br>(i,j+1)\<br>(i+1,j+1)<br>$$<br><img src="http://note.lizhihao999.cn/notes/20210714143121.png"></p><p>如图所示，最后要得到距离最短的规整路径，代价矩阵$D$定义为：<br>$$<br>D(i,j)=Dist(i,j)+\min[D(i-1,j),D(i,j-1),D(i-1,j-1)]<br>$$<br>使用动态规划来进行求解。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装PyTorch和PyTorch Geometric</title>
      <link href="2021/07/02/tuo-keng-ji-lu/an-zhuang-pytorch-he-pytorch-geometric/"/>
      <url>2021/07/02/tuo-keng-ji-lu/an-zhuang-pytorch-he-pytorch-geometric/</url>
      
        <content type="html"><![CDATA[<h1 id="1-安装PyTorch"><a href="#1-安装PyTorch" class="headerlink" title="1. 安装PyTorch"></a>1. 安装PyTorch</h1><p>在<a href="https://pytorch.org/">官网</a>选择操作系统、下载方式和对应的GPU配置：</p><p><img src="http://note.lizhihao999.cn/notes/20210701235241.png"></p><p>如果需要之前的版本可以点击下方<a href="https://pytorch.org/get-started/previous-versions/">链接</a>选择之前的版本：</p><p><img src="http://note.lizhihao999.cn/notes/20210701235457.png"></p><p>需要注意对应的CUDA版本号。如何安装、切换多版本CUDA可以参考<a href="http://lizhihao999.cn/2021/07/01/tuo-keng-ji-lu/linux-duo-ban-ben-cuda-an-zhuang-ji-qie-huan/">此前的博客</a>。可通过以下命令查看当前CUDA版本：</p><pre><code class="shell">cat  /usr/local/cuda/version.txt</code></pre><p>下载完成后可以通过以下命令检查torch版本及对应的CUDA版本：</p><pre><code class="shell">python -c "import torch; print(torch.__version__)"python -c "import torch; print(torch.version.cuda)"</code></pre><p>可以通过以下命令查看GPU是否可用：</p><pre><code class="shell">python&gt;&gt;&gt; import torch&gt;&gt;&gt; torch.cuda.is_available()     # GPU是否可用&gt;&gt;&gt; torch.cuda.device_count()    # GPU数量&gt;&gt;&gt; torch.cuda.current_device()    # 当前GPU&gt;&gt;&gt; exit()</code></pre><p>例如：</p><p><img src="http://note.lizhihao999.cn/notes/20210702001140.png"></p><p>注意，GPU devices从0开始编号。</p><h1 id="2-安装PyTorch-Geometric"><a href="#2-安装PyTorch-Geometric" class="headerlink" title="2. 安装PyTorch Geometric"></a>2. 安装PyTorch Geometric</h1><h2 id="2-1-快速安装"><a href="#2-1-快速安装" class="headerlink" title="2.1 快速安装"></a>2.1 快速安装</h2><p>根据<a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html">官网</a>，如果PyTorch版本$\ge1.8.0$，可以快速下载：</p><p><img src="http://note.lizhihao999.cn/notes/20210721155357.png"></p><h2 id="2-2-自定义安装"><a href="#2-2-自定义安装" class="headerlink" title="2.2 自定义安装"></a>2.2 自定义安装</h2><p>自定义下载需要根据当前的PyTorch版本和CUDA版本下载相关的依赖，下载命令如下：</p><pre><code class="shell">pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.htmlpip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.htmlpip install torch-geometric</code></pre><p>其中，<code>${TORCH}</code>替换为当前环境下的PyTorch版本，目前支持<code>1.4.0</code>、<code>1.5.0</code>、<code>1.6.0</code>、<code>1.7.0</code>、<code>1.7.1</code>、<code>1.8.0</code>、<code>1.8.1</code>、和<code>1.9.0</code>；<code>${CUDA}</code>替换为指定的CUDA版本，目前支持<code>cpu</code>、<code>cu92</code>、<code>cu101</code>、<code>cu102</code>、<code>cu110</code>和<code>cu111</code>。</p><p>例如对于PyTorch 1.8.0/1.8.1和CUDA 10.2：</p><pre><code class="shell">pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.htmlpip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.htmlpip install torch-geometric</code></pre><h2 id="2-3-版本依赖"><a href="#2-3-版本依赖" class="headerlink" title="2.3 版本依赖"></a>2.3 版本依赖</h2><p>使用自定义安装时，依然可能会出现安装失败的问题，因为pytorch geometric几个相关库之间有比较强的依赖关系，建议是在自定义安装的基础上指定对应库的版本，例如对于<code>pytorch==1.4.0</code>和<code>cuda==10.1</code>：</p><pre><code class="shell">pip install torch-scatter==2.0.4 -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.htmlpip install torch-cluster==1.5.4 -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.htmlpip install torch-sparse==0.6.1 -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.htmlpip install torch-spline-conv==1.2.0 -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.htmlpip install torch-geometric==1.6.0 -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html</code></pre><p>每个库的版本信息可以在GitHub上的release页找到，例如：</p><p><img src="http://note.lizhihao999.cn/notes/20210721160038.png"></p><p>几个相关库的GitHub地址如下：</p><ul><li><a href="https://github.com/rusty1s/pytorch_cluster/releases">pytorch_cluster</a></li><li><a href="https://github.com/rusty1s/pytorch_sparse/releases">pytorch_sparse</a></li><li><a href="https://github.com/rusty1s/pytorch_scatter/releases">pytorch_scatter</a></li><li><a href="https://github.com/rusty1s/pytorch_geometric/releases">pytorch_geometric</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux多版本CUDA安装及切换</title>
      <link href="2021/07/01/tuo-keng-ji-lu/linux-duo-ban-ben-cuda-an-zhuang-ji-qie-huan/"/>
      <url>2021/07/01/tuo-keng-ji-lu/linux-duo-ban-ben-cuda-an-zhuang-ji-qie-huan/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Linux安装cuda"><a href="#1-Linux安装cuda" class="headerlink" title="1. Linux安装cuda"></a>1. Linux安装cuda</h1><h2 id="1-下载CUDA"><a href="#1-下载CUDA" class="headerlink" title="1. 下载CUDA"></a>1. 下载CUDA</h2><p>根据需要选择对应的CUDA Toolkit版本<a href="https://developer.nvidia.com/cuda-toolkit-archive">下载</a>：</p><p><img src="http://note.lizhihao999.cn/notes/20210701142824.png"></p><p>选择自己对应的操作系统、结构、系统版本等之后，根据命令进行下载：</p><p><img src="http://note.lizhihao999.cn/notes/20210701150049.png"></p><p>如果不知道对应信息可以通过第二点进行查看。<strong>推荐下载runfile</strong>，可以直接跳到第三点讲解如何安装。</p><h2 id="2-确认系统版本"><a href="#2-确认系统版本" class="headerlink" title="2. 确认系统版本"></a>2. 确认系统版本</h2><p>选择对应系统的下载教程：</p><p><img src="http://note.lizhihao999.cn/notes/20210701143208.png"></p><p>按照官方文档的指引，确认自己的系统和GPU是否满足条件。</p><h3 id="1-确认GPU"><a href="#1-确认GPU" class="headerlink" title="1. 确认GPU"></a>1. 确认GPU</h3><p>首先确认GPU是否支持CUDA，对照<a href="https://developer.nvidia.com/zh-cn/cuda-gpus">官方列表</a>，通过以下命令查看自己的GPU：</p><pre><code class="shell">lspci | grep -i nvidia</code></pre><p><img src="http://note.lizhihao999.cn/notes/20210701144448.png"></p><h3 id="2-确认Linux系统版本"><a href="#2-确认Linux系统版本" class="headerlink" title="2. 确认Linux系统版本"></a>2. 确认Linux系统版本</h3><p>通过以下命令查看自己的系统版本：</p><pre><code class="shell">uname -m &amp;&amp; cat /etc/*release</code></pre><p><img src="http://note.lizhihao999.cn/notes/20210701144740.png"></p><p>主要注意以上两个信息，对比文档中给出的表格：</p><img src="http://note.lizhihao999.cn/notes/20210701144857.png" style="zoom:80%;"><h3 id="3-确认安装gcc"><a href="#3-确认安装gcc" class="headerlink" title="3. 确认安装gcc"></a>3. 确认安装gcc</h3><p>使用CUDA Toolkit进行开发需要gcc编译器，它通常是作为Linux安装的一部分安装的。可通过以下命令确认：</p><pre><code class="shell">gcc --version</code></pre><h3 id="4-确认系统有正确的内核头文件和正确的依赖包"><a href="#4-确认系统有正确的内核头文件和正确的依赖包" class="headerlink" title="4. 确认系统有正确的内核头文件和正确的依赖包"></a>4. 确认系统有正确的内核头文件和正确的依赖包</h3><p>文档给出不同Linux系统的安装命令，比如Ubuntu：</p><pre><code class="shell">sudo apt-get install linux-headers-$(uname -r)</code></pre><h2 id="3-Runfile安装"><a href="#3-Runfile安装" class="headerlink" title="3. Runfile安装"></a>3. Runfile安装</h2><p>下载好runfile文件之后，根据之前给出的指令进行安装：</p><pre><code class="shell">sudo sh cuda_10.1.243_418.87.00_linux.run</code></pre><h2 id="4-修改环境变量"><a href="#4-修改环境变量" class="headerlink" title="4. 修改环境变量"></a>4. 修改环境变量</h2><p>下一节讲解如何通过软连接进行不同版本cuda之间的切换，在环境变量中只用指向一个软连接的文件夹<code>cuda</code>即可，首先编辑环境变量：</p><pre><code class="shell">vim ~/.bashrc</code></pre><p>在末尾添加：</p><pre><code class="shell">export PATH=$PATH:/usr/local/cuda-10.0/binexport CUDA_HOME=$CUDA_HOME:/usr/local/cuda</code></pre><p>修改之后需要使环境变量生效：</p><pre><code class="shell">source ~/.bashrc</code></pre><h2 id="5-查看cuda安装状态"><a href="#5-查看cuda安装状态" class="headerlink" title="5. 查看cuda安装状态"></a>5. 查看cuda安装状态</h2><p>查看cuda-toolkit是否安装成功：</p><pre><code class="shell">nvcc -V</code></pre><p>查看显卡驱动运行情况：</p><pre><code class="shell">nvidia-smi</code></pre><h1 id="2-Linux多版本cuda切换"><a href="#2-Linux多版本cuda切换" class="headerlink" title="2. Linux多版本cuda切换"></a>2. Linux多版本cuda切换</h1><p>当我们安装了多个版本的cuda时，可以将每个版本的cuda放在对应版本命名的文件夹<code>cuda-x.x</code>下，在建立一个CUDA的软连接，环境变量的路径直接指向CUDA的软连接，切换CUDA版本时只用删除当前的软连接，再指向需要版本的软连接即可。</p><h2 id="1-建立软连接"><a href="#1-建立软连接" class="headerlink" title="1. 建立软连接"></a>1. 建立软连接</h2><p>cuda一般安装在 /usr/local/路径下，首先进入该文件夹并建立一个空的<code>cuda</code>文件夹：</p><pre><code class="shell">cd /usr/localsudo mkdir cuda</code></pre><p>然后建立软连接，以<code>cuda-9.2</code>为例：</p><pre><code class="shell">sudo ln -s cuda-9.2 cuda</code></pre><p>查看<code>cuda</code>文件夹下的version.txt文档，里面记录了cuda的版本信息：</p><pre><code class="shell">cat  cuda/version.txt</code></pre><p><img src="http://note.lizhihao999.cn/notes/20210718235109.png"></p><p>可以通过<code>stat</code>命令查看当前的cuda信息：</p><pre><code class="shell">stat cuda</code></pre><p><img src="http://note.lizhihao999.cn/notes/20210701140523.png"></p><h2 id="2-切换软连接"><a href="#2-切换软连接" class="headerlink" title="2. 切换软连接"></a>2. 切换软连接</h2><p>查看我们的所有的cuda版本，默认保存在/usr/local路径下：</p><pre><code class="shell">cd /usr/localls</code></pre><p><img src="http://note.lizhihao999.cn/notes/20210701140137.png"></p><p>这里我安装有三个版本。可以更改symbolic link，使其指向其他版本的cuda，例如10.0：</p><pre><code class="shell">rm -rf cudaln -s cuda-10.0 cuda</code></pre><p>再次查看cuda版本和软连接情况：</p><p><img src="http://note.lizhihao999.cn/notes/20210718235323.png"></p><p>看到已经切换到10.0版本的cuda了。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ubuntu </tag>
            
            <tag> cuda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Variational Graph Auto-encoder</title>
      <link href="2021/05/14/lun-wen-bi-ji/gnn/2016-nips-variational-graph-auto-encoders/"/>
      <url>2021/05/14/lun-wen-bi-ji/gnn/2016-nips-variational-graph-auto-encoders/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/abs/1611.07308">论文地址</a></p><p><a href="https://github.com/tkipf/gae">tensorflow-代码地址</a></p><p><a href="https://github.com/DaehanKim/vgae_pytorch">pytorch-代码地址</a></p></blockquote><p>这是一篇2016年NIPS的workshop，介绍了变分图自动编码器（VGAE），它是一种基于变分自动编码器（VAE）的无监督学习图结构化数据的框架。 该模型利用了潜在变量，并且能够为无向图学习可解释的潜在表示（请参见图1）。</p><p><img src="http://note.lizhihao999.cn/notes/20210514101222.png" alt="图1"></p><blockquote><p>在Cora引用网络数据集上训练的无监督VGAE模型的潜在空间。 </p><p>灰线表示引文链接。 颜色表示文档类别（训练期间未提供）。</p></blockquote><p>我们使用图卷积网络（GCN）编码器和一个简单的内积解码器演示了该模型。 我们的模型在引用网络中的链接预测任务上获得了具有竞争力的结果。 与大多数现有的无监督学习图形结构数据和链接预测模型相比，我们的模型可以自然地包含节点特征，从而显着提高了许多基准数据集的预测性能。</p><p><img src="http://note.lizhihao999.cn/notes/20210514101249.png" alt="形象化"></p><p>对于上图过程，可以看到变分自编码器学习<strong>低维向量表示的分布</strong>，包含一个Encoder和一个Decoder, 主要用于推理模型。其中Encoder把input变成概率分布，从概率分布中采样得到隐变量Z，Decoder把这个隐变量Z变成output。</p><h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>一个无边，无权重的图：<br>$$<br>G=(V,E)\quad with\quad N=|V|;nodes<br>$$</p><ul><li>邻接矩阵$A$，对角线元素为1</li><li>度矩阵$D$</li></ul><p>随机潜在向量$z_{i}$，由矩阵$Z(N\times F)$统一，结点特征向量矩阵$X(N\times D)$。</p><h2 id="推理模型"><a href="#推理模型" class="headerlink" title="推理模型"></a>推理模型</h2><p>通过一个两层GCN进行参数化：<br>$$<br>q(Z|X,A)=\prod_{i=1}^{N}{q(\vec{z_{i}}|X,A)}\quad with\quad q=(\vec{z_{i}}|X,A)=N(\vec{z_{i}}|\vec{\mu_{i}},\mathrm{diag}(\vec{\sigma_{i}}^{2}))<br>$$<br>其中，$\mu=GCN_{\mu}(X,A)$是均值向量$\mu_{i}$的矩阵；$\log{\sigma}=GCN_{\sigma}(X,A)$是方差向量的矩阵；$N(\cdot)$代表服从高斯分布。</p><p>两层GCN定义为：<br>$$<br>\mathrm{GCN}(X,A)=\mathrm{\tilde{A}}\mathrm{ReLU}(\mathrm{\tilde{A}XW_{0}})\mathrm{W_{1}}<br>$$<br>其中，$W_{i}$是每一层的权重矩阵，上述两个GCN共享第一层的权重矩阵$W_{0}$。</p><ul><li><p>线性整流函数$\mathrm{RuLU}(\cdot)=\max{(0,\cdot)}$</p></li><li><p>对称归一化邻接矩阵$\tilde{A}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$</p></li></ul><h2 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h2><p>通过两个潜在向量之间的内积给出：<br>$$<br>p(\mathrm{A|Z})=\prod_{i=1}^{N}{\prod_{j=1}^{N}{p(A_{ij}|\vec{z}<em>{i},\vec{z}</em>{j})}}\quad with\quad p(A_{ij=1}|\vec{z}<em>{i},\vec{z}</em>{j})=\sigma(\vec{z}<em>{i}^{T}\vec{z}</em>{j})<br>$$<br>其中$A_{ij}$是矩阵$\mathrm{A}$中的元素，$\sigma(\cdot)$是logistic sigmoid激活函数。</p><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><p>针对变量参数$\bold{W}<em>{i}$优化变量下限$L$：<br>$$<br>L=E</em>{q(Z|A,X)}[\log{p(A|Z)}]-\mathrm{KL}[q(Z|X,A)||p(Z)]<br>$$<br>其中：</p><ul><li><p>$E_{q}[\cdot]$是均值；</p></li><li><p>$\mathrm{KL}[q(\cdot)||p(\cdot)]$是$q(\cdot),p(\cdot)$之间的Kullback-Leibler divergence（相对熵）。相对熵可以衡量两个随机分布之间的距离，当两个随机分布相同时，它们的相对熵为零，当两个随机分布的差别增大时，它们的相对熵也会增大。</p></li></ul><p>进一步采用高斯平滑：<br>$$<br>p(Z)=\prod_{i}{p(z_{i})}=\prod_{i}{N(z_{i}|0,I)}<br>$$<br>我们执行批量梯度下降，并利用重新参数化技巧进行训练。 对于无特征的方法，我们只需放弃对X的依赖关系，然后用GCN中的单位矩阵替换X。</p><h2 id="非概率图自动编码器（GAE）模型"><a href="#非概率图自动编码器（GAE）模型" class="headerlink" title="非概率图自动编码器（GAE）模型"></a>非概率图自动编码器（GAE）模型</h2><p>对于VGAE模型的非概率变体，我们计算嵌入Z和重构的邻接矩阵$\tilde{A}$，如下所示：<br>$$<br>\tilde{A}=\sigma(ZZ^{T})\quad with\quad Z=\mathrm{GCN(X,A)}<br>$$</p><h1 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读"></a>代码解读</h1><p>对于<code>pytorch</code>版本的代码进行一定的解读。</p><h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><pre><code class="python"># model.py: class VGAEdef encode(self, X):        hidden = self.base_gcn(X)        self.mean = self.gcn_mean(hidden)    # 均值GCN        self.logstd = self.gcn_logstddev(hidden)    # 方差GCN        gaussian_noise = torch.randn(X.size(0), args.hidden2_dim)    # 随机采样        sampled_z = gaussian_noise*torch.exp(self.logstd) + self.mean    # 采样还原z'        return sampled_z</code></pre><p>Encoder把input变成概率分布，并从概率分布中采样得到隐变量Z。</p><h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><pre><code class="python"># model.py: class VGAEdef forward(self, X):        Z = self.encode(X)        A_pred = dot_product_decode(Z)    # decode        return A_pred# model.pydef dot_product_decode(Z):    A_pred = torch.sigmoid(torch.matmul(Z,Z.t()))    return A_pred</code></pre><p>通过Z和Z转置的点积，可以得到一个对称矩阵，再通过sigmoid函数，可以得到最终的output。</p><h2 id="train"><a href="#train" class="headerlink" title="train"></a>train</h2><pre><code class="python">for epoch in range(args.num_epoch):    ...    loss = log_lik = norm*F.binary_cross_entropy(A_pred.view(-1), adj_label.to_dense().view(-1), weight = weight_tensor)    # 通过交叉熵得到输出矩阵和实际连接矩阵的相似度（结构性）    if args.model == 'VGAE':        kl_divergence = 0.5/ A_pred.size(0) * (1 + 2*model.logstd - model.mean**2 - torch.exp(model.logstd)**2).sum(1).mean()        # 通过相对熵得到理论分布拟合真实分布时产生的信息损耗        loss -= kl_divergence    loss.backward()    optimizer.step()    ...</code></pre><p>根据公式，L由两部分构成，第一部分为输出矩阵和实际连接矩阵的交叉熵，即两者之间的相似度。连接矩阵反应不同点之间的连接情况，也是一个对称矩阵。第二部分是两个分布之间的相对熵，表示两个分布之间的距离。最终的损失函数为两者之差。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> NIPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>知识图谱概念</title>
      <link href="2021/03/12/zhi-shi-tu-pu/zhi-shi-tu-pu-gai-nian/"/>
      <url>2021/03/12/zhi-shi-tu-pu/zhi-shi-tu-pu-gai-nian/</url>
      
        <content type="html"><![CDATA[<p>逐步总结知识图谱相关知识，包括知识图谱概念、知识图谱构建、知识图谱嵌入和知识图谱应用。</p><h1 id="1-知识"><a href="#1-知识" class="headerlink" title="1. 知识"></a>1. 知识</h1><p>​        知识是人们在改造客观世界的过程中所积累的经验和总结升华的产物。知识作为人类对客观世界认识的表达，具有相对的正确性、局限性和抽象性。相比人类的知识，我们这里的知识特指用计算机可以表示、存储和计算的一种特殊信息。具体来说，人类社会生活产生了海量的数据，这些数据可以作为人工智能模型最原始和最基础的输入。其中存在大量无用的内容和噪声，在此之上经过处理提取出的有用的、相关的数据，称为<strong>信息</strong>。这些信息可以是<strong>结构化</strong>的、<strong>半结构化</strong>的或<strong>标签化</strong>的。</p><p>​        在此之上，对信息进一步的加工和处理所得到的普适、抽象和正确的信息，被称为<strong>知识</strong>，如某个领域的概念、概念之间的关系、概念的属性、实体的描述及规则等。因此，知识是蕴含在数据中的经过凝练的数据和信息，通过知识，可以更好地理解信息，可以推理更多的知识，并对未知的信息做出预测，从而体现出系统的智能性。</p><p><img src="https://ss0.baidu.com/6ON1bjeh1BF3odCf/it/u=3635028704,2156301383&amp;fm=15&amp;gp=0.jpg"></p><h1 id="2-知识图谱"><a href="#2-知识图谱" class="headerlink" title="2. 知识图谱"></a>2. 知识图谱</h1><p>​        知识图谱在学术界没有一致的定义，目前知识图谱泛指当前基于通用语义知识的形式化描述而组织的人类知识系统。这个系统本质上是一个有向、有环的复杂的图结构。其中，图的节点表示语义符号，节点之间的边表示符号之间的关系。总的来说，一个知识图谱（KG， Knowledge Graph）存储大量三元组形式的实体以及实体关系信息。在知识图谱系统中，不论是知识框架还是实体数据的描述都统一采用三元组的形式。知识图谱$G=(E,R,S)$，其中$E=\lbrace e_{1},e_{2},…,e_{|E|}\rbrace$表示知识库中的实体集合，共包含$|E|$种不同的实体；$R=\lbrace r_{1},r_{2},…,r_{|R|} \rbrace$是知识库中的关系集合，共包含$|R|$种不同的关系；$S\subseteq E\times R\times E$代表知识库中实体和关系的三元组集合。</p><p>​        知识图谱中的三元组使用RDF（Resource Description Framework），即资源描述框架来表示的。RDF本质上是一个数据模型，提供了一个统一的标准来描述web上的资源，也可以用来描述知识图谱。RDF在形式上表示为SPO三元组，即Subject，Predicate，Object三元组或借助图结构表示为$(h,r,t)$，即头实体（Head Entity）、关系（Relation）和尾实体（Tail Entity）的三元组。三元组也称为一条语句，在知识图谱中记为一条知识。</p><p>当前，公开的大规模知识图谱主要有：Freebase、DBpedia、YAGO、NELL、Wikidata等。中文的知识图谱有openKG、cnSchema、cnDBpedia及zhishi.me等。这些知识图谱都是按照三元组的二元关系进行描述，有比较严格和完整的Schema定义结构。</p><p><strong>参考资料：</strong></p><ol><li>人工智能知识图谱前沿技术. 朱小燕，李晶，肖寒，黄民烈. 中国工信出版集团，电子工业出版社.</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Knowledge Graph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识图谱 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib中文显示</title>
      <link href="2021/01/11/tuo-keng-ji-lu/matplotlib-zhong-wen-xian-shi/"/>
      <url>2021/01/11/tuo-keng-ji-lu/matplotlib-zhong-wen-xian-shi/</url>
      
        <content type="html"><![CDATA[<p>在脚本开始处进行如下设置：</p><pre><code class="python">plt.rcParams['font.family'] = ['sans-serif']plt.rcParams['font.sans-serif'] = ['SimHei']</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络CNN</title>
      <link href="2020/12/11/cnn/"/>
      <url>2020/12/11/cnn/</url>
      
        <content type="html"><![CDATA[<p>卷积神经网络（Convolutional neural network， ConvNets or CNNs），是一种深度学习算法，可以输入图像，为图像中的各个方面/对象分配重要性（可学习的权重和偏差），并能够区分彼此。主要用于图像识别、图像分类任务，可以应用于目标检测、人脸识别等领域。</p><h1 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h1><p>对于计算机来说，一张输入的图片是以像素数组（array of pixels）的形式呈现，数组大小由图片的分辨率决定。对于一张图片来说，像素数组通常有3个维度：<br>$$<br>(h\times w\times d)\<br>\begin{align}<br>&amp;h:Height\quad高度\<br>&amp;w:Width\quad宽度\<br>&amp;d:Dimension\quad维度<br>\end{align}<br>$$<br>对于RGB标准的图片来说，通过对红(R)、绿(G)、蓝(B)三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色，所以维度有三层，分别对应三个颜色的通道。而对于一张灰度图像来说，维度通常只有一层。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233045.png" alt="4x4x3 RGB Image"></p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>卷积神经网络（CNN或ConvNet）是一种用于深度学习的网络体系结构，可直接从数据中学习，而无需手动提取特征。ConvNet的架构类似于人脑中神经元的连接模式，其灵感来自于视觉皮层的组织。 单个神经元仅在被称为感受野的视野受限区域内对刺激做出反应。 这些字段的集合重叠以覆盖整个可视区域。</p><p>从技术上讲，深度学习CNN模型可以用于训练和测试，与其他神经网络一样，CNN也由输入层、输出层和之间的很多隐藏层组成。这些隐藏层执行更改数据的操作，目的是学习数据的特征。最常见的三个层是：卷积、激活函数或ReLU和池化。每个输入图像将通过一系列带有卷积核Filters（内核Kernels）、池化Pooling、全连接层（FC）的卷积层传递，并应用Softmax函数对概率值为$(0,1)$之间的对象进行分类。</p><ul><li><p>卷积将输入图像通过一组卷积核，每个卷积核都会激活图像中的某些特征；</p></li><li><p>线性整流单元（ReLU）通过将负值映射为零并保持正值，可以更快，更有效地进行训练。有时将其称为激活，因为只有激活的特征才被带入下一层；</p></li><li><p>池化通过执行非线性下降采样来简化输出，从而减少了网络需要学习的参数数量；</p></li></ul><p>下图是一个具有许多卷积层的CNN示例，将卷积核以不同的分辨率（尺寸）应用于每个训练图像，并将每个卷积图像的输出用作下一层的输入。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233101.jpg" alt="Example of a network with many convolutional layers. Filters are applied to each training image at different resolutions, and the output of each convolved image is used as the input to the next layer."></p><h1 id="隐藏层：特征学习"><a href="#隐藏层：特征学习" class="headerlink" title="隐藏层：特征学习"></a>隐藏层：特征学习</h1><p>卷积神经网络中通过隐藏层进行特征学习，单个隐藏层通常包含的三个层是：卷积层、激活函数或ReLU和池化层。</p><h2 id="卷积层-Convolution-Layer"><a href="#卷积层-Convolution-Layer" class="headerlink" title="卷积层 Convolution Layer"></a>卷积层 Convolution Layer</h2><p>卷积是从输入图像的第一层，以提取特征。 卷积通过使用输入数据的小方块学习图像特征来保留像素之间的关系。 这是一项数学运算，需要两个输入，例如图像矩阵和卷积核（内核）。</p><p>在每个卷积层，数据都是以三维形式存在的，可以把它看成许多个二维图片叠在一起，其中每一个称为一个特征图feature map。如果是灰度图片，那就只有一个feature map；如果是彩色图片，一般就是3个feature map（RGB）。层与层之间会有若干个卷积核，上一层和每个feature map跟每个卷积核做卷积，都会产生下一层的一个feature map。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233153.png" alt="Image matrix multiplies kernel or filter matrix"></p><h3 id="步长-Stribes"><a href="#步长-Stribes" class="headerlink" title="步长 Stribes"></a>步长 Stribes</h3><p>卷积核以某个“步长”（Stride Value）向右移动，直到解析完整宽度为止，它将跳至具有相同“步长”的图像的开始（左侧），并重复该过程，直到遍历整个图像为止。 当步长为1时，我们一次将卷积核移动1个像素。 当步长为2时，我们一次将卷积核移动2个像素，依此类推。 </p><p><img src="http://note.lizhihao999.cn/notes/20201211233201.png" alt="Movement of the Kernel"></p><p>在下面的演示中，将5 x 5 x 1图像矩阵的卷积与3 x 3 x 1卷积核矩阵相乘，称为“特征图”（feature map）。绿色部分类似于我们的5x5x1输入图像I。在卷积层的第一部分中执行卷积运算所涉及的元素称为内核/卷积核K，以黄色表示，我们选择K作为3x3x1矩阵。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233249.png" alt=" Image matrix multiplies kernel or filter matrix"></p><p>由于步长= 1（不跨步），内核每次移位9次，每次在K与内核所徘徊的图像I中部分P之间执行矩阵乘法运算。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233308.gif" alt="Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature"></p><p>对于具有多个通道的图像（例如RGB），内核的深度与输入图像的深度相同。 在Kn和堆栈内（[K1，I1]； [K2，I2]； [K3，I3]）之间执行矩阵乘法，所有结果与偏差相加，得到一个压缩的单深度通道卷积特征输出。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233319.gif" alt="Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel"></p><h3 id="填充-Padding"><a href="#填充-Padding" class="headerlink" title="填充 Padding"></a>填充 Padding</h3><p>有时执行操作时，卷积核无法完全适合输入图像，有两种填充方法：</p><ol><li><strong>Same Padding</strong>：用零填充图片（零填充），使其适合；</li><li><strong>Valid Padding</strong>：删除图像中不适合卷积核的部分，这称为有效填充，仅保留图像的有效部分。</li></ol><p>第一种方法下通常会让输出维数增加或保持不变，例如下图所示，当我们将5x5x1图像扩充为6x6x1图像，然后在其上应用3x3x1内核时，我们发现卷积矩阵的尺寸为5x5x1。 因此，名称为“相同填充”（Same Padding）。第二种方法，会保留和卷积核相同维度的一个矩阵，称为“有效填充”（Valid Padding）。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233327.gif" alt="**SAME padding:** 5x5x1 image is padded with 0s to create a 6x6x1 image"></p><h2 id="线性整流单元-ReLU"><a href="#线性整流单元-ReLU" class="headerlink" title="线性整流单元 ReLU"></a>线性整流单元 ReLU</h2><p>线性整流单元（Rectified Linear Unit，ReLU），用于非线性操作。通常意义下，线性整流函数指代数学中的斜坡函数，即函数输出结果为：<br>$$<br>f(x)=\max{(0,x)}<br>$$<br><img src="http://note.lizhihao999.cn/notes/20201212005722.png" alt="ReLU"></p><p>而在神经网络中，线性整流作为神经元的激活函数，定义了该神经元在线性变换$\bold{w^{T}x}+b$之后的非线性输出结果，即对于进入神经元的来自上一层神经网络的输入向量，使用线性整流激活函数的神经元会输出：<br>$$<br>\max{(0,\bold{w^{T}x}+b)}<br>$$<br>至下一层神经元或作为整个神经网络的输出（取决现神经元在网络结构中所处位置）。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233403.png" alt="ReLU operation"></p><p>为什么ReLU很重要：ReLU的目的是在我们的ConvNet中引入非线性。 因为，现实世界中的数据希望我们的ConvNet学习的是非负线性值。 还有其他一些非线性函数（例如tanh或Sigmoid）也可以代替ReLU使用。 大多数数据科学家都使用ReLU，因为在性能方面ReLU比其他两个要好。</p><h2 id="池化层-Pooling-Layer"><a href="#池化层-Pooling-Layer" class="headerlink" title="池化层 Pooling Layer"></a>池化层 Pooling Layer</h2><p>与卷积层相似，池化层负责减小卷积特征的空间大小，即通过降维来减少处理数据所需的计算能力的同时保留重要信息。 此外，它对于提取旋转和位置不变的主要特征很有用，从而保持有效训练模型的过程。 池化有不同的方法，最基本、最常见的方法有两类：</p><ul><li>最大池化（Max Pooling）</li><li>平均池化（Average Pooling）</li></ul><p>“最大池化”从内核覆盖的图像部分返回最大值，“平均池化”从内核覆盖的图像部分返回所有值的平均值。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233410.png" alt="Types of Pooling"></p><p>Max Pooling还可以充当噪声抑制器，它完全放弃激活噪声（只保留最大值），并且还执行了降噪以及降维。 而平均池化仅执行降维作为噪声抑制机制。 因此，我们可以说“最大池”的性能要比“平均池”好得多。下图为3x3的卷积核在5x5卷积上执行池化。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233419.gif" alt="3x3 pooling over 5x5 convolved feature"></p><p>卷积层和池化层一起形成了卷积神经网络的第i层（隐藏层）。根据图像的复杂性，可以增加这种层的数量以进一步捕获更低粒度的特征，但是以更大的计算能力为代价。</p><h1 id="分类功能"><a href="#分类功能" class="headerlink" title="分类功能"></a>分类功能</h1><p>我们需要将得到的矩阵扁平化为向量，再将其输入一个全连接层（例如要一个神经网络）。添加全连接层是学习卷积层输出所表示的高级特征的非线性组合的（通常）方便快捷的方法。 全连接层可以学习该空间中可能存在的非线性函数。</p><p><img src="http://note.lizhihao999.cn/notes/20201211233428.jpeg" alt="Classification — Fully Connected Layer"></p><p>经过一系列卷积（隐藏层），我们已经将输入图像转换为适合多层次感知器的形式，我们将把图像展平为列向量 (x1, x2, x3, …)。 扁平化后的输出作为前馈神经网络的输入，将反向传播应用于训练的每次迭代。 经过一系列epoch后，该模型能够区分图像中的主要特征和某些低级特征，并使用Softmax分类技术对其进行分类（输出层）。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><img src="http://note.lizhihao999.cn/notes/20201211233101.jpg" alt="完整的卷积神经网络图"></p><p>学习完之后，再回顾一下这副卷积神经网络进行图像分类的图例，应该对卷积神经网络的结构和进行图像分类的流程比较了解了。流程大致如下：</p><ol><li>提供输入图像到卷积层；</li><li>选择参数，根据“步长”应用卷积核，如果需要，使用填充方法；</li><li>在图像上执行卷积，并将ReLU激活应用于矩阵；</li><li>执行池化以减小维数大小；</li><li>添加尽可能多的卷积层直到满意；</li><li>展平输出并馈入完全连接的层（FC层）；</li><li>使用激活函数输出并分类图像。</li></ol><p>一般来说，可以认为一个卷积神经网络的前半部分为卷积（包括池化）进行特征学习，后半部分为一个分类器（一个或多个全连接层）。关于如何确定CNN中的卷积核大小、卷积层数以及每层feature map个数，目前还没有一个理论性很强的解释，更多的是在根据已有的经验设计，或者利用自动搜索的方法搜索出较为合适的取值。</p><p>之后会更新如何使用<code>Python</code>实现CNN模型。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way</a></p><p><a href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148">Understanding of Convolutional Neural Network (CNN) — Deep Learning</a></p><p><a href="https://www.mathworks.com/discovery/convolutional-neural-network-matlab.html">Convolutional Neural Network</a></p><p><a href="https://baike.baidu.com/item/ReLU%20%E5%87%BD%E6%95%B0/22689567?fr=aladdin">百度百科：ReLU函数</a></p><p><a href="https://blog.csdn.net/boon_228/article/details/81238091">理解卷积神经网络CNN中的特征图 feature map</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Neural Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Embedding 图嵌入简述</title>
      <link href="2020/11/28/tu-qian-ru-graph-embedding/"/>
      <url>2020/11/28/tu-qian-ru-graph-embedding/</url>
      
        <content type="html"><![CDATA[<h1 id="图嵌入-Graph-Embedding"><a href="#图嵌入-Graph-Embedding" class="headerlink" title="图嵌入 Graph Embedding"></a>图嵌入 Graph Embedding</h1><p>图嵌入是将图中的结点、边、关系映射到更低维度的向量空间，同时最大化地保留特征信息，例如图结构以及信息。由于图的规模、特征和主题不同，同时，图类型的数据是离散的，所以对于图的处理是很困难的。</p><blockquote><p>理由：</p><ol><li>用于图的机器学习算法有限</li><li>编码能够压缩数据</li><li>向量运算更简单、快速</li></ol></blockquote><p>如果将嵌入（Embedding）看作一种向低维的变换（transformation），则嵌入方法本身并不是一种神经网络模型（neural network model）。相反，嵌入是一种将图转换为可计算形式（computationally）的预处理算法（pre-processing algorithm）。</p><blockquote><p>挑战：</p><ol><li><p>确保嵌入能够保留足够图的信息</p><p>图形拓扑、节点连接和节点邻域</p></li><li><p>网络的大小不能减慢嵌入速度</p><p>高效处理大型图表</p></li><li><p>确定嵌入维度</p><p>高维能够保留更多信息但是增加时间和空间复杂度，需要折中考虑</p></li></ol></blockquote><p>现在有多种方式实现图嵌入，每种方法都有不同的粒度等级。嵌入能够实施于结点层级、子图层级或者通过图遍历这样的策略进行实施。</p><h1 id="遍历嵌入法-Walk-embedding"><a href="#遍历嵌入法-Walk-embedding" class="headerlink" title="遍历嵌入法 Walk embedding"></a>遍历嵌入法 Walk embedding</h1><h2 id="DeepWalk"><a href="#DeepWalk" class="headerlink" title="DeepWalk"></a>DeepWalk</h2><blockquote><p><a href="https://arxiv.org/pdf/1403.6652.pdf">论文地址</a></p><p><a href="https://github.com/phanein/deepwalk">代码地址</a></p></blockquote><p>DeepWalk是第一个被广泛用作基准（Benchmark）的图学习方法。DeepWalk通过遍历（walk）来实现嵌入。如果用任意表示向量来表示图中的每个节点，则可以遍历该图。该遍历的步骤可以通过在矩阵中排列相邻的节点表示向量来进行聚合。</p><p>DeepWalk使用以下公式来完成一系列的随机遍历：<br>$$<br>Pr(v_i|(\Phi(v_1),\Phi(v_2),…,\Phi(v_{i-1})))<br>$$<br>目标是估计观察结点$v_i$的可能性，其中$Pr()$代表概率，$\Phi$表示图中每个结点$v$的潜在表示。潜在表示将会成为神经网络的输入，神经网络建立在结点的特点和行走过程中遇见结点的概率，能够预测结点的特征或分类。</p><p><img src="http://note.lizhihao999.cn/notes/20201109110934.png"></p><p>预测的方法为<strong>skip-gram</strong>（与Word2vec相同）。DeepWalk通过遍历整个图来学习得到一个嵌入。模型可以通过一个靶结点来进行预测“context”，即一张图的关联性，结构规则和节点特征。</p><p>DeepWalk是直推式（transductive）的方法，即每添加一个新结点都需要重新训练模型。</p><h2 id="Node2vec"><a href="#Node2vec" class="headerlink" title="Node2vec"></a>Node2vec</h2><blockquote><p><a href="https://cs.stanford.edu/people/jure/pubs/node2vec-kdd16.pdf">论文地址</a></p><p><a href="https://github.com/aditya-grover/node2vec">代码地址</a></p></blockquote><p>Node2vec和DeepWalk的之间的区别差之毫厘，却谬以千里。Node2vec通过变量α决定（bias）遍历路径，其中α由参数p和q决定。参数p优先考虑BFS的过程，参数q优先考虑DFS的过程。下一步路径的决定由概率$1/p$或$1/q$决定。</p><img src="http://note.lizhihao999.cn/notes/20201105173741.png" style="zoom:80%;"><p>如图所示，BFS可以更多地学习本地邻居结点的信息(local neighbors)，DFS可以学习到更多的全局变量（global variables）。Node2vec可以根据任务不同来切换两种优先级，即对于不同的参数值，会产生不同的结果。与DeepWalk相同，Node2vec同样使用潜在嵌入并作为神经网络的输入来分类结点。</p><p>BFS更擅长根据结构部分(枢纽、桥梁、离群点等)进行分类，而DFS返回的是更具社区驱动的分类方案。</p><h2 id="Graph2vec"><a href="#Graph2vec" class="headerlink" title="Graph2vec"></a>Graph2vec</h2><blockquote><p><a href="https://arxiv.org/abs/1707.05005">论文地址</a></p><p><a href="https://github.com/benedekrozemberczki/graph2vec">代码地址</a></p></blockquote><p>Graph2vec是对Node2vec变体的一种修改，本质上是学习嵌入图的子图。Doc2vec中使用的一个方程证明了这一点，这是一个密切相关的变体，也是本文的一个灵感点。<br>$$<br>Pr(w_j|d)=\frac{exp(d\cdot w_j)}{\sum_{w\in v}{exp(d\cdot w)}}<br>$$<br>该等式可写为：单词（$w_j$）出现在给定文档（d）的上下文中的概率等于文档嵌入矩阵（d〜）的指数乘以单词嵌入矩阵（w〜j从文档中取样），然后除以文档嵌入矩阵的所有指数之和再乘以所有文档中词汇表（V）中每个单词的单词嵌入矩阵。</p><p>与word2vec进行类比，如果文档由句子组成（然后由单词组成），则图由子图组成（然后由节点组成）。这些预定的子图具有用户指定的一组边数，同样的，将潜在的子图嵌入传递到神经网络中进行分类。</p><h1 id="相似度嵌入法-Proximity-embedding"><a href="#相似度嵌入法-Proximity-embedding" class="headerlink" title="相似度嵌入法 Proximity embedding"></a>相似度嵌入法 Proximity embedding</h1><h2 id="SDNE"><a href="#SDNE" class="headerlink" title="SDNE"></a>SDNE</h2><blockquote><p><strong>Structural Deep Network embedding</strong></p><p><a href="https://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf">论文地址</a></p><p>[代码地址](<a href="https://github.com/suanrong/SDNE">suanrong/SDNE: This is a implementation of SDNE (Structural Deep Network embedding) (github.com)</a>)</p></blockquote><p>与遍历嵌入法不同，SDNE尝试学习两类独立的指标：</p><ol><li>一阶相似：两个节点具有相似性，如果它们共享同一条边（pairwise similarity）；</li><li>二阶相似：两个节点具有相似性，如果它们共享很多相邻节点。</li></ol><p>最终目标是捕捉高阶的非线性结构。通过使用深度自编码器（半监督）来保留一阶（监督）和二阶（无监督）网络邻近度来实现。</p><blockquote><p>深度自编码器 Deep Autoencoders</p><p>自编码器是只有一层隐藏节点，输入和输出具有相同节点数的神经网络，可以用于数据压缩、降维，预训练神经网络，生成数据等等。</p></blockquote><p>为了保留一阶相似度，模型还使用了Laplacian特征图的一种变体，这是一种图形嵌入/降维技术。 当相似节点在嵌入式空间中彼此远离地映射时，拉普拉斯特征映射嵌入算法会施加惩罚，从而允许通过最小化相似节点之间的空间来进行优化。</p><p>为了保留二阶相似度，将邻接矩阵传递给一个无监督自编码器，该编码器需要最小化重构损失函数。</p><img src="http://note.lizhihao999.cn/1_44eDEuZBEsmG_TCAKRI3Kw%402x.png" style="zoom: 50%;"><p>将一阶接近损失函数和二阶重构损失函数联合最小化以返回图嵌入，其中嵌入是通过神经网络学习的。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在将表示形式通过机器学习模型之前，图嵌入技术先将图嵌入到低维连续潜空间中。主要有两类方法：遍历嵌入（walk embedding）和相似度嵌入（proximity embedding）。</p><p>遍历嵌入方法执行图的遍历，目的是保持结构和特征，并将这些遍历集合起来，然后通过递归神经网络进行遍历。</p><p>相似度嵌入方法使用深度学习方法和/或接近度损失函数来优化接近度，以使原始图中彼此靠近的节点也同样在嵌入中。</p><p><strong>参考资料：</strong><br><a href="https://towardsdatascience.com/overview-of-deep-learning-on-graph-embeddings-4305c10ad4a4">Graph Embedding for Deep Learning</a></p><p><a href="https://towardsdatascience.com/graph-embeddings-the-summary-cc6075aba007">Graph Embeddings — The Summary</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GE </tag>
            
            <tag> 知识图谱 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MIT 6.S081/Fall 2019 Lab2 Simple xv6 shell</title>
      <link href="2020/11/24/mit-6.s081-fall-2019/shi-yan-2-bi-ji/"/>
      <url>2020/11/24/mit-6.s081-fall-2019/shi-yan-2-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>MIT 6.S081/Fall 2019实验<a href="https://pdos.csail.mit.edu/6.828/2019/labs/sh.html">Lab: Simple xv6 shell</a>，为xv6写一个简单的shell。应该能够使用参数运行命令，处理输入和输出重定向，并设置双元素管道。对于这些示例以及类似的命令，实现的<code>shell</code>应类似于 xv6 shell sh：</p><pre><code class="shell">echo hello thereecho something &gt; file.txtls | grep READgrep lion &lt; data.txt | wc &gt; countecho echo hello | nshfind . b | xargs grep hello</code></pre><p>同时，该实验不能使用动态内存分配接口，例如<code>malloc()</code>、<code>sbrk()</code>，取而代之的是，只有本地变量（栈分配的）和全局变量可以使用。可以对命令名的最大长度、参数的最大数量或者任何单个参数的最大长度等内容施加合理的固定限制。</p><p>本次实验的关键点和难点在于指令的解析和不同类型指令的执行。本文对主要思路和关键部分的代码实现进行说明，<a href="https://github.com/Thooooor/xv6-riscv-fall19/tree/sh">完整代码</a>实现可以参考我的GitHub仓库.</p><h1 id="1-shell执行流程"><a href="#1-shell执行流程" class="headerlink" title="1. shell执行流程"></a>1. shell执行流程</h1><ol><li>shell执行<code>getcmd</code>获得用户输入的命令；</li><li>shell执行<code>fork</code>创建一个shell进程的副本，然后shell进行wait状态；</li><li>调用<code>parsecmd(buf)</code>解析输入的命令；</li><li>shell执行<code>runcmd</code>运行用户的命令；</li><li><code>runcmd</code>函数调用<code>exec</code>系统调用加载适当的函数如：<code>echo</code>、<code>cat</code>、<code>grep</code>等；</li><li>函数执行结束后，接着执行<code>exit</code>系统调用返回shell，shell从wait中退出。</li></ol><p>据此编写<code>main</code>函数：</p><pre><code class="c">/*    main process:    get cmd -&gt; cd? -&gt; fork -&gt; parse cmd -&gt; run cmd -&gt; get cmd                   -&gt; cd*/int main(void) {    init_index();    static char buf[MAXBUF];    int fd;    while ((fd = open("console", O_RDWR)) &gt;= 0){        if (fd &gt;= 3) {            close(fd);            break;        }    }    while (getcmd(buf, sizeof(buf)) &gt;= 0) {        if (buf[0] == 'c' &amp;&amp; buf[1] == 'd' &amp;&amp; buf[2] == ' ') {            buf[strlen(buf) - 1] = 0;            if (chdir(buf+3) &lt; 0) fprintf(2, "cannot cd %s\n", buf+3);            continue;        }        if(fork() == 0) runcmd(parsecmd(buf));        wait(0);    }    exit(0);}</code></pre><p>其中<code>cd</code>指令较为特殊，需要进行特判。</p><h1 id="2-parsecmd解析指令"><a href="#2-parsecmd解析指令" class="headerlink" title="2. parsecmd解析指令"></a>2. parsecmd解析指令</h1><p>指令解析函数<code>parsecmd</code>执行的核心函数的<code>parseline</code>，这个函数是递归执行的，其执行流程如下：</p><ol><li><p>首先执行<code>parsepipe</code>的核心函数<code>parseexec</code>，调用<code>execcmd</code>，生成一个<code>execcmd</code>的结构体，然后调用<code>parseredirs</code>函数，检查是否有重定向符号”&lt;“或”&gt;”，如果有，则将之前的<code>execcmd</code>改为<code>redircmd</code>。将命令的入参保存在cmd-&gt;argv中；</p></li><li><p>接着，检查用户输入的命令中是否有管道命令，如果有，递归调用<code>parsepipe</code>，则建立管道连接；</p></li><li><p>返回parseline，执行命令中是否有&amp;（返回命令），如果有，则生成一个新的backcmd；</p></li><li><p>检查是否有；（多条命令分别要执行），如果有，递归调用<code>parseline</code>，将所有的命令分别解析后连接起来。</p></li></ol><p>据此编写以下解析cmd的函数：</p><pre><code class="c">struct cmd* parsecmd(char *s) {    struct cmd *cmd;    char *es;    es = s + strlen(s);    cmd = parsepipe(&amp;s, es);    if (s != es) {        fprintf(2, "leftovers: %s", s);        exit(-1);    }    return cmd;}/*    pipe cmd? -&gt; left_cmd | right_cmd -&gt; parseexec(left_cmd) -&gt; pipecmd(left_cmd, parsepipe(right_cmd))              -&gt; parseexec(cmd)*/struct cmd* parsepipe(char **ps, char *es) {    struct cmd *cmd;    char *q, *eq;    if (1 == scan(ps, es, "|", &amp;q, &amp;eq)) {        cmd = parseexec(&amp;q, eq);        (*ps)++;        cmd = pipecmd(cmd, parsepipe(ps, es));    } else {        cmd = parseexec(&amp;q, eq);    }    return cmd;}struct cmd* parseexec(char **ps, char *es){    char *q, *eq;    int token, argc;    struct execcmd *cmd;    struct cmd *ret;    ret = execcmd();    cmd = (struct execcmd*)ret;    argc = 0;    ret = parseredirs(ret, ps, es);    while(*ps &lt; es) {        if((token=gettoken(ps, es, &amp;q, &amp;eq)) == 0) break;        if(token != 'a') {            fprintf(2, "syntax error.\n");            exit(-1);        }        cmd-&gt;argv[argc] = copy(q, eq);        argc++;        if(argc &gt;= MAXARGS) {            fprintf(2, "too many args.\n");            exit(-1);        }        ret = parseredirs(ret, ps, es);    }    cmd-&gt;argv[argc] = 0;    return ret;}/*    cmd &gt; file -&gt;                                       -&gt; redircmd(cmd, file)                  cmd -&gt; parseexec(cmd) -&gt; execcmd(cmd)                  file -&gt; file*/struct cmd* parseredirs(struct cmd *cmd, char **ps, char *es) {    int token;    char *q, *eq;    while(peek(ps, es, "&lt;&gt;")) {        token = gettoken(ps, es, 0, 0);        if (gettoken(ps, es, &amp;q, &amp;eq) != 'a') {            fprintf(2, "missing file for redirection.\n");            exit(-1);        }        switch(token) {            case '&lt;':                // fprintf(2, "&lt; cmd\n");                cmd = redircmd(cmd, copy(q, eq), REDIR, O_RDONLY, 0);                break;            case '&gt;':                // fprintf(2, "&gt; cmd\n");                cmd = redircmd(cmd, copy(q, eq), REDIR, O_WRONLY|O_CREATE, 1);                break;        }    }    return cmd;}/*    create pipecmd and convert it to cmd*/struct cmd *pipecmd(struct cmd *left, struct cmd *right) {    if (++cmd_index[PIPE] &gt;= MAXCMDS) {        fprintf(2, "Too many commands.\n");        exit(-1);    }    struct pipecmd *cmd = &amp;mypipecmd[cmd_index[PIPE]];    cmd-&gt;type = PIPE;    cmd-&gt;left = left;    cmd-&gt;right = right;    return (struct cmd*) cmd;}/*    create execcmd and convert it to cmd*/struct cmd *execcmd(void) {    if (++cmd_index[EXEC] &gt;= MAXCMDS) {        fprintf(2, "Too many commands.\n");        exit(-1);    }    struct execcmd *cmd = &amp;myexeccmd[cmd_index[EXEC]];    cmd-&gt;type = EXEC;    return (struct cmd*)cmd;}/*    create redircmd and convert it to cmd*/struct cmd *redircmd(struct cmd *subcmd, char *file, int type, int mode, int fd) {    if (++cmd_index[REDIR] &gt;= MAXCMDS) {        fprintf(2, "Too many commands.\n");        exit(-1);    }    struct redircmd *cmd = &amp;myredircmd[cmd_index[REDIR]];    cmd-&gt;type = type;    cmd-&gt;cmd = subcmd;    cmd-&gt;file = file;    cmd-&gt;mode = mode;    cmd-&gt;fd = fd;    return (struct cmd*)cmd;}</code></pre><h1 id="3-cmd执行"><a href="#3-cmd执行" class="headerlink" title="3. cmd执行"></a>3. cmd执行</h1><h2 id="3-1-cmd结构体"><a href="#3-1-cmd结构体" class="headerlink" title="3.1 cmd结构体"></a>3.1 cmd结构体</h2><p>参考<code>sh.c</code>中的cmd结构体定义，定义不同指令的结构体：</p><pre><code class="c">struct cmd {  int type;};struct execcmd {  int type;  char *argv[MAXARGS];  char *eargv[MAXARGS];};struct redircmd {  int type;  struct cmd *cmd;  char *file;  char *efile;  int mode;  int fd;};struct pipecmd {  int type;  struct cmd *left;  struct cmd *right;};</code></pre><p>由于不能使用动态分配函数，所以事先定义指令数组，分配好空间：</p><pre><code class="c">/*    not allowed to use m a l l o c()    use global parameters instead    index and cmd_index record the use of space*/struct cmd mycmd[MAXCMDS];struct pipecmd mypipecmd[MAXCMDS];struct execcmd myexeccmd[MAXCMDS];struct redircmd myredircmd[MAXCMDS];int cmd_index[MAXCMDS];char mybuf[MAXBUF];char cmdbuff[MAXBUF];int index = 0;</code></pre><h2 id="3-2-cmd执行"><a href="#3-2-cmd执行" class="headerlink" title="3.2 cmd执行"></a>3.2 cmd执行</h2><p>不同类型的指令，最终都会使用<code>exec</code>进行执行，根据指令的不同类型，递归调用<code>runcmd</code>完成对不同指令的执行。</p><pre><code class="c">void runcmd(struct cmd *cmd) {    int p[2];    struct execcmd *ecmd;    struct pipecmd *pcmd;    struct redircmd *rcmd;    if (cmd == 0) exit(0);    switch(cmd-&gt;type) {        default:            fprintf(2, "error cmd.\n");            exit(-1);        case EXEC:            ecmd = (struct execcmd*)cmd;            if (ecmd-&gt;argv[0] == 0) exit(-1);            if (-1 == exec(ecmd-&gt;argv[0], ecmd-&gt;argv)) fprintf(2, "exec %s failed.\n", ecmd-&gt;argv[0]);            break;        case REDIR:            rcmd = (struct redircmd*)cmd;            close(rcmd-&gt;fd);            if (open(rcmd-&gt;file, rcmd-&gt;mode) &lt; 0) {                fprintf(2, "open %s failed.\n", rcmd-&gt;file);                exit(-1);            }            runcmd(rcmd-&gt;cmd);            break;        case PIPE:            pcmd = (struct pipecmd*)cmd;            if (pipe(p) &lt; 0) exit(-1);            if (fork() == 0) {                close(1);                dup(p[1]);                close(p[0]);                close(p[1]);                runcmd(pcmd-&gt;left);            }            if (fork() == 0) {                close(0);                dup(p[0]);                close(p[0]);                close(p[1]);                runcmd(pcmd-&gt;right);            }            close(p[0]);            close(p[1]);            wait(0);            wait(0);            break;    }    exit(0);}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> MIT 6.S081/Fall 2019 Lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MIT 6.S081/Fall 2019 Lab7 locks</title>
      <link href="2020/11/24/mit-6.s081-fall-2019/shi-yan-3-bi-ji/"/>
      <url>2020/11/24/mit-6.s081-fall-2019/shi-yan-3-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>MIT 6.S081/Fall 2019实验 <a href="https://pdos.csail.mit.edu/6.828/2019/labs/lock.html">Lab: locks</a>，多核计算机上并行性差的一个常见症状是高锁争用。为了减少争用，提高并行性通常需要同时改变数据结构和锁定策略。在这个实验中，分为两部分内容：为xv6内存分配器和磁盘缓存buffer cache重新设计代码提高并行性。</p><p>本文对主要思路和关键部分的代码实现进行说明，<a href="https://github.com/Thooooor/xv6-riscv-fall19/tree/lock">完整代码</a>实现可以参考我的GitHub仓库.</p><h1 id="1-内存分配器"><a href="#1-内存分配器" class="headerlink" title="1. 内存分配器"></a>1. 内存分配器</h1><h2 id="1-1-基本原理"><a href="#1-1-基本原理" class="headerlink" title="1.1 基本原理"></a>1.1 基本原理</h2><p>xv6对上层提供<code>kalloc</code>和<code>kfree</code>接口来管理物理内存。通过<code>kalloc</code>和<code>kfree</code>，屏蔽了对物理内存的管理，使得调用者只需要关心虚拟地址空间，在需要使用新内存空间的时候调用<code>kalloc</code>，在需要释放内存空间的时候调用<code>kfree</code>。</p><p>在系统启动时，<code>main()</code>函数（见<code>kernel/main.c</code>）调用<code>kinit()</code>来初始化分配器。<code>kinit</code>通过保存所有空闲页来初始化链表。<code>kinit</code>调用<code>freerange</code>来把空闲内存加到链表里，<code>freerange</code>是把每个空闲页逐一加到链表里来实现此功能的。</p><h2 id="1-2-链表操作"><a href="#1-2-链表操作" class="headerlink" title="1.2 链表操作"></a>1.2 链表操作</h2><h3 id="释放内存"><a href="#释放内存" class="headerlink" title="释放内存"></a>释放内存</h3><p>释放内存的函数是<code>kfree(char *v)</code>，首先将 <code>char *v</code> 开始的页物理内存初始化为1，这是为了让之前使用它的代码不能再读取到有效的内容，期望这些代码能尽早崩溃以发现问题所在。然后将这空闲页物理内存加到链表头。</p><p><img src="http://note.lizhihao999.cn/notes/20201225000930.png"></p><h3 id="申请内存"><a href="#申请内存" class="headerlink" title="申请内存"></a>申请内存</h3><p><code>kalloc(void *)</code>用来分配内存，移除并返回空闲链表头的第一个元素，即给调用者分配1页物理内存。</p><p><img src="http://note.lizhihao999.cn/notes/20201225000947.png"></p><p>由于物理内存是在多进程之间共享的，所以不管是分配还是释放页面，每次操作<code>kmem.freelist</code>时都需要先申请<code>kmem.lock</code>，此后再进行内存页面的操作。</p><h2 id="1-3-Lock"><a href="#1-3-Lock" class="headerlink" title="1.3 Lock"></a>1.3 Lock</h2><p><code>kalloc.c</code>中调用<code>acquire()</code>和<code>release()</code>来获取锁和释放锁，kalloc只在<code>kalloc()</code>和<code>kfree()</code>中使用了锁，都是把对freelist的操作锁了起来。<code>kfree()</code>在向freelist里加节点前锁了一下，操作完之后解锁。<code>kalloc()</code>在移除freelist第一个元素时也加锁，操作完成再释放锁。所以对于内存分配器中需要锁保护的只有对freelist的操作。</p><h2 id="1-4-具体步骤"><a href="#1-4-具体步骤" class="headerlink" title="1.4 具体步骤"></a>1.4 具体步骤</h2><ol><li><p>将kalloc的共享freelist改为每个CPU独立的freelist；</p><pre><code class="c">struct run {  struct run *next;};struct kmem{  struct spinlock lock;  struct run *freelist;};struct kmem kmems[NCPU];void kinit(){  char *lockname = "kmem 0";  for (int i = 0; i &lt; NCPU; i++) {    lockname[5] = '0' + i;    initlock(&amp;kmems[i].lock, lockname);  }  freerange(end, (void*)PHYSTOP);}</code></pre></li><li><p>获取内存块时，优先分配当前CPU的freelist中的内存块；</p></li><li><p>当前CPU没有空闲内存块，则从其他CPU的freelist中窃取内存块；</p></li><li><p>所有CPU都没有空闲块时，返回0；</p><pre><code class="c">void *kalloc(void){  struct run *r;  push_off();  int cpu_num = cpuid();  acquire(&amp;kmems[cpu_num].lock);  // 加锁  r = kmems[cpu_num].freelist;  if (r) {  // 优先分配freelist里面的内存块    kmems[cpu_num].freelist = r-&gt;next;    release(&amp;kmems[cpu_num].lock);  } else {  // 从其他CPU的freelist进行窃取    release(&amp;kmems[cpu_num].lock);    for (int i = 0; i &lt; NCPU; i++) {      acquire(&amp;kmems[i].lock);      r = kmems[i].freelist;      if (r) {         kmems[i].freelist = r-&gt;next;        release(&amp;kmems[i].lock);        break;      }      release(&amp;kmems[i].lock);  // 解锁    }  }  pop_off();  if(r) memset((char*)r, 5, PGSIZE); // fill with junk  return (void*)r;}</code></pre></li><li><p>释放内存块时，将内存块放入当前CPU的freelist中；</p><pre><code class="c">void kfree(void *pa){  struct run *r;  if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP)    panic("kfree");  // Fill with junk to catch dangling refs.  memset(pa, 1, PGSIZE);  r = (struct run*)pa;  push_off();  int cpu_num = cpuid();  acquire(&amp;kmems[cpu_num].lock);  // 加锁  r-&gt;next = kmems[cpu_num].freelist;    // 加入freelist  kmems[cpu_num].freelist = r;  release(&amp;kmems[cpu_num].lock);  // 解锁  pop_off();}</code></pre></li><li><p>为2-5步的过程合理加锁，保证每个freelist的一致性；</p></li></ol><h1 id="2-磁盘缓存"><a href="#2-磁盘缓存" class="headerlink" title="2. 磁盘缓存"></a>2. 磁盘缓存</h1><h2 id="2-1-bcache"><a href="#2-1-bcache" class="headerlink" title="2.1 bcache"></a>2.1 bcache</h2><p>数据结构<code>bcache</code>（见<code>kernel/bio.c</code>）维护了一个由静态数组<code>struct buf buf[NBUF]</code>组成的双向链表，它以块为单位，每次读入或写出一个磁盘块，放到一个内存缓存块中（<code>bcache.buf</code>），同时自旋锁<code>bcache.lock</code>用于用户互斥访问。所有对缓存块的访问都是通过<code>bcache.head</code>引用链表来实现的，而不是<code>buf</code>数组。</p><pre><code class="c">struct {  struct spinlock lock;  struct buf buf[NBUF];  // Linked list of all buffers, through prev/next.  // head.next is most recently used.  struct buf head;} bcache;</code></pre><p>每个缓存块都由三个部分组成，其中data字段标示了它的内容，指针字段（<em>prev，</em>next）用于组成链表，数值字段用于标示它的属性，如，字段<code>valid</code>的意思是缓存区包含了一个块的复制（即该buffer包含对应磁盘块的数据），字段<code>disk</code>的意思是缓存区的内容已经被提交到了磁盘，字段<code>dev</code>是设备号，字段<code>blockno</code>是缓存数据块号，字段<code>refcnt</code>是被引用次数，<code>lock</code>是睡眠锁。</p><pre><code class="c">struct buf {  int valid;   // has data been read from disk?  int disk;    // does disk "own" buf?  uint dev;  uint blockno;  struct sleeplock lock;  uint refcnt;  struct buf *prev; // LRU cache list  struct buf *next;  uchar data[BSIZE];};</code></pre><p>对<code>bcache</code>的操作如下：</p><ul><li>在系统启动时，<code>main()</code>函数（见<code>kernel/main.c</code>）调用<code>binit()</code>来初始化缓存，随即调用<code>initlock()</code>初始化<code>bcache.lock</code>，然后循环遍历<code>buf</code>数组，采用头插法逐个链接到<code>bcache.head</code>后面。</li><li>上层文件系统读磁盘时，调用<code>bread()</code>，随即调用<code>bget()</code>检查请求的磁盘块是否在缓存中，如果命中，返回缓存命令结果。如果未命中，转到底层的<code>virtio_disk_rw()</code>函数先此磁盘块从磁盘加载进缓存中，再返回此磁盘块。</li><li>上层文件写磁盘时，调用<code>bwrite()</code>，随即调用<code>virtio_disk_rw()</code>函数直接将缓存中的数据写入磁盘。</li><li>上层文件系统可通过调用<code>brelse()</code>释放一块不再使用的缓存块。</li></ul><h2 id="2-2-锁"><a href="#2-2-锁" class="headerlink" title="2.2 锁"></a>2.2 锁</h2><p>在<code>bio.c</code>中，一共使用两种类型的锁：自旋锁<code>spinlock</code>（<code>bcache.lock</code>）和睡眠锁<code>sleeplock</code>（<code>b.lock</code>）。</p><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p><code>bcache.lock</code>用于表示当前访问的bcache缓存块数据结构的是否被锁住。 当<code>bcache.lock</code>为0时表示为锁住，能够访问当前数据结构bcache，如果为1，即暂时无法获得锁，则不断循环、自旋、等待锁重新可用。</p><p><code>bget()</code>在操作bcache数据结构（修改<code>refcnt</code>、<code>dev</code>、<code>blockno</code>、<code>valid</code>）时，需要获取到自旋锁<code>bcache.lock</code>，操作完成后再释放该锁。</p><p><code>brelse()</code>需要获取到自旋锁<code>bcache.lock</code>，才能将<code>refcnt</code>（引用计数）减1，且只有在<code>refcnt</code>为0时，将该数据缓存块插入到<code>bcache.head</code>链表后面，操作完成后再释放该锁。</p><p><code>bpin()</code>和<code>bunpin()</code>获取到锁后，才能修改<code>refcnt</code>，操作完成后再释放该锁。</p><h3 id="睡眠锁"><a href="#睡眠锁" class="headerlink" title="睡眠锁"></a>睡眠锁</h3><p><code>b.lock</code>用于表示bcache缓存块数据结构中的当前缓存数据块buf是否被锁住，当<code>b.lock</code>为1时，则调用<code>sleep()</code>睡眠等待锁重新可用，为0则表示锁已经被释放。睡眠锁的三个接口函数如下：</p><ul><li><code>acquiresleep()</code>：查询<code>b.lock</code>是否被锁，如果被锁了，就睡眠，让出CPU，直到<code>wakeup()</code>唤醒后，获取到锁，并将<code>b.lock</code>置1。</li><li><code>releasesleep()</code>：释放锁，并调用wakeup()</li><li><code>holdingsleep()</code>：返回锁的状态（1：锁住或0：未锁）</li></ul><p><code>bget()</code>在获取到缓存块（命中的缓存块，或者，未命中时通过LRU算法替换出来缓存中的缓存块）后，调用<code>acquiresleep()</code>获取睡眠锁。</p><p><code>bwrite()</code>在写入到磁盘之前，先调用<code>holdingsleep()</code>查询是否已经获取到该睡眠锁，确保有带锁而入。</p><p><code>brelse()</code>也先调用<code>holdingsleep()</code>查询是否已经获取到该睡眠锁，确保有带锁后，才调用<code>releasesleep()</code>释放该锁。</p><h2 id="2-3-具体步骤"><a href="#2-3-具体步骤" class="headerlink" title="2.3 具体步骤"></a>2.3 具体步骤</h2><ol><li><p>构建<code>bcache</code>数据结构哈希表；</p><pre><code class="c">#define HashSize 17struct {  struct spinlock lock[HashSize];  struct buf buf[NBUF];  // Linked list of all buffers, through prev/next.  // head.next is most recently used.  // struct buf head;  struct buf hashbucket[HashSize];} bcache;int hashconflict(int number) {  return (number + 1) % HashSize;}void binit(void) {  struct buf *b;  // initial every lock  for (int i = 0; i &lt; HashSize; i++) {    char *lockname = "bcache 00";    initlock(&amp;bcache.lock[i], lockname);    // Create linked list of buffers    bcache.hashbucket[i].prev = &amp;bcache.hashbucket[i];    bcache.hashbucket[i].next = &amp;bcache.hashbucket[i];  }  // use bcache.hashbucket[0] to store temporally， made a mistake there (put it in the loop above)  for (b = bcache.buf; b &lt; bcache.buf+NBUF; b++) {    b-&gt;next = bcache.hashbucket[0].next;    b-&gt;prev = &amp;bcache.hashbucket[0];    initsleeplock(&amp;b-&gt;lock, "buffer");    bcache.hashbucket[0].next-&gt;prev = b;    bcache.hashbucket[0].next = b;  }}</code></pre></li><li><p>修改<code>bget()</code>和<code>brelse()</code>使得查找和释放缓存中的不同块时，锁之间的冲突更少；</p><ul><li>首先在硬件层面寻找空闲的缓存块，如果没有则分配一个新的缓存块；</li></ul><pre><code class="c">static struct buf* bget(uint dev, uint blockno){  // get the hash index of blockno  int locknumber = blockno % HashSize;  struct buf *b;  acquire(&amp;bcache.lock[locknumber]);  // Is the block already cached?  for(b = bcache.hashbucket[locknumber].next; b != &amp;bcache.hashbucket[locknumber]; b = b-&gt;next){    if(b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno){      b-&gt;refcnt++;      release(&amp;bcache.lock[locknumber]);      acquiresleep(&amp;b-&gt;lock);      return b;    }  }  int hashnumber = hashconflict(locknumber);  // Not cached; recycle an unused buffer.  while (hashnumber != locknumber) {    acquire(&amp;bcache.lock[hashnumber]);    for(b = bcache.hashbucket[hashnumber].prev; b != &amp;bcache.hashbucket[hashnumber]; b = b-&gt;prev){      if(b-&gt;refcnt == 0) {        b-&gt;dev = dev;        b-&gt;blockno = blockno;        b-&gt;valid = 0;        b-&gt;refcnt = 1;        // take out the buf        b-&gt;next-&gt;prev = b-&gt;prev;        b-&gt;prev-&gt;next = b-&gt;next;        release(&amp;bcache.lock[hashnumber]);        // put the buf in locknumber bcache        b-&gt;next = bcache.hashbucket[locknumber].next;        b-&gt;prev = &amp;bcache.hashbucket[locknumber];        bcache.hashbucket[locknumber].next-&gt;prev = b;        bcache.hashbucket[locknumber].next = b;        release(&amp;bcache.lock[locknumber]);        acquiresleep(&amp;b-&gt;lock);        return b;      }    }    release(&amp;bcache.lock[hashnumber]);    hashnumber = hashconflict(hashnumber);  }  panic("bget: no buffers");}</code></pre><ul><li><p>释放一个已经锁住的缓存块，将其移到MRU list的头部</p><pre><code class="c">void brelse(struct buf *b){  uint blockno = b-&gt;blockno;  int locknumber = blockno % HashSize;  if(!holdingsleep(&amp;b-&gt;lock))    panic("brelse");  releasesleep(&amp;b-&gt;lock);  acquire(&amp;bcache.lock[locknumber]);  b-&gt;refcnt--;  if (b-&gt;refcnt == 0) {    // no one is waiting for it.    b-&gt;next-&gt;prev = b-&gt;prev;    b-&gt;prev-&gt;next = b-&gt;next;    b-&gt;next = bcache.hashbucket[locknumber].next;    b-&gt;prev = &amp;bcache.hashbucket[locknumber];    bcache.hashbucket[locknumber].next-&gt;prev = b;    bcache.hashbucket[locknumber].next = b;  }  release(&amp;bcache.lock[locknumber]);}</code></pre></li></ul></li><li><p>修改<code>bpin()</code>和<code>bunpin()</code>增加或减少<code>refcnt</code>之前获取对应数据缓存块的锁，操作完成之后再释放锁。</p><pre><code class="c">void bpin(struct buf *b) {  uint blockno = b-&gt;blockno % HashSize;  acquire(&amp;bcache.lock[blockno]);  b-&gt;refcnt++;  release(&amp;bcache.lock[blockno]);}void bunpin(struct buf *b) {  uint blockno = b-&gt;blockno % HashSize;  acquire(&amp;bcache.lock[blockno]);  b-&gt;refcnt--;  release(&amp;bcache.lock[blockno]);}</code></pre></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> MIT 6.S081/Fall 2019 Lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MIT 6.S081/Fall 2019 Lab3 Allocator for xv6</title>
      <link href="2020/11/24/mit-6.s081-fall-2019/shi-yan-4-bi-ji/"/>
      <url>2020/11/24/mit-6.s081-fall-2019/shi-yan-4-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>MIT 6.S081/Fall 2019实验 <a href="https://pdos.csail.mit.edu/6.828/2019/labs/alloc.html">Lab: Allocator for xv6</a>，用好友分配器替换 xv6 内核中的页面分配器，修改分配和释放文件方法，使用buddy allocator进行动态地分配和释放；同时，实现一个优化，减少buddy allocator对内存的使用。</p><p>本文对主要思路和关键部分的代码实现进行说明，<a href="https://github.com/Thooooor/xv6-riscv-fall19/tree/alloc">完整代码</a>实现可以参考我的GitHub仓库.</p><h1 id="1-使用buddy-allocator"><a href="#1-使用buddy-allocator" class="headerlink" title="1. 使用buddy allocator"></a>1. 使用buddy allocator</h1><p>修改<code>file.c</code>文件，删去ftable结构体中<code>file[NFILE]</code>的声明：</p><pre><code class="c">struct {  struct spinlock lock;} ftable;</code></pre><p>在<code>filealloc</code>中使用<code>bd_malloc</code>进行动态申请，同时每次申请之后对<code>f</code>进行初始化：</p><pre><code class="c">struct file*filealloc(void){  acquire(&amp;ftable.lock);  struct file *f  = bd_malloc(sizeof(struct file));  if (f) {    memset(f, 0, sizeof(struct file));    f-&gt;ref = 1;    release(&amp;ftable.lock);    return f;  }  release(&amp;ftable.lock);  return 0;}</code></pre><p>之后对<code>fileclose</code>进行修改，使用对应的<code>bd_free</code>进行释放，需要使用<code>acquire</code>对<code>f-&gt;ref</code>进行保护：</p><pre><code class="c">voidfileclose(struct file *f){  struct file ff;  acquire(&amp;ftable.lock);  if(f-&gt;ref &lt; 1)    panic("fileclose");  if(--f-&gt;ref &gt; 0){    release(&amp;ftable.lock);    return;  }  ff = *f;  f-&gt;ref = 0;  f-&gt;type = FD_NONE;  release(&amp;ftable.lock);  if(ff.type == FD_PIPE){    pipeclose(ff.pipe, ff.writable);  } else if(ff.type == FD_INODE || ff.type == FD_DEVICE){    begin_op(ff.ip-&gt;dev);    iput(ff.ip);    end_op(ff.ip-&gt;dev);  }  bd_free(f);}</code></pre><h1 id="2-优化伙伴系统算法"><a href="#2-优化伙伴系统算法" class="headerlink" title="2. 优化伙伴系统算法"></a>2. 优化伙伴系统算法</h1><p>首先修改<code>bd_init</code>函数，减半分配给<code>struct sz_info</code>的空间：</p><pre><code class="c">for (int k = 0; k &lt; nsizes; k++) {    lst_init(&amp;bd_sizes[k].free);    sz = sizeof(char)* ROUNDUP(NBLK(k), 16)/16;    bd_sizes[k].alloc = p;    memset(bd_sizes[k].alloc, 0, sz);    p += sz;  }</code></pre><p>Buddy alloctor管理内存时会在内存区域头部存放metadata，所以有部分的空间是不可用的（unavailable），通过以下代码可知：</p><pre><code class="c">// done allocating; mark the memory range [base, p) as allocated, so  // that buddy will not hand out that memory.  int meta = bd_mark_data_structures(p);  // mark the unavailable memory range [end, HEAP_SIZE) as allocated,  // so that buddy will not hand out that memory.  int unavailable = bd_mark_unavailable(end, p);  void *bd_end = bd_base+BLK_SIZE(MAXSIZE)-unavailable;</code></pre><p>所以可用的<code>available space</code>为<code>[p, end]</code>，之后在初始化每层的buddy时，需要考虑边界范围。之后通过函数<code>bd_initfree</code>对每层进行初始化，修改函数<code>bd_initfree</code>。</p><p>在函数入口增加左右边界<code>min_left</code>，<code>max_right</code>，对应可用空间<code>[p, end]</code>。</p><pre><code class="c">int free = bd_initfree(p, bd_end, p, end);</code></pre><p>函数<code>bd_initfree</code>中，通过调用<code>bd_initfree_pair</code>分别对内存块和它的buddy进行初始化，所以初始化的操作在<code>bd_initfree_pair</code>中进行，对应修改<code>bd_initfree_pair</code>的函数入口，增加<code>min_left</code>和<code>max_right</code>。</p><pre><code class="c">intbd_initfree(void *bd_left, void *bd_right, void *min_left, void *max_right) {  int free = 0;  for (int k = 0; k &lt; MAXSIZE; k++) {   // skip max size    int left = blk_index_next(k, bd_left);    int right = blk_index(k, bd_right);    free += bd_initfree_pair(k, left, min_left, max_right);    if(right &lt;= left)      continue;    free += bd_initfree_pair(k, right, min_left, max_right);  }  return free;}</code></pre><p><code>bd_initfree_pair</code>函数通过判断传入的内存块是否已经allocted，以及它的buddy是否空闲来判断是将buddy放入free list还是该内存块放入free list。因为使用一个bit来同时记录一对buddy的alloc情况，所以需要修改判断函数<code>bit_isset</code>，新的函数命名为<code>new_bit_isset</code>，因为分配给alloc的空间减半，故其中将index除以2。</p><pre><code class="c">void new_bit_set(char *array, int index) {  index /= 2;  char m = (1 &lt;&lt; (index % 8));  array[index/8] ^= m;}</code></pre><p>若该内存块已经allocted，则判断buddy是否为free，方法为判断buddy的地址是否在可用空间内，即<code>[min_left, max_right)</code>。如果在可用空间之内，则将buddy加入free list，否则将该内存块加入free list。</p><pre><code class="c">if(new_bit_isset(bd_sizes[k].alloc, bi)) {    // one of the pair is free    free = BLK_SIZE(k);    if(addr(k, buddy) &gt;= min_left &amp;&amp; addr(k, buddy) &lt; max_right)      lst_push(&amp;bd_sizes[k].free, addr(k, buddy));   // put buddy on free list    else      lst_push(&amp;bd_sizes[k].free, addr(k, bi));      // put bi on free list}</code></pre><p>接着修改<code>bd_malloc</code>函数，将其中对alloc的set操作换为<code>new_bit_set</code>，通过异或操作，只用一个bit位来记录一对buddy的alloc情况，其中注意需要将index除以2。</p><pre><code class="c">int new_bit_isset(char *array, int index) {  index /= 2;  char b = array[index/8];  char m = (1 &lt;&lt; (index % 8));  return (b &amp; m) == m;}</code></pre><p>修改<code>bd_malloc</code>函数时，需要注意<code>set split</code>的函数仍然需要使用原来的<code>set</code>函数，只有对alloc的set函数需要进行替换。</p><pre><code class="c">void * bd_malloc(uint64 nbytes){  int fk, k;  acquire(&amp;lock);  // Find a free block &gt;= nbytes, starting with smallest k possible  fk = firstk(nbytes);  for (k = fk; k &lt; nsizes; k++) {    if(!lst_empty(&amp;bd_sizes[k].free))      break;  }  if(k &gt;= nsizes) { // No free blocks?    release(&amp;lock);    return 0;  }  // Found a block; pop it and potentially split it.  char *p = lst_pop(&amp;bd_sizes[k].free);  new_bit_set(bd_sizes[k].alloc, blk_index(k, p));  for(; k &gt; fk; k--) {    // split a block at size k and mark one half allocated at size k-1    // and put the buddy on the free list at size k-1    char *q = p + BLK_SIZE(k-1);   // p's buddy    bit_set(bd_sizes[k].split, blk_index(k, p));    new_bit_set(bd_sizes[k-1].alloc, blk_index(k-1, p));    lst_push(&amp;bd_sizes[k-1].free, q);  }  release(&amp;lock);  return p;}</code></pre><p>对应的，修改<code>bd_mark</code>函数中对alloc声明部分的函数为<code>new_bit_set</code>，对<code>split</code>的声明部分不变：</p><pre><code class="c">void bd_mark(void *start, void *stop) {  int bi, bj;  if (((uint64) start % LEAF_SIZE != 0) || ((uint64) stop % LEAF_SIZE != 0))    panic("bd_mark");  for (int k = 0; k &lt; nsizes; k++) {    bi = blk_index(k, start);    bj = blk_index_next(k, stop);    for(; bi &lt; bj; bi++) {      if(k &gt; 0) {        // if a block is allocated at size k, mark it as split too.        bit_set(bd_sizes[k].split, bi);      }      new_bit_set(bd_sizes[k].alloc, bi);    }  }}</code></pre><p>最后，修改<code>bd_free</code>函数，其中判断函数修改为<code>new_bit_isset</code>，对buddy的alloc函数更换为<code>new_bit_set</code>：</p><pre><code class="c">void bd_free(void *p) {  void *q;  int k;  acquire(&amp;lock);  for (k = size(p); k &lt; MAXSIZE; k++) {    int bi = blk_index(k, p);    int buddy = (bi % 2 == 0) ? bi+1 : bi-1;    new_bit_set(bd_sizes[k].alloc, bi); // free p at size k    if (new_bit_isset(bd_sizes[k].alloc, buddy)) {  // is buddy allocated?      break;   // break out of loop    }    // budy is free; merge with buddy    q = addr(k, buddy);    lst_remove(q);    // remove buddy from free list    if(buddy % 2 == 0) {      p = q;    }    // at size k+1, mark that the merged buddy pair isn't split    // anymore    bit_clear(bd_sizes[k+1].split, blk_index(k+1, p));  }  lst_push(&amp;bd_sizes[k].free, p);  release(&amp;lock);}</code></pre><p>本实验主要通过使用动态声明buddy alloctor来优化xv6的文件系统。其中动态声明解决静态声明文件的大小限制，不用受限于file文件的结构体数目。同时，优化buddy alloctor，使用一个bit位来同时记录一对buddy的alloc情况，节省内存空间。</p><p>实验过程中最主要的困难在于理解buddy alloctor的分配和释放逻辑，需要知道整个流程以及流程中的函数调用，需要看懂每个函数中每行代码的作用。之后需要修改其中关于alloc的部分，减少分配空间，重写set函数。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> MIT 6.S081/Fall 2019 Lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MIT 6.S081/Fall 2019 Lab1 Xv6 and Unix utilities</title>
      <link href="2020/11/24/mit-6.s081-fall-2019/shi-yan-1-bi-ji/"/>
      <url>2020/11/24/mit-6.s081-fall-2019/shi-yan-1-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>MIT 6.S081/Fall 2019实验<a href="https://pdos.csail.mit.edu/6.828/2019/labs/util.html">Lab: Xv6 and Unix utilities</a>，实现Xv6下的几个常用功能函数。</p><blockquote><p>接口：<code>int main(int argc, char *argv[])</code></p><p><code>argc</code>：参数数量</p><p><code>argv</code>：二维参数数组（字符型）</p><p>需要注意，默认第一个参数<code>argv[0]</code>为指令名称。</p></blockquote><p>本文对思路和重要函数作分析，具体完整的实现可以查看我<a href="https://github.com/Thooooor/xv6-riscv-fall19/tree/util">Github仓库</a>上的代码.</p><h1 id="1-sleep函数"><a href="#1-sleep函数" class="headerlink" title="1. sleep函数"></a>1. sleep函数</h1><p>从shell获取参数（sleep的时间），因为参数是字符串，需要通过<code>atoi</code>将字符串转换为数值，然后调用<code>sleep</code>函数执行操作。</p><pre><code class="c">int main(int argc, char *argv[]) {    // 判断参数数量是否符合    if (argc != 2) {        printf("Please enter only ONE INT PARAMETER!\n");    } else {        int time = atoi(argv[1]);   // 将char转换为int        if (time) {            printf("Sleep time = %d\n", time);            sleep(time);        } else {            printf("Please enter An INT &gt; 0.\n");        }    }    exit();}</code></pre><h1 id="2-pingpong函数"><a href="#2-pingpong函数" class="headerlink" title="2. pingpong函数"></a>2. pingpong函数</h1><p>两个进程在管道两侧来回通信。父进程通过将”ping”写入parent_fd [1]来发送子进程，而子进程则通过从parent_fd [0]读取来接收字节。子进程从父进程收到后，通过将“pong”写入child_fd [1]来回复，然后由父进程从child_fd[0]读取。</p><h2 id="2-1-进程-pid"><a href="#2-1-进程-pid" class="headerlink" title="2.1 进程 pid"></a>2.1 进程 pid</h2><p>需要创建一个子进程，创建进程的接口为<code>int fork()</code>，该函数会复制父进程，从而创建一个新的进程，创建失败会返回-1。该函数调用一次会有两次返回值，在子进程中会返回0，父进程中会返回子进程的pid号，可以据此判断是父进程还是子进程，进行不同的操作。</p><p>使用示例:</p><pre><code class="c">int pid, child_pid, parent_pid;// 创建子进程，判断是否创建成功if ((pid = fork()) &lt; 0 ) {    printf("Fork error!\n");    exit();}if (pid == 0) {    // 子进程    child_pid = getpid();    ...} else {    // 父进程    parent_pid = getpid();    ...}</code></pre><p>可以通过<code>getpid()</code>获取当前的进程号。要确保子进程先退出，父进程再退出。</p><h2 id="2-2-管道-pipe"><a href="#2-2-管道-pipe" class="headerlink" title="2.2 管道 pipe"></a>2.2 管道 pipe</h2><p>需要创建两个管道，一个用于父进程写和子进程读，另一个用于子进程写和父进程读。创建管道的接口为<code>int pipe(pipe_name[2])</code>，成功返回0，不成功返回-1，正常创建后，<code>p[1]</code>为管道写入端，<code>p[0]</code>为管道读出端。</p><p>使用方法示例：</p><pre><code class="c">int p1[2], p2[2];// 创建两个管道if (pipe(p1) != 0 || pipe(p2) != 0) {    printf("Pipe failed.\n");    exit();}// 从p1中读入read(p1[0], buf, sizeof(buf));close(p1[0]);    // 使用后需要关闭管道// 写入p2write(p2[1], "pong", 4);close(p2[1]);    // 使用后需要关闭管道</code></pre><p>需要注意，管道read是一直阻塞的，直到管道有数据写入；如果绑定在这个管道的写端口关闭了，read返回0。需要及时关闭管道的写端，否则读出端无法判断传输是否结束。</p><p><code>pingpong</code>函数实现如下：</p><pre><code class="c">int main(int argc, char *argv[]) {    if (argc != 1) {    // 判断参数数量        printf("Please don't add any PARAMTERS!\n");    } else {        int p1[2], p2[2];        int pid, child_pid, parent_pid;        // 创建两个管道        if (pipe(p1) != 0 || pipe(p2) != 0) {            printf("Pipe failed.\n");            exit();        }        // 创建子进程        if ((pid = fork()) &lt; 0 ) {            printf("Fork error!\n");            exit();        }         // 子进程        if (pid == 0) {            child_pid = getpid();            // 从p1[0]中读出父进程传来的ping            read(p1[0], buf, sizeof(buf));            close(p1[0]);            printf("%d: received %s\n", child_pid, buf);            // 写入p2[1]            write(p2[1], "pong", 4);            close(p2[1]);            exit();        } else {    // 父进程            parent_pid = getpid();            // 写入p1[1]            write(p1[1], "ping", 4);            close(p1[1]);            // 从p2[0]中读出子进程传来的pong            read(p2[0], buf, sizeof(buf));            close(p2[0]);            printf("%d: received %s\n", parent_pid ,buf);            exit();        }    }    exit();}</code></pre><h1 id="3-素数筛选-primes"><a href="#3-素数筛选-primes" class="headerlink" title="3. 素数筛选 primes"></a>3. 素数筛选 primes</h1><p>在xv6上使用管道实现“质数筛选”， 输出2~35之间的而所有质数。</p><p>筛选思路为：主进程将所有数据（例2~11）输入到管道的左侧，第一个子进程从管道读出并筛选出2，排除掉2的倍数，其他数字再写入下一管道；第二个子进程读出并筛选出3，排除掉3的倍数，其他数字写入到下一管道；第三个子进程读出筛选出5，以此类推……如下图所示：</p><p><img src="http://note.lizhihao999.cn/notes/20201225000824.png"></p><p>因为需要创建多个子进程和管道，但是多个进程和管道之间不会交替使用，即同一时间只有一对进程和管道在使用，所以使用一个<code>close_pipe</code>函数关闭使用过的pipe和进程文件。要确保子进程先退出，父进程再退出。</p><pre><code class="c">void my_close(int port, int pd[]) {    close(port);    dup(pd[port]);    close(pd[0]);    close(pd[1]);}</code></pre><blockquote><p><strong>相关函数</strong></p><p><strong>dup</strong></p><p>功能为复制一个文件句柄，用法为<code> int dup(int handle)</code></p><p>因为标准输入描述符总是0，并且dup函数调用总是取最小可用的数字，如果关闭0,再调用dup函数，新的文件描述符就是0了。</p><p><strong>close</strong></p><p>用来关闭已打开的文件，任何有关该文件描述符上的记录锁和使用该文件的进程都会被关闭和移除。用法为<code> int close(int fd)</code>，参数fd为<code>open()</code>或<code>create()</code>打开的文件。</p></blockquote><p>每次筛选的操作在函数<code>primes</code>中实现，递归调用，直到筛选完所有的数。</p><pre><code class="c">void primes() {    int pid;    int pd[2];    int number;    // 读入管道中的第一个数，为素数    if (read(0, &amp;number, sizeof(number))) {        printf("prime %d\n", number);    } else {        exit();    }    // 创建管道    if (pipe(pd) != 0) {        printf("Pipe failed.\n");        exit();    }    // 创建子进程    if ((pid = fork()) &lt; 0) {        printf("Fork error!\n");        exit();    }    // 子进程筛选素数    if (pid == 0) {        my_close(1, pd);    // 关闭当前子进程的文件和管道        pipe_number(number);    } else {    // 父进程继续调用primes()        my_close(0, pd);    // 关闭当前父进程的文件和管道        primes();    }}</code></pre><p>当前进程需要筛选管道中的数字，将筛选后的数字写入管道传给下一个子进程，在函数<code>pipe_number</code>中实现：</p><pre><code class="c">void pipe_number(int number) {    int recieved;    // 从管道中读出数字，写入recieved    while (read(0, &amp;recieved, sizeof(recieved))) {        if (recieved % number != 0) {   // 过滤掉能被number整除的数            write(1, &amp;recieved, sizeof(recieved));        }    }}</code></pre><p>对于<code>main</code>函数，需要对输入进行判断，初始化输入的数字，调用<code>primes</code>进行筛选。</p><pre><code class="c">int main(int argc, char *argv) {    if (argc != 1) {        printf("Please enter No PARAMETERS.\n");    }    int pd[2];    int pid;    if (pipe(pd) != 0) {        printf("Pipe failed.\n");        exit();    }    if ((pid = fork()) &lt; 0) {        printf("Fork error!\n");        exit();    }    if (pid == 0) { // 对子进程输入2-35        my_close(1, pd);        for (int i = 2; i &lt;= 35; i++) {            write(1, &amp;i, sizeof(i));        }    } else {        my_close(0, pd);        primes();    }    exit();}</code></pre><h1 id="4-文件找寻函数-find"><a href="#4-文件找寻函数-find" class="headerlink" title="4. 文件找寻函数 find"></a>4. 文件找寻函数 find</h1><p>在xv6上实现UNIX函数<code>find(argv1 argv2)</code>，即在目录树<code>argv1</code>中查找名称与字符串<code>argv2</code>匹配的所有文件。参照<code>user/ls.c</code>和<code>user/grep.c</code>的实现逻辑。</p><p>思路为划分路径，递归处理每一步的文件夹下的所有文件，依次判断当前文件类型是文件还是文件夹，如果：</p><ul><li>文件，则判断名称是否匹配，结束递归；</li><li>文件夹，递归进入该文件夹，继续处理；</li></ul><p>主要函数为<code>find(char *path, char *name)</code>，实现如下：</p><pre><code class="c">void find(char *path, char *name){    // from ls.c    char buf[512], *p;    int fd;    struct dirent de;    struct stat st;    // 打开当前路径的文件    if((fd = open(path, 0)) &lt; 0){        fprintf(2, "find: cannot open %s\n", path);        return;    }    // 将文件转换为结构体    if(fstat(fd, &amp;st) &lt; 0){        fprintf(2, "find: cannot stat %s\n", path);        close(fd);        return;    }    // 判断当前文件类型是文件还是文件夹    switch(st.type){        case T_FILE:  // 判断名字是否匹配            if(match(name, fmtname(path)))            printf("%s\n", path);            break;        case T_DIR: {            if(strlen(path) + 1 + DIRSIZ + 1 &gt; sizeof buf) {                printf("find: path too long\n");                break;            }            strcpy(buf, path);            p = buf+strlen(buf);            *p++ = '/';            // 对文件夹下的文件/文件夹依次进行判断            while(read(fd, &amp;de, sizeof(de)) == sizeof(de)) {                if(de.inum == 0)                    continue;                memmove(p, de.name, DIRSIZ);                p[DIRSIZ] = 0;                if(stat(buf, &amp;st) &lt; 0){                    printf("find: cannot stat %s\n", buf);                    continue;                }                // avoid recursing into "." and ".."                if(strlen(de.name) == 1 &amp;&amp; de.name[0] == '.') continue;                if(strlen(de.name) == 2 &amp;&amp; de.name[0] == '.' &amp;&amp; de.name[1] == '.') continue;                // 继续递归                find(buf, name);            }            break;        }    }    close(fd);}</code></pre><p>另一个主要函数为判断匹配函数<code>int match(char *re, char *text)</code>，主要参考<code>user/grep.c</code>文件：</p><pre><code class="c">int match(char *re, char *text){  if(re[0] == '^')    return matchhere(re+1, text);  do{  // must look at empty string    if(matchhere(re, text))      return 1;  }while(*text++ != '\0');  return 0;}// matchhere: search for re at beginning of textint matchhere(char *re, char *text){  if(re[0] == '\0')    return 1;  if(re[1] == '*')    return matchstar(re[0], re+2, text);  if(re[0] == '$' &amp;&amp; re[1] == '\0')    return *text == '\0';  if(*text!='\0' &amp;&amp; (re[0]=='.' || re[0]==*text))    return matchhere(re+1, text+1);  return 0;}// matchstar: search for c*re at beginning of textint matchstar(int c, char *re, char *text){  do{  // a * matches zero or more instances    if(matchhere(re, text))      return 1;  }while(*text!='\0' &amp;&amp; (*text++==c || c=='.'));  return 0;}</code></pre><h1 id="5-xargs函数"><a href="#5-xargs函数" class="headerlink" title="5. xargs函数"></a>5. xargs函数</h1><p>在xv6上实现UNIX函数xargs，即从标准输入中读取行并为每行运行一个命令，且将该行作为命令的参数。</p><p>思路为依次处理每行，根据空格符和换行符分割参数，调用子进程执行指令，需要注意的是，父进程需要等待子进程执行结束后再继续处理。</p><pre><code class="c">int main(int argc, char *argv[]) {    char buf2[512];    char buf[32][32];    char *pass[32];    for (int i = 0; i &lt; 32; i++) pass[i] = buf[i];    // 依次读入    for (int i = 1; i &lt; argc; i++) strcpy(buf[i - 1], argv[i]);    // 依次处理    int n;    while ((n = read(0, buf2, sizeof(buf2))) &gt; 0) {        int pos = argc - 1; // 参数数量        char *c = buf[pos];        // 根据空行或者换行符分割参数和指令        for (char *p = buf2; *p; p++) {            if (*p == ' ' || *p == '\n') {                *c = '\0';                pos++;                c = buf[pos];            } else *c++ = *p;        }        *c = '\0';        pos++;        pass[pos] = 0;        if (fork()) wait(); // 父进程等待子进程执行结束        else exec(pass[0], pass);   // 子进程执行命令    }    if (n &lt; 0) {        printf("xargs: read error\n");        exit();    }    exit();}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> MIT 6.S081/Fall 2019 Lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Joint Neural Model for Information Extraction with Global Features</title>
      <link href="2020/10/18/lun-wen-bi-ji/ner/a-joint-neural-model-for-information-extraction-with-global-features/"/>
      <url>2020/10/18/lun-wen-bi-ji/ner/a-joint-neural-model-for-information-extraction-with-global-features/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2020 ACL会议《A Joint Neural Model for Information Extraction with Global Features》</p><p><a href="https://www.aclweb.org/anthology/2020.acl-main.713/">论文地址</a></p></blockquote><p>该论文提出一个名为ONEIE的信息抽取框架，增加一个全局特征，在实例之间和子任务之间进行联合决策。</p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>大多数的信息抽取的联合学习模型使用task-specific分类对独立实体进行标记而不是使用实体之间的交互信息。论文提出名为ONEIE的端到端信息抽取框架，整个过程分为四个操作阶段：</p><ol><li>对输入语句进行编码（Embedding）；</li><li>识别句中的实体（Entity）和事件（Event）并用结点（Node）进行表示；</li><li>使用句内信息（Local classifier）计算所有结点及其连接（Link）的标签分数（Label Score）；</li><li>解码（Decoding）时使用束搜索（Beam search）找到全局最优图。</li></ol><p>在解码阶段加入全局特征（Global Feature）捕捉实例之间（cross-instance）和子任务之间（cross-subtask）的联系（Interaction）。同时ONEIE框架没有使用任何特定语言的语法特征（Language-specific feature），所以很容易适应新语言。</p><p><img src="http://note.lizhihao999.cn/notes/20201018225620.png" alt="框架示意图"></p><h1 id="2-Task"><a href="#2-Task" class="headerlink" title="2. Task"></a>2. Task</h1><ol><li><p><strong>Entity Extraction 实体抽取</strong></p><p>根据提前定义（Pre-defined）的实体分类识别语句中提及的实体。</p></li><li><p><strong>Relation Extraction 关系抽取</strong></p><p>对给定的实体对分配关系类型。</p></li><li><p><strong>Event Extraction 事件抽取</strong></p><p>涉及识别非结构语句中的事件触发语（Event trigger: the word or phrases that most clearly express event occurrences）及这些词语和短语的论据（Arguments: the words and phrases for participants in those events），并将这些短语根据类型和语法规则进行分类。</p><p>一个Argument可以是一个实体、时间表达式或数值等。</p></li></ol><p>对信息抽取的任务作如下规定：<br>对于给定的句子，目的是提取一个信息表示图：$G=(V,E)$，其中$V$和$E$分别表示结点集和边集。</p><p>对于任意结点$v_i=&lt;a_i, b_i, l_i&gt;\in V$表示一个实体（Entity）或事件触发器（Event trigger），其中$a$和$b$分别表示结点起始和结束词语的索引（indices），$l$表示结点类型标签（Node type label）。</p><p>对于任意边$e_{ij}=&lt;i,j,l_{ij}&gt;\in E$表示两个结点之间的关系，其中$i$和$j$分别表示两个相关结点的索引，$l_{ij}$表示关系类型。</p><h1 id="3-Approach"><a href="#3-Approach" class="headerlink" title="3. Approach"></a>3. Approach</h1><p>ONEIE框架对给定的语句进行信息网络提取，分为以下四步：encoding，identification，classification和decoding。我们使用预训练的BERT模型进行编码，然后对语句中的实体和事件触发器进行识别。之后计算所有的结点和相关的边的类型标签分数（Type label scores）。在解码阶段，我们使用束搜索（Beam Search）探索输入语句可能的信息网络。</p><h2 id="3-1-Encoding"><a href="#3-1-Encoding" class="headerlink" title="3.1 Encoding"></a>3.1 Encoding</h2><p>输入一句包含$L$个词的语句，使用预训练的BERT模型将每个词表示为$x_i$。实验发现使用最后三层BERT在大多数的子任务上表现较好。</p><h2 id="3-2-Identification"><a href="#3-2-Identification" class="headerlink" title="3.2 Identification"></a>3.2 Identification</h2><p>这一阶段将识别句中的实体提及和事件触发器，并表示为信息网络中的结点。我们使用前馈神经网络FFN计算每个词的分数向量$\hat{y}_i=FFN(x_i)$，$\hat{y}_i$表示一个标签在目标标签集（Target tag set）中的分数。</p><p>之后使用CRF层捕捉标签之间的联系，计算tag path： $\hat{z}={\hat{z_1},…,\hat{z}_L}$ 的分数:</p><img src="http://note.lizhihao999.cn/notes/20201018231804.png" style="zoom:80%;"><p>其中$X={x_1,…,x_L}$是输入语句中每个词的向量表示，$\hat{y}<em>{i,\hat{z_i}}$ 是分数向量 $\hat{y}_i$在第 $\hat{z}<em>i$条路径的组合，$A</em>{\hat{z}</em>{i-1},\hat{z}<em>{i}}$ 是矩阵A中 $\hat{z}</em>{i-1}$到 $\hat{z}_i$的转移分数。同时，我们在A中添加两个特殊的标签$<start>,<end>$分别作为$\hat{z}<em>0$和$\hat{z}</em>{L+1}$来表示词语序列的开始和结束。</end></start></p><p>训练阶段时，我们最大化标准标签路径的对数似然估计：<br>$$<br>\log{p(z|X)}=s(X,z)-log{\sum_{\hat{z}\in Z}{e^{s(X.\hat{z})}}}<br>$$</p><p>其中$Z$是输入语句中所有可能标签路径的集合。</p><p>所以我们定义实体识别阶段的损失函数为：<br>$$<br>L^I=-\log{p(z|X)}<br>$$</p><h2 id="3-3-Classification"><a href="#3-3-Classification" class="headerlink" title="3.3 Classification"></a>3.3 Classification</h2><p>将每个识别出的结点表示为$v_i$，之后使用分离的针对特定任务的前馈神经网络来计算每个结点的标签分数：<br>$$<br>\hat{y}_{i}^{t}=FFN^t(v_i)<br>$$</p><p>其中$t$表示一个特定的任务。</p><p>为了获得$i-th$和$j-th$结点之间边的标签分数，我们连接它们的跨度表示（Span Representation），将向量表示为：<br>$$<br>\hat{y}_{k}^{t}=FFN^t(v_i,v_j)<br>$$</p><p>对于每个任务，训练目标是最小化以下交叉熵损失：<br>$$<br>L^{t}=-\frac{1}{N^t}\sum_{i=1}^{N^t}{y_i^{t}\log{\hat{y}^{t}_{i}}}<br>$$</p><p>其中，$y_i^{t}$是向量的正确标签，$N^t$是任务$t$中的实体数量。</p><p>如果忽略结点和边的内在依赖关系（Inter-dependencies），我们可以直接通过每个任务的最高分数来预测标签，之后生成局部的最佳图$\hat{G}$。最佳图$\hat{G}$分数的计算方法为：<br>$$<br>s’(\hat{G})=\sum_{t\in T}\sum_{i=1}^{N^t}{\max{\hat{y}_i^t}}<br>$$</p><p>其中，$T$是任务的集合，将$s’(\hat{G})$作为$\hat{G}$的局部分数参考。</p><h2 id="3-4-Global-Features"><a href="#3-4-Global-Features" class="headerlink" title="3.4 Global Features"></a>3.4 Global Features</h2><p>我们考虑框架中的两种类型的内部依赖：</p><ol><li><p>子任务间的作用 Cross-subtask interactions</p><p>这种依赖关系存在于实体、关系和事件之间；</p></li><li><p>实体之间的作用 Cross-instance interactions</p><p>这种依赖存在于一个句子中多个事件和/或关系的实例之间。</p></li></ol><p><img src="http://note.lizhihao999.cn/notes/20201018225648.png" alt="全局特征类型模板（Event schemas）"></p><p>我们设计一套全局特征类型模板（Event schemas）来捕捉以上两类相互作用，模型填充所有可能的类型来生成特征，并在训练过程中学习每个特征的权重。对于给定的一张图，我们将它的全局特征向量描述为：<br>$$<br>f_G={f_1(G),…,f_M(G)}<br>$$<br>其中，$M$是全局特征的数量，$f_i(\cdot)$是一个函数，对某个特征求值并返回标量。比如：<br>$$<br>f_i(G)=\begin{cases}<br>1,G,has,multiple,ATTCK,events\<br>0,otherwise<br>\end{cases}<br>$$<br>之后，ONEIE框架学习到一个权重向量$u\in \R^{M}$并且将$f(G)$和$u$的点乘作为图G的全局特征分数。将图G的局部分数和全局特征分数之和作为G的全局分数：<br>$$<br>s(G)=s’(G)+{u}{f}(G)<br>$$<br>我们假定一条语句的最佳（Gold-standard）图应该拥有最高的全局分数。所以，我们最小化该损失函数：<br>$$<br>L^{G}=s(\hat{G})-s(G)<br>$$<br>其中，$\hat{G}$是局部分类得到的图，$G$是最佳图。</p><p>最终，我们在训练中最优化如下的联合目标函数：<br>$$<br>L=L^I+\sum_{t\in{T}}{L^t}+L^{G}<br>$$</p><h2 id="3-5-Decoding"><a href="#3-5-Decoding" class="headerlink" title="3.5 Decoding"></a>3.5 Decoding</h2><p>ONEIE对所有的结点和成对的边进行联合决策，得到全局的最优图。最基本的方法是计算所有候选图的全局分数，选择分数最高的作为最终结果。为了优化复杂度，我们设计了一个以束搜索为基础的解码器（Beam search-based decoder）。</p><p><img src="http://note.lizhihao999.cn/notes/20201018225711.png" alt="解码算法示例"></p><p>对于给定的识别出的结点集$V$、所有结点的标签分数（label scores）和他们之间的成对联系执行解码，初始束集（initial beam set）为$B={K_{0}}$，$K_0$是一个零阶图。每一步$i$分为两小步，分别对结点和边进行扩展：</p><ol><li><p><strong>Node Step</strong></p><p>选择$v_i\in V$，定义候选集为$V_i={&lt;a_i,b_i,l_i^{(k)}&gt;|1\le K\le\beta_v}$，其中$l_i^{(k)}$表示$v_i$中分数第$k$高的局部标签分数，$\beta_v$是控制候选标签数量的超参数（hyper-parameter）。通过如下公式更新束集（beam set）：<br>$$<br>B\leftarrow{G+v|(G,v)\in B\times V_i}<br>$$</p></li><li><p><strong>Edge Step</strong></p><p>迭代地选择一个$i$之前的结点$v_j\in V,j&lt;i$，同时在$v_j$和$v_i$之间添加可能的边。如果$v_i$和$v_j$都是触发器（trigger）则跳过$v_j$。每一次迭代中，我们构造一个候选边集$E_{ij}={&lt;j,i,l_{ij}^{(k)}&gt;|1\le k\le \beta_e}$，其中$l_{ij}^{(k)}$是$e_{ij}$中分数第$k$高的标签，$\beta_e$是候选标签数量的阈值。之后，通过如下函数更新束集：<br>$$<br>B\leftarrow {G+e|(G,e)\in B\times E_{ij}}<br>$$<br>在每次edge step的最后，如果$|B|$超过束的宽度$\theta$，我们对候选对象按全局分数从高到低进行排序，只保留分数最高的$\theta$个。</p></li></ol><p>最后一步之后，返回全局分数最高的图，作为输入语句中提取的信息网络。</p><p>$$<br>u\in \R^{M}<br>$$</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NER </tag>
            
            <tag> ACL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>优化（规划）问题</title>
      <link href="2020/08/08/shu-xue-jian-mo/shu-xue-gui-hua/"/>
      <url>2020/08/08/shu-xue-jian-mo/shu-xue-gui-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="线性规划"><a href="#线性规划" class="headerlink" title="线性规划"></a>线性规划</h1><p>在一组线性约束条件的限制下，求一线性目标函数最大或最小的问题。</p><h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><ul><li><strong>比例性</strong></li><li><strong>可加性</strong></li><li><strong>连续性</strong></li></ul><p>比例性和可加性保证目标函数和约束条件对于决策变量的线性性，连续性则允许得到决策变量的实数最优解。</p><h2 id="标准模型"><a href="#标准模型" class="headerlink" title="标准模型"></a>标准模型</h2><p>$$<br>\max\quad z=\sum_{j=1}^n{c_jx_j}\<br>s.t.\quad \begin{cases}<br>\sum_{j=1}^{n}{a_{ij}x_j}=b_i\quad i=1,2,…,m\<br>x_j\ge0\quad j=1,2,…,n<br>\end{cases}<br>$$</p><h2 id="scipy库——scipy-optimize-linprog"><a href="#scipy库——scipy-optimize-linprog" class="headerlink" title="scipy库——scipy.optimize.linprog"></a>scipy库——scipy.optimize.linprog</h2><h3 id="模型形式"><a href="#模型形式" class="headerlink" title="模型形式"></a>模型形式</h3><p>$$<br>\min_{x}{c^{T}x}\<br>s.t.\begin{cases}<br>A_{ub}x\le b_{ub},\<br>A_{eq}x=b_{eq}\<br>l\le x\le u,<br>\end{cases}<br>$$</p><ul><li>x：决策变量的向量</li><li>$c,b_{ub},b_{eq},l,u$：向量</li><li>$A_{ub},A_{eq}$：矩阵</li></ul><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><pre><code class="python">scipy.optimize.linprog(    c,    # 一维向量，要最小化的线性目标函数的系数    A_ub=None,    # 不等式约束矩阵，每一行指定x上线性不等式约束的系数    b_ub=None,     # 不等式约束向量，每一个元素代表一个对应的值的上限    A_eq=None,     # 等式约束矩阵，每一行指定x上线性等式约束的系数    b_eq=None,     # 等式约束向量，A_eq@x的每个元素必须等于b_eq的相应元素    bounds=None, # sequence，x中每个元素的（min，max）对序列，定义该决策变量的最小值和最大值。                # 默认情况下，边界是（0，None）（所有决策变量都是非负的）。                    method='interior-point',    # 用于解决标准格式问题的算法，                              # {‘interior-point’, ‘revised simplex’, ‘simplex’}    callback=None,    # 如果提供了回调函数，则每次算法迭代将至少调用一次回调函数     options=None,         x0=None     # 决策变量的猜测值，通过优化算法对其进行优化。)            # method='revised simplex'，并且只有当x0代表一个基本的可行解时才能使用</code></pre><h3 id="method"><a href="#method" class="headerlink" title="method"></a>method</h3><ul><li><p><strong>interior-point method——内点法</strong></p><p>从初始内点出发，沿着最速下降方向，通过可行域内部直接达到最优解，由于是在可行域内部寻优，故对于大规模线性规划问题，当约束条件和变量数目增加时，内点算法的迭代次数变化较少，收敛性和计算速度均优于单纯形法。</p></li><li><p><strong>revised simplex method——修正单纯形法</strong></p><p>基本步骤和单纯形法大致相同，主要区别是在逐次迭代中不再以高斯消去法为基础，而是由旧基阵的逆去直接计算新基阵的逆，再由此确定检验数。这样做可以减少迭代中的累积误差，提高计算精度，同时也减少了在计算机上的存储量。</p></li><li><p><strong>simplex method——单纯形法</strong></p><p>先找出可行域的一个顶点，据一定规则判断其是否最优；若否，则转换到与之相邻的另一顶点，并使目标函数值更优；如此下去，直到找到某最优解为止。寻优步数随着决策变量的增加呈指数增长（最差情况下，具有指数复杂度）。</p></li></ul><h3 id="返回值——res"><a href="#返回值——res" class="headerlink" title="返回值——res"></a>返回值——res</h3><p>A <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult"><code>scipy.optimize.OptimizeResult</code></a> consisting of the fields:</p><blockquote><p><strong>x： 1-D array</strong></p><p>在满足约束条件下使目标函数<strong>最小化</strong>的决策变量的值。</p><p><strong>fun： float</strong></p><p>目标函数的最优值。</p><p><strong>slack： 1-D array</strong></p><p>松弛变量（&gt;0）, <code>b_ub - A_ub @ x</code>.</p><p><strong>con1-D： array</strong></p><p>等式约束的（=0）残差, <code>b_eq - A_eq @ x</code>.</p><p><strong>success： bool</strong></p><p><code>True</code> when the algorithm succeeds in finding an optimal solution.</p><p><strong>status： int</strong></p><p>An integer representing the exit status of the algorithm.</p><p><code>0</code> : 优化成功终止.</p><p><code>1</code> : 达到迭代上限.</p><p><code>2</code> : 问题似乎不可行.</p><p><code>3</code> : 问题似乎没有边界.</p><p><code>4</code> : 遇到数字困难.</p><p><strong>nit： int</strong></p><p>在所有阶段中执行的迭代总数。</p><p><strong>message： str</strong></p><p>算法退出状态的字符串</p></blockquote><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>考虑一个简单的线性规划问题：<br>$$<br>\begin{split}\max_{x_1, x_2, x_3, x_4} \ &amp; 29x_1 + 45x_2 \ \mbox{such that} \ &amp; x_1 -x_2 -3x_3 \leq 5\ &amp; 2x_1 -3x_2 -7x_3 + 3x_4 \geq 10\ &amp; 2x_1 + 8x_2 + x_3 = 60\ &amp; 4x_1 + 4x_2 + x_4 = 60\ &amp; 0 \leq x_0\ &amp; 0 \leq x_1 \leq 5\ &amp; x_2 \leq 0.5\ &amp; -3 \leq x_3\\end{split}<br>$$<br>首先，让我们考虑目标函数。我们希望最大化目标函数，但<code>linprog</code>只能接受最小化问题。通过将最大化转换为很容易解决 29x1+45x2 最小化$ −29x_1−45x_2$，$x_3,x_4$在目标函数中未显示。这意味着$x_3,x_4$权重为零。因此，目标函数可以转换为：<br>$$<br>\min_{x_1,x_2,x_3,x_4}{-29x_1-45x_2+0x_3+0x_4}<br>$$<br>如果我们定义决策变量的向量 $x=[x_1,x_2,x_3,x_4]^T$，目标权重向量 c在这个问题应该是：<br>$$<br>c=[-29,-45,0,0]^T<br>$$<br>接下来，让我们考虑两个不平等约束。第一个是“小于”不等式，因此它已经处于被<code>linprog</code>接受的形式。第二个是“大于”不等式，因此我们需要将双方乘以−1将其转化为“小于”不平等，同时明确显示零系数，得到：<br>$$<br>x_1-x_2-3x_3+0x_4\le 5\<br>-2x_1+3x_2+7x_3-3x_4\le-10<br>$$<br>将以上方程式转换为矩阵形式：<br>$$<br>A_{ub}x\le b_{ub}\<br>A_{ub}=\begin{bmatrix}<br>1&amp;-1&amp;-3&amp;0\<br>-2&amp;3&amp;7&amp;-3<br>\end{bmatrix}\<br>b_{ub}=\begin{bmatrix}<br>5\-10<br>\end{bmatrix}<br>$$<br>接下来考虑两个相等约束，同时明确显示零权重，得到：<br>$$<br>2x_1+8x_2+1x_3+0x_4=60\<br>4x_1+4x_2+0x_3+1x_4=60<br>$$<br>转换为矩阵形式，得到：<br>$$<br>A_{eq}x=b_{eq}\<br>A_{eq}=\begin{bmatrix}<br>2&amp;8&amp;1&amp;0\<br>4&amp;4&amp;0&amp;1<br>\end{bmatrix}\<br>b_{eq}=\begin{bmatrix}<br>60\60<br>\end{bmatrix}<br>$$<br>最后，让我们考虑对各个决策变量的单独不等式约束，这些约束称为“框约束”或“简单边界”。可以使用的bounds参数应用这些约束。bounds的默认值为<code>(0, None)</code>，这意味着每个决策变量的下限为0，而每个决策变量的上限为无穷大：所有决策变量均为非负数。我们的界限是不同的，因此我们需要将每个决策变量的下限和上限指定为元组，并将这些元组分组到一个列表中。</p><p><strong>实现代码：</strong></p><pre><code class="python">import numpy as npfrom scipy.optimize import linprogc = np.array([-29.0, -45.0, 0.0, 0.0])A_ub = np.array([[1.0, -1.0, -3.0, 0.0],                [-2.0, 3.0, 7.0, -3.0]])b_ub = np.array([5.0, -10.0])A_eq = np.array([[2.0, 8.0, 1.0, 0.0],                [4.0, 4.0, 0.0, 1.0]])b_eq = np.array([60.0, 60.0])x0_bounds = (0, None)x1_bounds = (0, 5.0)x2_bounds = (-np.inf, 0.5)  # +/- np.inf can be used instead of Nonex3_bounds = (-3.0, None)bounds = [x0_bounds, x1_bounds, x2_bounds, x3_bounds]result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)print(result)</code></pre><p><strong>运行结果：</strong></p><pre><code class="python">    con: array([15.5361242 , 16.61288005])  # may vary    fun: -370.2321976308326  # may vary message: 'The algorithm terminated successfully and determined that the problem is infeasible.'    nit: 6  # may vary  slack: array([ 0.79314989, -1.76308532])  # may vary status: 2 success: False      x: array([ 6.60059391,  3.97366609, -0.52664076,  1.09007993])  # may vary</code></pre><p>结果表明我们的问题是<strong>不可行</strong>的，这意味着没有满足所有约束的解向量。这并不一定意味着我们做错了任何事。有些问题确实是不可行的。但是，假设我们要决定对$x_1$太紧了，尝试松动到 $0≤x_1≤6$。调整我们的代码以反映更改并再次执行之后：</p><pre><code class="python">import numpy as npfrom scipy.optimize import linprogc = np.array([-29.0, -45.0, 0.0, 0.0])A_ub = np.array([[1.0, -1.0, -3.0, 0.0],                [-2.0, 3.0, 7.0, -3.0]])b_ub = np.array([5.0, -10.0])A_eq = np.array([[2.0, 8.0, 1.0, 0.0],                [4.0, 4.0, 0.0, 1.0]])b_eq = np.array([60.0, 60.0])x0_bounds = (0, None)x1_bounds = (0, 6)    # 修改x2_bounds = (-np.inf, 0.5)  # +/- np.inf can be used instead of Nonex3_bounds = (-3.0, None)bounds = [x0_bounds, x1_bounds, x2_bounds, x3_bounds]result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)print(result)</code></pre><p>得到结果：</p><pre><code class="python">    con: array([9.78840831e-09, 1.04662945e-08])  # may vary    fun: -505.97435889013434  # may varymessage: 'Optimization terminated successfully.'    nit: 4  # may vary  slack: array([ 6.52747190e-10, -2.26730279e-09])  # may vary status: 0success: True      x: array([ 9.41025641,  5.17948718, -0.25641026,  1.64102564])  # may vary</code></pre><p>可以检查目标值：</p><pre><code class="python">&gt;&gt;&gt; x = np.array(result.x)&gt;&gt;&gt; print(c @ x)-505.97435889013434  # may vary</code></pre><p>我们还可以检查所有约束是否都在合理的公差范围内：</p><pre><code class="python">&gt;&gt;&gt; print(b_ub - (A_ub @ x).flatten())  # this is equivalent to result.slack[ 6.52747190e-10, -2.26730279e-09]  # may vary&gt;&gt;&gt; print(b_eq - (A_eq @ x).flatten())  # this is equivalent to result.con[ 9.78840831e-09, 1.04662945e-08]]  # may vary&gt;&gt;&gt; print([0 &lt;= result.x[0], 0 &lt;= result.x[1] &lt;= 6.0, result.x[2] &lt;= 0.5, -3.0 &lt;= result.x[3]])[True, True, True, True]</code></pre><p>如果我们需要更高的精度（通常以速度为代价），则可以使用以下方法求解：<code>revised simplex</code></p><pre><code class="python">&gt;&gt;&gt; print(result)    con: array([0.00000000e+00, 7.10542736e-15])  # may vary    fun: -505.97435897435895    # may varymessage: 'Optimization terminated successfully.'    nit: 5  # may vary  slack: array([ 1.77635684e-15, -3.55271368e-15])  # may vary status: 0success: True      x: array([ 9.41025641,  5.17948718, -0.25641026,  1.64102564])  # may vary</code></pre><h1 id="非线性规划"><a href="#非线性规划" class="headerlink" title="非线性规划"></a>非线性规划</h1><h2 id="scipy-optimize-minimize"><a href="#scipy-optimize-minimize" class="headerlink" title="scipy.optimize.minimize"></a>scipy.optimize.minimize</h2><p>用于无约束和有约束的最小化算法</p><pre><code class="python">scipy.optimize.minimize(    fun,     # 需要最小化的目标函数    x0,     # 初步猜测    args=(),     method=None,     jac=None,     hess=None,     hessp=None,     bounds=None,     constraints=(),     tol=None,     callback=None,     options=None)</code></pre><blockquote><p><strong>Parameters:</strong></p><ul><li><p><strong>fun</strong>    <em>callable</em></p><p> 需要最小化的目标函数<code>fun(x, *args) -&gt; float</code></p><ul><li><code>x</code>是形状为（n，）的一维数组</li><li><code>args</code> 是完全指定函数所需的固定参数的元组</li></ul></li><li><p><strong>x0</strong>    <em>ndarray, shape (n,)</em></p><p>初步猜测，大小为（n，）的实数元素的数组</p></li><li><p><strong>args    可选</strong>    <em>tuple</em></p><p>额外的参数传递给目标函数及其派生类（<em>fun</em>，<em>jac</em>和<em>hess</em>函数）</p></li><li><p><strong>method    可选</strong>    <em>str or callable</em></p><p>求解器类型。具体参照之后有约束和无约束情况。</p><p>如果没有给出，选择为之一<code>BFGS</code>，<code>L-BFGS-B</code>，<code>SLSQP</code>，取决于如果问题有约束或边界。</p></li><li><p><strong>jac    可选</strong>    <em>{callable, ‘2-point’, ‘3-point’, ‘cs’, bool}</em></p><p>梯度矢量的计算方法。仅适用于CG，BFGS，Newton-CG，L-BFGS-B，TNC，SLSQP，dogleg，trust-ncg，trust-krylov，trust-exact和trust-constr。</p><p>如果它是可调用的，则应该是一个返回梯度向量的函数：<code>jac(x, *args) -&gt; array_like, shape (n,)</code></p></li><li><p><strong>hess    可选</strong>    <em>{callable, ‘2-point’, ‘3-point’, ‘cs’, HessianUpdateStrategy}</em></p><p>计算黑塞矩阵的方法。仅适用于Newton-CG，dogleg，trust-ncg，trust-krylov，trust-exact和trust-constr。</p><p>如果可以调用，则应返回黑塞矩阵：<code>hess(x, *args) -&gt; {LinearOperator, spmatrix, array}, (n, n)</code></p></li><li><p><strong>hessp    可选</strong>    <em>callable</em></p><p>目标函数的黑塞矩阵乘以任意向量p。仅适用于Newton-CG，trust-ncg，trust-krylov，trust-constr。</p><p><em>hessp</em>或<em>hess只需要给予一个。如果提供了</em>hess<em>，那么</em>hessp*将被忽略。 </p><p><em>hessp</em>必须计算黑塞矩阵乘以一个向量：<code>hessp(x, p, *args) -&gt; ndarray shape (n,)</code></p></li><li><p><strong>bounds    可选</strong>    <em>sequence or <code>Bounds</code></em></p><p>L-BFGS-B，TNC，SLSQP，Powell和trust-constr方法的变量界限。有两种方法可以指定范围：</p><ul><li><code> Bounds class</code>的一个实例</li><li><em>x中</em>每个元素的<code>(min, max)</code>序列，<code>None</code>用于指定无边界。</li></ul></li><li><p><strong>constrains    可选</strong>     <em>{Constraint, dict} or List of {Constraint, dict}</em></p><p>约束定义（仅适用于COBYLA，SLSQP和trust-constr）。“ trust-constr”的约束定义为单个对象或指定优化问题约束的对象列表。可用的约束是：</p><ul><li><code>LinearConstraint</code>，线性约束</li><li><code>NonlinearConstraint</code>，非线性约束</li></ul></li><li><p><strong>tol    可选</strong>    <em>float</em></p><p>终止公差。要进行详细控制，请使用特定于求解器的选项。</p></li><li><p><strong>options    可选</strong>    <em>dict</em></p><p>求解器选项字典。所有方法都接受以下通用选项：</p><ul><li><code>maxiter</code>：要执行的最大迭代次数。根据方法的不同，每个迭代可能会使用多个函数评估。</li><li><code>disp</code>：设置为<code>True</code>以打印收敛消息。</li></ul></li><li><p><strong>callback    可选</strong>    <em>callable</em></p><p>在每次迭代后调用。</p></li></ul><p><strong>Return:</strong></p><ul><li><strong>res</strong>    <em>OptimizeResult</em></li></ul></blockquote><h2 id="无约束"><a href="#无约束" class="headerlink" title="无约束"></a>无约束</h2><p>无约束优化问题形式如下：<br>$$<br>\text{minimize}\quad f(\bold{x})\<br>\text{subject to}\quad \bold{x}\in\Omega<br>$$</p><ul><li><p><strong>Nelder-Mead 单纯形法（<code>method='Nelder-Mead'</code>）</strong></p><p>单纯形算法可能是最小化行为良好的函数的最简单方法。它仅需要功能评估，对于简单的最小化问题是一个不错的选择。但是，由于它不使用任何梯度评估，因此可能需要更长的时间才能找到最小值。</p></li><li><p><strong>鲍威尔算法（<code>method='Powell'</code>）</strong></p><p>利用共轭方向可以加快收敛速度的性质形成的一种搜索方法。该方法不需要对目标函数进行求导，当目标函数的导数不连续的时候也能应用，因此，鲍威尔算法是一种十分有效的直接搜索法。</p><p>Powell法可用于求解一般无约束优化问题，对于维数n&lt;20的目标函数求优化问题，此法可获得较满意的结果。</p></li><li><p><strong>BFGS算法（<code>method='BFGS'</code>）</strong></p><p>为了更快地收敛到解，该例程使用目标函数的梯度。如果用户未给出梯度，则使用一阶差进行估算。BFGS方法通常需要比单纯形算法更少的函数调用，即使必须估计梯度也是如此。</p></li><li><p><strong>共轭梯度算法（<code>method='CG'</code>）</strong></p><p>共轭梯度法是一个典型的共轭方向法，它的每一个搜索方向是互相共轭的，而这些搜索方向d仅仅是负梯度方向与上一次迭代的搜索方向的组合，因此，存储量少，计算方便。</p></li><li><p><strong>牛顿共轭梯度算法（<code>method='Newton-CG'</code>）</strong></p><p>牛顿共轭梯度算法是牛顿方法的一种改进方法，它使用共轭梯度算法来（近似）反转局部黑塞矩阵。</p></li><li><p><strong>L-BFGS-B算法（<code>method='L-BFGS-B'</code>）</strong></p><p>L-BFGS-B是用于受限约束优化的有限内存拟牛顿算法，适用于任何类型的带有线搜索的非线性（或线性）问题。另外，对于L-BFGS-B和共轭梯度求解器，收敛所需的迭代次数几乎相同。</p></li><li><p><strong>牛顿截断法（<code>method='TNC'</code>）</strong></p><p>阶段牛顿法旨在优化具有大量自变量的非线性函数。</p></li><li><p><strong>信任区域牛顿共轭梯度算法（<code>method='trust-ncg'</code>）</strong></p><p>该方法是线搜索方法：它找到使函数的二次逼近最小的搜索方向，然后使用线搜索算法在该方向上找到（几乎）最佳步长。</p></li><li><p><strong>信任区域截断的广义Lanczos /共轭梯度算法（<code>method='trust-krylov'</code>）</strong></p><p>该方法是一种适用于大规模问题的方法，因为它仅通过矩阵向量积将hessian用作线性算子。</p></li></ul><h2 id="有约束"><a href="#有约束" class="headerlink" title="有约束"></a>有约束</h2><p>有约束优化问题标准化形式如下：<br>$$<br>\begin{align}<br>\text{minimize}\quad &amp;f(\bold{x})\<br>\text{subject to}\quad &amp;\bold{h(x)=0}\<br>&amp;\bold{g(x)\le 0}<br>\end{align}<br>$$</p><ul><li><p><strong>线性逼近约束优化（<code>method='COBYLA'</code>）</strong></p><p>通过迭代逼近实际约束优化问题和线性规划问题来工作。在迭代过程中，解决了近似线性规划问题，以获得最佳解的候选者。使用原始目标和约束函数评估候选解决方案，从而在优化空间中产生一个新的数据点。此信息用于改进算法的下一次迭代所用的近似线性规划问题。当解决方案无法再改进时，步长将减小，从而完善了搜索范围。当步长变得足够小时，算法结束。</p></li><li><p><strong>递推最小二乘算法（<code>method='SLSQP'</code>）</strong></p><p>SLSQP方法用于目标函数和约束两次连续可微的数学问题。SQP方法解决了一系列优化子问题，每个子问题都会根据约束的线性化来优化目标的二次模型。</p></li><li><p><strong>信任区域算法（<code>method='trust-constr'</code>）</strong></p><p>在数学优化中，信任区域算法是使用模型函数（通常是二次函数）近似的目标函数区域的子集。如果在信任区域内找到了目标函数的适当模型，则该区域将扩展；否则，该区域将被扩展。相反，如果近似值不佳，则该区域将缩小。通过比较模型近似的预期改进与目标函数中观察到的实际改进的比率来评估拟合。</p></li><li><p><strong>狗腿信任区域算法（<code>method='dogleg'</code>）</strong></p><p>对朴素信任区域算法进行改进。</p></li><li><p><strong>牛顿共轭梯度信任区算法（<code>method='trust-ncg'</code>）</strong></p></li><li><p><strong>近似精确信任区域算法（<code>method='trust-exact'</code>）</strong></p></li><li><p><strong>改进近似精确信任区域算法（<code>method='trust-krylov'</code>）</strong></p><p>使用仅需要矩阵向量乘积与黑塞矩阵的近似精确信任区域算法。</p></li></ul><h1 id="多目标规划"><a href="#多目标规划" class="headerlink" title="多目标规划"></a>多目标规划</h1><p>多目标优化问题可表示为：<br>$$<br>\text{minimize}\quad \bold{f(x)}=\begin{bmatrix}<br>f_1(x_1,x_2,…,x_n)\<br>f_2(x_1,x_2,…,x_n)\<br>…\<br>f_l(x_1,x_2,…,x_n)<br>\end{bmatrix}\<br>\text{subject to}\quad x\in\Omega<br>$$<br>通常情况下，求解多目标优化问题需要在多个目标之间寻找合适的折中。简而言之，在多目标优化问题中，综合考虑所有的目标函数，对于某个解，在可行集内没有其他解能够对目标进行改进，那么这个解就是最优解。</p><p>习惯将多目标优化问题的最优解称为帕累托极小点（帕累托解）。帕累托极小点（最优解）的集合称为帕累托前沿。</p><h2 id="多目标进化算法"><a href="#多目标进化算法" class="headerlink" title="多目标进化算法"></a>多目标进化算法</h2><p>使用<code>geatpy</code>实现：</p><pre><code class="python"># MyProblem.pyimport numpy as npimport geatpy as ea"""该案例展示了一个离散决策变量的最小化目标的双目标优化问题。min f1 = -25 * (x1 - 2)**2 - (x2 - 2)**2 - (x3 - 1)**2 - (x4 - 4)**2 - (x5 - 1)**2min f2 = (x1 - 1)**2 + (x2 - 1)**2 + (x3 - 1)**2 + (x4 - 1)**2 + (x5 - 1)**2s.t.x1 + x2 &gt;= 2x1 + x2 &lt;= 6x1 - x2 &gt;= -2x1 - 3*x2 &lt;= 24 - (x3 - 3)**2 - x4 &gt;= 0(x5 - 3)**2 + x4 - 4 &gt;= 0x1,x2,x3,x4,x5 ∈ {0,1,2,3,4,5,6,7,8,9,10}"""class MyProblem(ea.Problem):    # 继承Problem父类    def __init__(self, M = 2):        name = 'MyProblem' # 初始化name（函数名称，可以随意设置）        Dim = 5 # 初始化Dim（决策变量维数）        maxormins = [1] * M # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标）        varTypes = [1] * Dim # 初始化varTypes（决策变量的类型，0：实数；1：整数）        lb = [0] * Dim # 决策变量下界        ub = [10] * Dim # 决策变量上界        lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含）        ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含）        # 调用父类构造方法完成实例化        ea.Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin)    def aimFunc(self, pop): # 目标函数        Vars = pop.Phen # 得到决策变量矩阵        x1 = Vars[:, [0]]        x2 = Vars[:, [1]]        x3 = Vars[:, [2]]        x4 = Vars[:, [3]]        x5 = Vars[:, [4]]        f1 = -25 * (x1 - 2)**2 - (x2 - 2)**2 - (x3 - 1)**2 - (x4 - 4)**2 - (x5 - 1)**2        f2 = (x1 - 1)**2 + (x2 - 1)**2 + (x3 - 1)**2 + (x4 - 1)**2 + (x5 - 1)**2#        # 利用罚函数法处理约束条件#        idx1 = np.where(x1 + x2 &lt; 2)[0]#        idx2 = np.where(x1 + x2 &gt; 6)[0]#        idx3 = np.where(x1 - x2 &lt; -2)[0]#        idx4 = np.where(x1 - 3*x2 &gt; 2)[0]#        idx5 = np.where(4 - (x3 - 3)**2 - x4 &lt; 0)[0]#        idx6 = np.where((x5 - 3)**2 + x4 - 4 &lt; 0)[0]#        exIdx = np.unique(np.hstack([idx1, idx2, idx3, idx4, idx5, idx6])) # 得到非可行解的下标#        f1[exIdx] = f1[exIdx] + np.max(f1) - np.min(f1)#        f2[exIdx] = f2[exIdx] + np.max(f2) - np.min(f2)        # 利用可行性法则处理约束条件        pop.CV = np.hstack([2 - x1 - x2,                            x1 + x2 - 6,                            -2 - x1 + x2,                            x1 - 3*x2 - 2,                            (x3 - 3)**2 + x4 - 4,                            4 - (x5 - 3)**2 - x4])        pop.ObjV = np.hstack([f1, f2]) # 把求得的目标函数值赋值给种群pop的ObjV</code></pre><p>运行：</p><pre><code class="python"># main.pyimport geatpy as ea     # import geatpyfrom MyProblem import MyProblem    # 导入自定义问题接口if __name__ == '__main__':    """================================实例化问题对象==========================="""    problem = MyProblem()       # 生成问题对象    """==================================种群设置==============================="""    Encoding = 'BG'             # 编码方式    NIND = 50                   # 种群规模    Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器    population = ea.Population(Encoding, Field, NIND) # 实例化种群对象（此时种群还没被初始化，仅仅是完成种群对象的实例化）    """================================算法参数设置============================="""    myAlgorithm = ea.moea_NSGA2_templet(problem, population) # 实例化一个算法模板对象    myAlgorithm.mutOper.Pm = 0.2 # 修改变异算子的变异概率    myAlgorithm.recOper.XOVR = 0.9 # 修改交叉算子的交叉概率    myAlgorithm.MAXGEN = 200    # 最大进化代数    """==========================调用算法模板进行种群进化========================"""    NDSet = myAlgorithm.run()   # 执行算法模板，得到帕累托最优解集NDSet    NDSet.save()                # 把结果保存到文件中    # 输出    print('用时：%s 秒'%(myAlgorithm.passTime))    print('非支配个体数：%s 个'%(NDSet.sizes))    print('单位时间找到帕累托前沿点个数：%s 个'%(int(NDSet.sizes // myAlgorithm.passTime)))</code></pre><p>可以得到输出：</p><pre><code class="shell">种群信息导出完毕。用时：0.15359210968017578 秒非支配个体数：50 个单位时间找到帕累托前沿点个数：325 个</code></pre><p>帕累托前沿分布：</p><p><img src="E:\Thor\Documents\Study\数学建模\数学规划.assets\image-20200706142245386.png" alt="image-20200706142245386"></p><p>结果保存为文件：</p><p><img src="E:\Thor\Documents\Study\数学建模\数学规划.assets\image-20200706143959892.png" alt="image-20200706143959892"></p><h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><h2 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h2><ul><li><h4 id="给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解"><a href="#给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解" class="headerlink" title="给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解"></a>给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解</h4></li><li><h4 id="很多优化问题可分为多个子问题，子问题相互关联，子问题的解被-重复使用"><a href="#很多优化问题可分为多个子问题，子问题相互关联，子问题的解被-重复使用" class="headerlink" title="很多优化问题可分为多个子问题，子问题相互关联，子问题的解被==重复使用=="></a>很多优化问题可分为多个子问题，子问题相互关联，子问题的解被==重复使用==</h4></li></ul><h2 id="使用条件"><a href="#使用条件" class="headerlink" title="使用条件"></a>使用条件</h2><ul><li><h4 id="优化子结构"><a href="#优化子结构" class="headerlink" title="优化子结构"></a>优化子结构</h4><ul><li><strong>一个问题的优化解包含了子问题的优化解</strong></li></ul></li><li><h4 id="重叠子问题"><a href="#重叠子问题" class="headerlink" title="重叠子问题"></a>重叠子问题</h4><ul><li><strong>在问题的求解过程中，很多子问题的解将被多次使用</strong></li></ul></li></ul><h2 id="设计步骤"><a href="#设计步骤" class="headerlink" title="设计步骤"></a>设计步骤</h2><ul><li><h4 id="刻画一个最优解的结构特征"><a href="#刻画一个最优解的结构特征" class="headerlink" title="刻画一个最优解的结构特征"></a>刻画一个最优解的结构特征</h4><p>寻找最优子结构，利用这种子结构从子问题的最优解构造出原问题的最优解</p></li><li><h4 id="递归定义最优解的值"><a href="#递归定义最优解的值" class="headerlink" title="递归定义最优解的值"></a>递归定义最优解的值</h4></li><li><h4 id="自底向上计算最优解的值"><a href="#自底向上计算最优解的值" class="headerlink" title="自底向上计算最优解的值"></a>自底向上计算最优解的值</h4></li><li><h4 id="根据构造最优解的信息构造优化解"><a href="#根据构造最优解的信息构造优化解" class="headerlink" title="根据构造最优解的信息构造优化解"></a>根据构造最优解的信息构造优化解</h4></li></ul><h2 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h2><ul><li><h4 id="带备忘的自顶向下法"><a href="#带备忘的自顶向下法" class="headerlink" title="带备忘的自顶向下法"></a>带备忘的自顶向下法</h4><ul><li>递归求解</li><li>保存每个子问题的解（数组或散列表）</li></ul></li><li><h4 id="自底向上法"><a href="#自底向上法" class="headerlink" title="自底向上法"></a>自底向上法</h4><ul><li>恰当定义子问题的<strong>规模</strong></li><li>任何子问题的求解都只依赖于<strong>更小的</strong>子问题的解</li><li>按子问题规模<strong>由小到大进行求解</strong></li><li>第一次求解一个问题时，它的所有前提子问题都已求解完成且<strong>保存结果</strong></li></ul></li></ul><p>两种方法的算法的<strong>渐进运行时间相同</strong>，<strong>自底向上的时间复杂性</strong>函数通常具有更小的系数，某些情况下自顶向下无法真正递归考察所有可能的子问题。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="最优子结构"><a href="#最优子结构" class="headerlink" title="最优子结构"></a>最优子结构</h3><ul><li><p><strong>发掘最优子结构的通用模式</strong></p><ol><li>证明问题最优解的第一个组成部分是做出一个选择，做出这次选择会产生一个或多个待解的子问题</li><li>对于一个给定问题，在其可能的第一步选择中，你<strong>假定已经知道</strong>哪种选择才会得到最优解。并<strong>不关心如何得到，只是假定已经知道</strong></li><li>给定可获得最优解的选择后，你确定这次选择会产生哪些<strong>子问题</strong>，以及如何<strong>最好地刻画子问题空间</strong></li></ol></li><li><p><strong>保持子问题空间尽可能简单，只在必要时才扩展它</strong></p></li><li><p><strong>不同问题领域，最优子结构的不同</strong>：</p><ul><li>原问题的最优解中涉及多少个子问题</li><li>再确定最优解使用哪些子问题时，我们需要考虑多少种选择</li></ul></li><li><p><strong>粗略分析算法的运行时间：</strong><br>$$<br>O(m\times n)\<br>\Theta(n):子问题个数\quad\quad m:考察的选择个数<br>$$</p></li></ul><h3 id="重构最优解"><a href="#重构最优解" class="headerlink" title="重构最优解"></a>重构最优解</h3><p><strong>将每个子问题所做的选择存在一个表中</strong>：重构每次选择只需$$O(1)$$时间</p><h3 id="备忘"><a href="#备忘" class="headerlink" title="备忘"></a>备忘</h3><p>维护一个表记录子问题的解，保持递归算法的控制流程：</p><ul><li>每个表项的初值设为一个特殊值，表示尚未填入子问题的解</li><li>当递归调用过程中第一次遇到子问题时，计算其解，并存入对应表项</li><li>每次遇到同一个子问题，查表返回解</li></ul><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><ul><li><strong>通常情况</strong>：每个子问题必须至少求解一次<ul><li>自底向上动态规划算法比自顶向下备忘算法快（都是$$O(n^3)$$，相差常量系数）</li><li>自底向上算法没有递归调用的开销，表的维护开销更小</li></ul></li><li><strong>某些问题：</strong>可利用表的访问模式进一步降低时空代价</li><li><strong>某些子问题完全不必求解：</strong>备忘方法更有优势（只求解必要子问题）</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sympy的基本使用</title>
      <link href="2020/08/08/shu-xue-jian-mo/sympy/"/>
      <url>2020/08/08/shu-xue-jian-mo/sympy/</url>
      
        <content type="html"><![CDATA[<pre><code class="python">from sympy import *init_printing(use_unicode=True)</code></pre><p><a href="https://docs.sympy.org/latest/tutorial/index.html"><code>Sympy</code></a>是一个用于符号计算的python库，可以完成多项式求值、求极限、解方程、求积分、微分方程等符号计算问题，介绍一些常用功能。</p><h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><h2 id="1-定义变量"><a href="#1-定义变量" class="headerlink" title="1. 定义变量"></a>1. 定义变量</h2><pre><code class="python">x, y, z = symbols("x y z")    # 多个变量t = Symbol('t')    # 单个变量</code></pre><h2 id="2-运算符"><a href="#2-运算符" class="headerlink" title="2. 运算符"></a>2. 运算符</h2><h3 id="导数diff"><a href="#导数diff" class="headerlink" title="导数diff"></a>导数<code>diff</code></h3><pre><code class="python">In[1]: diff(cos(x), x)Out[1]: -sin(x)# 高阶导数两种写法In[2]: diff(x**4, x, 3)Out[2]: 24⋅xIn[3]: diff(x**4, x, x, x)Out[3]: 24⋅x# 偏导数In[4]:     expr = exp(x*y*z)         diff(expr, x, y, 2, z, 4)Out[4]:  3  2 ⎛ 3  3  3       2  2  2                ⎞  x⋅y⋅zx ⋅y ⋅⎝x ⋅y ⋅z  + 14⋅x ⋅y ⋅z  + 52⋅x⋅y⋅z + 48⎠⋅ℯ</code></pre><h3 id="积分intergrate"><a href="#积分intergrate" class="headerlink" title="积分intergrate"></a>积分<code>intergrate</code></h3><p><code>intergrate(integration_variable, lower_limit, upper_limit)</code></p><pre><code class="python">In[5]: integrate(sin(x), x)Out[5]: -cos(x)In[6]: integrate(exp(-x), (x, 0, oo))Out[6]: 1# 多重积分In[7]: integrate(exp(-x**2-y**2), (x,-oo,oo), (y, -oo, oo))Out[7]: π</code></pre><h3 id="极限limit"><a href="#极限limit" class="headerlink" title="极限limit"></a>极限<code>limit</code></h3><p><code>limit(f(x), x, x0)</code></p><pre><code class="python">In[8]: limit(sin(x)/x, x, 0)Out[8]: 1# 单侧极限In[9]: limit(1/x, x, 0, '+')Out[9]: ∞</code></pre><h3 id="等式Eq"><a href="#等式Eq" class="headerlink" title="等式Eq"></a>等式<code>Eq</code></h3><pre><code class="python">In[10]: Eq(x, y)Out[10]: x = y</code></pre><h2 id="3-方程"><a href="#3-方程" class="headerlink" title="3. 方程"></a>3. 方程</h2><h3 id="代数方程solveset"><a href="#代数方程solveset" class="headerlink" title="代数方程solveset"></a>代数方程<code>solveset</code></h3><p><code>solveset(f, symbol=None, domain=S.Complexes)</code></p><pre><code class="python">In[11]: solveset(x**2-x, x)Out[11]: {0, 1}In[12]: solveset(exp(x), x)Out[12]: ∅</code></pre><h3 id="线性方程组linsolve"><a href="#线性方程组linsolve" class="headerlink" title="线性方程组linsolve"></a>线性方程组<code>linsolve</code></h3><p><code>linsolve(system, *symbols)</code></p><pre><code class="python">In[13]: linsolve([x+y+z-1,x+y+2*z-3], (x,y,z))Out[13]: {(-y - 1, y, 2)}In[14]:linsolve(Matrix(([1, 1, 1, 1], [1, 1, 2, 3])), (x, y, z))Out[14]: {(-y - 1, y, 2)}In[15]: M = Matrix(((1, 1, 1, 1), (1, 1, 2, 3)))        system = A, b = M[:, :-1], M[:, -1]        linsolve(system, x, y, z)Out[15]: {(-y - 1, y, 2)}</code></pre><h3 id="非线性方程组nonlinsolve"><a href="#非线性方程组nonlinsolve" class="headerlink" title="非线性方程组nonlinsolve"></a>非线性方程组<code>nonlinsolve</code></h3><p><code>nonlinsolve(system, *symbols)</code></p><pre><code class="python"># 仅有实数解In[16]: nonlinsolve([x*y - 1, x - 2], x, y)Out[16]: {(2, 1/2)}# 仅有复数解In[17]: nonlinsolve([x**2+1, y**2+1], [x,y])Out[17]: {(-ⅈ, -ⅈ), (-ⅈ, ⅈ), (ⅈ, -ⅈ), (ⅈ, ⅈ)}# 同时存在实数解和复数解In[18]: nonlinsolve([x**2-2*y**2-2, x*y-2], [x, y])Out[18]: {(-2, -1), (2, 1), (-√2⋅ⅈ, √2⋅ⅈ), (√2⋅ⅈ, -√2⋅ⅈ)}# 无数值解In[19]: nonlinsolve([x*y, x*y-x], [x, y])Out[19]: {(0, y)}</code></pre><p>解的顺序与给定符号的顺序相对应.</p><h3 id="微分方程dsolve"><a href="#微分方程dsolve" class="headerlink" title="微分方程dsolve"></a>微分方程<code>dsolve</code></h3><p><code>dsolve(eq, func=None, hint="default", simplify=True, ics= None, xi=None, eta=None, x0=0, n=6, **kwargs)</code></p><pre><code class="python"># 首先需要创建新的未定义函数In[20]: f, g = symbols('f g', cls=Function)        f(x)Out[20]: f(x)# 定义方程In[21]::diffeq = Eq(x.diff(x, x) - 2*f(x).diff(x) + f(x), sin(x))Out[21]:          d                f(x) - 2⋅──(f(x)) = sin(x)         dx               In[22]: dsolve(diffeq, f(x))Out[22]:        ⎛      -x              -x        ⎞          ⎜      ───             ───       ⎟  x       ⎜       2               2        ⎟  ─       ⎜     ℯ   ⋅sin(x)   2⋅ℯ   ⋅cos(x)⎟  2f(x) = ⎜C₁ + ─────────── + ─────────────⎟⋅ℯ        ⎝          5              5      ⎠ </code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>摊还分析</title>
      <link href="2020/05/10/suan-fa-bi-ji/tan-huan-fen-xi/"/>
      <url>2020/05/10/suan-fa-bi-ji/tan-huan-fen-xi/</url>
      
        <content type="html"><![CDATA[<p>在摊还分析中，我们求数据结构的一个操作序列中所执行的所有操作的<strong>平均时间</strong>，来评价操作的代价。摊还分析不同于平均情况分析，不涉及概率，保证<strong>最坏情况下每个操作的平均性能</strong>。通过做摊还分析，通常可以获得对某种特定数据结构的认识，这种认识有助于优化设计。</p><h1 id="聚合分析"><a href="#聚合分析" class="headerlink" title="聚合分析"></a>聚合分析</h1><p>利用聚合分析，我们证明对所有n，一个n个操作序列<strong>最坏情况</strong>下花费的总时间为T(n)。因此，在最坏情况下，每个操作的平均代价，或者是<strong>摊还代价</strong>为$\frac{T(n)}{n}$。需要注意的是，此摊还代价是适用于每个操作的，即使序列中有多种类型的操作也是如此。因此在这种方法中一个操作序列中不同的操作具有相同的摊还时间。</p><h1 id="核算法"><a href="#核算法" class="headerlink" title="核算法"></a>核算法</h1><p>在用核算法进行摊还分析时，我们对不同的操作赋予不同费用，我们将赋予一个操作的费用称为它的摊还代价，因此在核算法中，不同的操作具有不同的摊还代价。当一个操作的摊还代价超出其实际代价时，我们将差额存入到<strong>数据结构中的特定对象</strong>中，存入的差额称为<strong>信用</strong>，对于后续操作中摊还代价小于实际代价的情况，信用可以用来支付差额。因此我们可以将一个操作的摊还代价分解为实际代价和信用。不同的操作可能有不同的摊还代价。</p><p>我们必须小心的选择操作的摊还代价，以保证对所有操作序列来说，其<strong>摊还代价总和会大于等于其实际代价的总和</strong>。如果用$c_i$表示第i个操作的真实代价，用$\hat{c_i}$表示其摊还代价，则对任意n个操作的序列，要求<br>$$<br>\sum_{i=1}^{n}{\hat{c_i}}\ge\sum_{i=1}^{n}{c_i}<br>$$<br>数据结构中存储的信用恰好等于总摊还代价与总实际代价的差值，即$\sum_{i=1}^{n}{\hat{c_i}}-\sum_{i=1}^{n}{c_i}$。数据结构所关联的信用必须一直为非负值，即要保证<strong>数据结构中的总信用永远为非负</strong>。</p><h1 id="势能法"><a href="#势能法" class="headerlink" title="势能法"></a>势能法</h1><p>势能法摊还分析并不将预付代价表示为数据结构中特定对象的信用，可是表示为势能，将势能释放即可用来支付未来操作的代价并且不同于核算法，我们是将势能与整个数据结构而不是特定对象联系在一起的。</p><p>势能法工作方式如下：</p><ol><li><p>对一个初始数据结构$D_0$执行n个操作。</p></li><li><p>对每个$i=1,2,…,n$，令$c_i$为第i个操作的实际代价，令$D_i$为在数据结构$D_{i-1}$上执行第i个操作得到的结果数据结构。</p></li><li><p>势函数$\Phi $将每个数据结构$D_i$映射到一个实数$\Phi(D_i)$，此值即为关联到数据结构$D_i$的势。</p></li><li><p>第i个操作的瘫痪代价$\hat{c_i}$用势函数$\Phi $定义为：<br>$$<br>\hat{c_i}=c_i+\Phi(D_i)-\Phi(D_{i-1})<br>$$</p></li></ol><p>因此，每个操作的摊还代价等于其实际代价加上此操作引起的势能变化。n个操作的总摊还代价为：<br>$$<br>\sum_{i=1}^{n}{\hat{c_i}}=\sum_{i=1}^{n}{(c_i+\Phi(D_{i})-\Phi(D_{i-1}))}=\sum_{i=1}^{n}{c_i}+\Phi(D_n)-\Phi(D_0)<br>$$<br>如果对所有i，我们要求$\Phi(D_i)\ge\Phi(D_0)$，则可以像核算法一样保证总能提前支付。通常，我们将$\Phi(D_0)$简单定义为0，然后说明对所有i，有$\Phi(D_i)\ge 0$。</p><p>所以在进行势能法分析时，我们需要先确定一个势函数，然后再通过关系式去求解每个操作的摊还代价。此势函数应该<strong>要满足对所有操作序列，其值应要大于等于0</strong>。 </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络最大流</title>
      <link href="2020/05/09/suan-fa-bi-ji/wang-luo-zui-da-liu/"/>
      <url>2020/05/09/suan-fa-bi-ji/wang-luo-zui-da-liu/</url>
      
        <content type="html"><![CDATA[<h1 id="流网络"><a href="#流网络" class="headerlink" title="流网络"></a>流网络</h1><h2 id="流网络和流"><a href="#流网络和流" class="headerlink" title="流网络和流"></a>流网络和流</h2><p>流网络$G=(V,E)$，是一个有向图，图中每条边$(u,v)\in E$有一个非负的<strong>容量值</strong>$c(u,v)\ge 0$。而且不存在平行反向边，即如果存在边$(u,v)$，便不存在反方向的边$(v,u)$。如果$(u,v)\notin E$，定义$c(u,v)=0$，并且在图中不允许自循环。</p><p>所有结点中定义两个特殊结点：<strong>源结点s</strong>和<strong>汇点t</strong>。假定每个结点都在从源结点到汇点的某条路径上。所以，对于每个结点$v\in V$，流网络都包括一条路径$s\rightsquigarrow v\rightsquigarrow t$。因此，流网络是连通的，$|E|\ge |V|-1$。</p><img src="http://note.lizhihao999.cn/notes/20200824164601.png" alt="《算法导论》流网络示例" style="zoom: 67%;"><p>设流网络$G=(V,E)$，其容量函数为c。设s为网络的源结点，t为汇点。G中的流是一个实值函数$f:V\times V\to R$，满足：</p><ul><li><p><strong>容量限制</strong></p><p>对于所有的结点$u,v\in V$，要求$0\le f(u,v)\le c(u,v)$</p></li><li><p><strong>流量守恒</strong></p><p>对于所有的结点$u\in V-{s,t}$，要求<br>$$<br>\sum_{v\in V}{f(v,u)}=\sum_{v\in V}{f(u,v)}<br>$$</p></li></ul><p>当$(u,v)\notin E$时，从结点u到结点v之间没有流，因此$f(u,v)=0$。</p><p>称非负值$f(u,v)$为从结点u到结点v的流。</p><p>一个流$f$的值$|f|$定义如下：<br>$$<br>|f|=\sum_{v\in V}{f(s,v)}-\sum_{v\in V}{f(v,s)}<br>$$<br>流$f$的值是从源结点流出的总流量减去流入源结点的总流量。</p><p><strong>最大流问题</strong>中，给定一个流网络G，一个源结点s，一个汇点t，希望找到值最大的一个流。</p><h1 id="Ford-Fulkerson方法"><a href="#Ford-Fulkerson方法" class="headerlink" title="Ford-Fulkerson方法"></a>Ford-Fulkerson方法</h1><p>Ford-Fulkerson方法循环增加流的值，在开始的时候，对于所有结点$u,v\in V,f(u,v)=0$，给出的初始流值为0。在每一次迭代中，我们将图G的流值进行增加，方法就是在一个关联的“残存网络”$G_f$中寻找一条“增广路径”。一旦知道图$G_f$中一条增广路径的边，就可以很容易辨识出G中的一些具体的边，我们可以对这些边上的流量进行修改，从而增加流的值。虽然Ford-Fulkerson方法每次迭代都能增加流的值，但是对于图G的一条特定边来说，其流量可能增加也可能减少；对于某些边的流进行缩减可能是必要的，以便让算法可以将更多的流从源结点发送到汇点。重复对流进行这一过程，直到残存网络中不再存在增广路径为止。最大流最小切割定理将说明在算法终结时，该算法将获得一个最大流。</p><pre><code class="c">FORD-FILKERSON-METHOD(G,s,t)    initial flow f to 0    while there exists an augmenting path p in the residual network Gf        augment flow f along p    return f</code></pre><h2 id="残存网络"><a href="#残存网络" class="headerlink" title="残存网络"></a>残存网络</h2><p>给定流网络G和流量f，残存网络$G_f$由那些仍有空间对流量进行调整的边构成。流网络的一条边可以允许的额外容量等于该边的容量减去该边上的流量。如果差值为正，则将该条边置于图$G_f$中，并将其残存容量设置为$c_f(u,v)=c(u,v)-f(u,v)$。对于图G中的边来说，只有能够允许额外流量的边才能加入到图$G_f$中。如果边$(u,v)$的流量等于其容量，则$c_f(u,v)=0$，该条边将不属于图$G_f$</p><p>假定有一个流网络$G=(V,E)$，其源结点为s，汇点为t。设f为图G中的一个流，考虑结点对$u,v\in V$，定义残存容量$c_f(u,v)$如下：</p><img src="http://note.lizhihao999.cn/notes/20200824161054.png" style="zoom:67%;"><p>给定一个流网络$G=(V,E)$，和一个流$f$，则由$f$所诱导的图G的残存网络为$G_f=(V,E_f)$，其中<br>$$<br>E_f={(u,v)\in V\times V:c_f(u,v)&gt;0}<br>$$<br>如果$f$是G的一个流，$f’$是对应的残存网络$G_f$中的一个流，定义$f\uparrow f’$为流$f’$对流$f$的递增，他是一个从$V\times V$到R的函数：</p><img src="http://note.lizhihao999.cn/notes/20200824161132.png" style="zoom: 80%;"><p>因为在残存网络中将流量发送到反向边上等同于在原来的网络中缩减流量，所以将边$(u,v)$的流量增加$f’(u,v)$，但减少$f’(v,u)$。在残存网络中将流量推送回去也称为<strong>抵消操作</strong>。</p><h2 id="增广路径"><a href="#增广路径" class="headerlink" title="增广路径"></a>增广路径</h2><p>给定流网络$G=(V,E)$和流$f$，增广路径p是残存网络$G_f$中一条从源结点s到汇点t的简单路径。根据残存网络的定义，对于一条增广路径上的边$(u,v)$，我们可以增加其流量的幅度最大为$c_f(u,v)$，而不会违反原始流网络G对边$(u,v)$或$(v,u)$的容量限制。</p><p>称在一条增广路径p上能够为每条边增加的流量的最大值为路径p的残存容量：<br>$$<br>c_f(p)=\min{c_f(u,v):(u,v)属于路径p}<br>$$</p><h2 id="流网络的切割"><a href="#流网络的切割" class="headerlink" title="流网络的切割"></a>流网络的切割</h2><p>流网络$G=(V,E)$中的一个切割$(S,T)$将结点集合V划分为S和$T=V-S$两个集合，使得$s\in S,t\in T$，若$f$是一个流，则定义横跨切割$(S,T)$的净流量$f(S,T)$：<br>$$<br>f(S,T)=\sum_{u\in S}{\sum_{v\in T}{f(u,v)}}-\sum_{u\in S}{\sum_{v\in T}f(v,u)}<br>$$<br>切割$(S,T)$的容量是：<br>$$<br>c(S,T)=\sum_{u\in S}{\sum_{v\in T}{c(u,v)}}<br>$$<br>一个网络的最小切割是整个网络中容量最小的切割。</p><blockquote><p><strong>最大流最小切割定理</strong></p><p>设$f$为流网络$G=(V,E)$中的一个流，该流网络的源结点为$s$，汇点为$t$，则下面的条件是等价的：</p><ol><li>$f$是$G$的一个最大流</li><li>残存网络$G_f$不包括任何增广路径</li><li>$|f|=c(S,T)$，其中$(S,T)$是流网络G的某个切割</li></ol></blockquote><h1 id="基本Ford-Fulkerson算法"><a href="#基本Ford-Fulkerson算法" class="headerlink" title="基本Ford-Fulkerson算法"></a>基本Ford-Fulkerson算法</h1><p>假设流网络的容量$c(u,v)$都已经给出，如果边$(u,v)\notin  E$，则$c(u,v)=0$。</p><pre><code class="pseudocode">FORD-FILKERSON(G,s,t)    /* 将流f初始化为0 */    for each edge(u,v) in G.E        (u,v).f = 0    /* 重复在残存网络Gf中寻找一条增广路径p */    while there exsits a path p from s to t in the residual network Gf        cf(p) = min{cf(u,v): (u,v) is in p}        /* 使用残存容量cf(p)对路径p上的流f进行加赠 */        for each edge(u,v) in p            if (u,v) in E                (u,v).f = (u,v).f + cf(p)            else                (v,u).f = (v,u).f - cf(p)</code></pre><ol><li>2~3行：将流$f$初始化为0</li><li>4~9行while循环：重复在残存网络$G_f$中寻找一条增广路径p，然后使用残存容量$c_{f}(p)$来对路径p上的流$f$进行加增。路径p上每条残存边要么是原来网络中的一条边，要么是原来网络中的边的反向边。<ol><li>7~9行：针对每种情况对流进行相应的更新：<ul><li>如果残存边是原来网络中的一条边，则增加流量，否则缩减流量</li><li>当不再有增广路径时，流$f$就是最大流</li></ul></li></ol></li></ol><h2 id="运行时间"><a href="#运行时间" class="headerlink" title="运行时间"></a>运行时间</h2><p>Ford-Fulkerson算法的运行时间取决于算法第4行如何寻找增广路径。while循环的次数最多为$|f^*|$次，因为流量值在每次迭代中最少增加一个单位；每执行一次的时间为$O(E)$。从而整个Ford-Fulkerson算法的运行时间为$O(E|f^*|)$</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>所有结点对最短路径</title>
      <link href="2020/05/08/suan-fa-bi-ji/suo-you-jie-dian-dui-de-zui-duan-lu-jing/"/>
      <url>2020/05/08/suan-fa-bi-ji/suo-you-jie-dian-dui-de-zui-duan-lu-jing/</url>
      
        <content type="html"><![CDATA[<h1 id="Floyd算法"><a href="#Floyd算法" class="headerlink" title="Floyd算法"></a>Floyd算法</h1><p>Floyd算法利用<strong>动态规划</strong>来解决所有结点对最短路径问题，运行时间为$O(V^3)$。假设负权重的边可以存在，但不能存在负权重的环路。</p><p>使用<strong>邻接矩阵W</strong>来表示图，矩阵W是一个$n\times n$的矩阵W，该矩阵代表的是一个有n个结点的有向图$G=(V,E)$的边的权重，即$W=(w_{ij})$其中</p><img src="http://note.lizhihao999.cn/notes/20200824144945.png" style="zoom:67%;"><h2 id="最短路径的结构"><a href="#最短路径的结构" class="headerlink" title="最短路径的结构"></a>最短路径的结构</h2><p>Floyd算法考虑一条最短路径上的中间结点，即简单路径$p=&lt;v_1,v_2,..,v_n&gt;$上的中间结点指路径p上除了$v_1,v_n$之外的任意结点，将中间结点作为集合：${v_2,v_3,…,v_{n-1}}$</p><p>假定图G的所有结点为$V={1,2,..,n}$，考虑其中的一个子集${1,2,…,k}$，这里k是某个小于n的整数。对于任意结点对$i,j\in V$，考虑从结点$i$到结点$j$的所有中间结点均取自集合${1,2,…,k}$的路径，并且设$p$为其中权重最小的路径（$p$是简单路径）。Floyd算法利用路径$p$和从$i$到$j$之间中间结点均取自集合${1,2,…,k-1}$的最短路径之间的关系。该关系依赖于结点$k$是否是路径$p$上的一个中间结点。</p><ul><li><p>如果结点$k$不是路径$p$上的一个中间结点，则路径$p$上的所有中间结点都属于集合${1,2,..,k-1}$。因此从结点$i$到结点$j$的中间结点取自集合${1,2,…,k-1}$的一条最短路径也是从结点$i$到结点$j$的中间结点取自集合${1,2,…,k}$的一条最短路径。</p></li><li><p>如果结点$k$是路径$p$上的一个中间结点，则将路径$p$分解为$i\rightsquigarrow^{p_1}k\rightsquigarrow^{p_2}j$，如图所示。</p><img src="http://note.lizhihao999.cn/notes/20200824145123.png" style="zoom:67%;"><p>$p_1$是从结点$i$到结点k的中间结点全部取自集合${1,2,…,k}$的一条最短路径。事实上，因为$k$不是路径$p_1$上的中间结点，路径$p_1$上的所有中间结点都属于集合${1,2,…,k-1}$的一条最短路径。类似地，$p_2$是从结点$k$到结点$j$的中间结点全部取自集合${1,2,…,k-1}$的一条最短路径。</p></li></ul><h2 id="所有结点对最短路径问题的一个递归解"><a href="#所有结点对最短路径问题的一个递归解" class="headerlink" title="所有结点对最短路径问题的一个递归解"></a>所有结点对最短路径问题的一个递归解</h2><p>设$d_{ij}^{(k)}$为从结点$i$到结点$j$的所有中间结点全部取自集合${1,2,…,k}$的一条最短路径的权重。当$k=0$时，从结点$i$到结点$j$的一条不包括编号大于0的中间结点的路径将没有任何中间结点。这样的路径最多只有一条边，因此$d_{ij}^{(0)}=w_{ij}$。根据上面的讨论，递归定义:</p><img src="http://note.lizhihao999.cn/notes/20200824155308.png" style="zoom:67%;"><p>因为对于任何路径来说，所有的中间结点都属于集合${1,2,….n}$，矩阵$D^{(n)}=(d_{ij}^{(n)})$给出的就是最终答案：<br>$$<br>对于所有的i,j\in V,d_{ij}^{(n)}=\delta(i,j)<br>$$</p><h2 id="自底向上计算最短路径权重"><a href="#自底向上计算最短路径权重" class="headerlink" title="自底向上计算最短路径权重"></a>自底向上计算最短路径权重</h2><p>算法输入为一个$n\times n$的矩阵$W$，下面的算法返回的是最短路径权重矩阵$D^{n}$：</p><pre><code class="c">FLOYD(W)    n = W.rows    D^0 = W    for k=1 to n        let D^k = (d(i,j)^k) be a new n*n matrix        for i=1 to n            for j=1 to n                d(i,j)^k = min(d(i,j)^(k-1), d(i,k)^(k-1)+d(k,j)^(k-1))    return D^n</code></pre><h2 id="构建一条最短路径"><a href="#构建一条最短路径" class="headerlink" title="构建一条最短路径"></a>构建一条最短路径</h2><p>可以先计算最短路径权重矩阵D然后从D矩阵来构造前驱矩阵$\Pi$，或者在计算矩阵$D^{(k)}$的同时计算前驱矩阵$\Pi$。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;constexpr auto INFI = 1e9;constexpr auto NIL = -1;vector&lt;vector&lt;int&gt;&gt; floyd(vector&lt;vector&lt;int&gt;&gt; W, vector&lt;vector&lt;int&gt;&gt;&amp; P) {    int n = W.size();    vector&lt;vector&lt;int&gt;&gt; D = W;    for (int k = 0; k &lt; n; k++) {        for (int i = 0; i &lt; n; i++) {            for (int j = 0; j &lt; n; j++) {                if (D[i][j] &gt; D[i][k] + D[k][j]) {                    D[i][j] = D[i][k] + D[k][j];                    P[i][j] = k;                }            }        }    }    return D;}void print_matrix(vector&lt;vector&lt;int&gt;&gt; W) {    for (auto&amp; w : W) {        for (auto&amp; item : w) {            cout &lt;&lt; item &lt;&lt; " ";        }        cout &lt;&lt; endl;    }}// 打印最短路径void print_path(int a, int b, vector&lt;vector&lt;int&gt;&gt; P) {    cout &lt;&lt; a;    while (a != P[a][b]) {        if (P[a][b] &gt;= 0) {            cout &lt;&lt; "-&gt;" &lt;&lt; P[a][b];            a = P[a][b];        }        else {            cout &lt;&lt; endl;            return;        }    }    cout &lt;&lt; endl;}int main(){    int n;  // 结点数量    cin &gt;&gt; n;    vector&lt;vector&lt;int&gt;&gt; W(n);    vector &lt;vector&lt;int&gt;&gt; P(n);    for (int i = 0; i &lt; n; i++) {        W[i].resize(n, INFI);        W[i][i] = 0;        P[i].resize(n, NIL);    }    int a; // 边的数量    cin &gt;&gt; a;    for (int i = 0; i &lt; a; i++) {        int u, v, w;    // u、v：端点，w：边的权重        cin &gt;&gt; u &gt;&gt; v &gt;&gt; w;        W[u][v] = w;        P[u][v] = v;    }    print_matrix(W);    print_matrix(P);    vector&lt;vector&lt;int&gt;&gt; D = floyd(W, P);    print_matrix(D);    print_matrix(P);    print_path(0, 1, P);}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单源最短路径</title>
      <link href="2020/05/07/suan-fa-bi-ji/dan-yuan-zui-duan-lu-jing/"/>
      <url>2020/05/07/suan-fa-bi-ji/dan-yuan-zui-duan-lu-jing/</url>
      
        <content type="html"><![CDATA[<h1 id="最短路径问题"><a href="#最短路径问题" class="headerlink" title="最短路径问题"></a>最短路径问题</h1><p>在该问题中，给定一个带权重的有向图$G=(V,E)$和权重函数$w:E\to R$，该权重函数将每条边映射到实数值的权重上。图中一条路径$p=&lt;v_0,v_1,…,v_k&gt;$的<strong>权重</strong>$w(p)$是构成该路径的所有边的权重之和：<br>$$<br>w(p)=\sum_{i=1}^{k}{w(v_{i-1},v_i)}<br>$$<br>定义从结点u到结点v的<strong>最短路径权重</strong>$\delta(u,v)$：</p><img src="http://note.lizhihao999.cn/notes/20200824000613.png" style="zoom: 80%;"><p>从结点u到结点v的<strong>最短路径</strong>则定义为任何一条权重为$w(p)=\delta(u,v)$的从u到v的路径p</p><h1 id="最短路径的表示"><a href="#最短路径的表示" class="headerlink" title="最短路径的表示"></a>最短路径的表示</h1><p>给定图$G=(V,E)$，对于每个结点点v，维持一个**前驱结点$v.\pi$**。该前驱结点可能是另一个结点或者NIL。当给定结点v，且$v.\pi\ne NIL$时，从结点v开始将前驱结点链反转就是从s到v的一条最短路径。</p><p>我们对由$\pi$值引导的<strong>前驱子图</strong>$G_\pi=(V_\pi,E_\pi)$感兴趣。我们定义结点集$V_\pi$为图G中的前驱结点不为NIL的结点的集合，再加上源结点s，即<br>$$<br>V_\pi={v\in V:v.\pi\ne NIL}\bigcup{s}<br>$$<br>有向边集合$E_\pi$是由$V_\pi$中的结点的$\pi$值所诱导的边的集合，即<br>$$<br>E_\pi={(v.\pi,v)\in E:v\in V_\pi-{s}}<br>$$<br>本章算法所生成的$\pi$值具有以下性质：</p><p>在算法终止时，$G_\pi$是一棵“最短路径树”，包括从源结点s到每个可以从s到达的结点的一条最短路径。一棵根结点为s的最短路径树是一个有向子图$G’=(V’,E’)$，这里$V’\subseteq V,E’\subseteq E$，满足：</p><ol><li>V‘是图G中从源结点s可以到达的所有结点的集合；</li><li>G’形成一棵根结点为s的树；</li><li>对于所有结点$v\in V’$，图G‘中从结点s到结点v的唯一简单路径是图G中从结点s到结点v的一条最短路径。</li></ol><p>需要指出，最短路径不一定唯一，最短路径树也不一定唯一。</p><h1 id="松弛-relaxation-操作"><a href="#松弛-relaxation-操作" class="headerlink" title="松弛(relaxation)操作"></a>松弛(relaxation)操作</h1><blockquote><p>最短路径算法的核心技术是<strong>松弛</strong>。</p></blockquote><p>对于每一个结点v，维持一个属性$v.d$，用来记录从源结点s到结点v的最短路径权重的上界，称$v.d$为s到v的<strong>最短路径估计</strong>。使用下面运行时间为$\Theta(V)$的算法来<strong>对最短路径估计和前驱结点进行初始化</strong>：</p><pre><code class="pseudocode">INITIALIZE-SINGLE-SOURCE(G,s)    for each vertex v in G.V        v.d = infinit        v.pi = NIL    s.d = 0</code></pre><p>初始化之后，对于所有结点$v \in V$，我们有$v.\pi=NIL,s.d=0$，对于所有结点$v \in V-{s}$，我们有$v.d=\infin$。</p><p>对一条边的松弛过程为：首先测试是否可以对从s到v的最短路径进行改善。测试方法是：将从结点s到结点u之间的最短路径距离加上结点u与v之间的边权重，并与当前的s到v的最短路径估计进行比较，如果前者更小，则对$v.d$和$v.\pi$进行更新。松弛步骤可能降低最短路径的估计值$v.d$并更新v的前驱属性$v.\pi$。下面的伪代码执行对边$(u,v)$在$O(1)$时间内进行的松弛操作：</p><pre><code class="pseudocode">RELAX(u,v,w)    if v.d &gt; u.d+w(u,v)        v.d = u.d + w(u,v)        v.pi = u</code></pre><p><img src="http://note.lizhihao999.cn/notes/20200823225845.png" alt="《算法导论》松弛示例"></p><h1 id="最短路径和松弛操作的性质"><a href="#最短路径和松弛操作的性质" class="headerlink" title="最短路径和松弛操作的性质"></a>最短路径和松弛操作的性质</h1><ul><li><p><strong>三角不等式性质</strong></p><p>对于任何边$(u,v)\in E$，我们有$\delta (s,v)\le \delta(s,u)+w(u,v)$</p></li><li><p><strong>上界性质</strong></p><p>对于所有结点$v\in V$，总是有$v.d\ge\delta(s,v)$。一旦$v.d$的取值到达$\delta(s,v)$，其值不再发生变化。</p></li><li><p><strong>非路径性质</strong></p><p>如果从结点s到结点v之间不存在路径，则总是有$v.d=\delta(s,v)=\infin$</p></li><li><p><strong>收敛性质</strong></p><p>对于某些结点u，$v\in V$，如果$s\rightsquigarrow u\to v$是图G中的一条最短路径，并且在对边$(u,v)$进行松弛前的任意时间有$u.d=\delta(s,u)$，则在之后的所有时间有$v.d=\delta(s,v)$</p></li><li><p><strong>路径松弛性质</strong></p><p>如果$p = &lt;v_0,v_1,…,v_k&gt;$是从源结点$s=v_0$到结点$v_k$的一条最短路径，并且我们对p中的边所进行松弛的次序为$(v_0,v_1),(v_1,v_2),…,(v_{k-1},v_k)$，则$v_k.d=\delta(s,v_k)$。</p><p>该性质的成立与其他的松弛操作无关，即使这些操作是对p上的边所进行的松弛操作穿插进行的。</p></li><li><p><strong>前驱子图性质</strong></p><p>对于所有的结点$v\in V$，一旦$v.d=\delta(s,v)$，则前驱子图是一棵根结点为s的最短路径树。</p></li></ul><h1 id="Bellman-Ford算法"><a href="#Bellman-Ford算法" class="headerlink" title="Bellman-Ford算法"></a>Bellman-Ford算法</h1><p>Bellman-Ford算法解决的是<strong>一般情况下的单源最短路径问题</strong>，在这里，<strong>边的权重可以为负值</strong>。给定带权重的有向图$G=(V,E)$，和权重函数$w:E\to R$，Bellman-Ford算法返回一个布尔值，以表明是否存在一个从源结点可以到达的权重为负值的环路。如果存在这样一个环路，算法将告诉我们不存在解决方案。如果没有这种环路存在，算法将给出最短路径及它们的权重。</p><p>Bellman-Ford算法通过对边进行松弛操作来渐进地降低从源结点s到每个结点v的最短路径的估计值$v.d$，直到该估计值与实际最短路径权重$\delta(s,v)$相同为止。该算法返回TRUE值当且仅当输入图不包含可以从源结点到达的权重为负值的环路。</p><pre><code class="c">BELLMAN_FORD(G,w,s)    INITIALIZE-SINGLE-SOURCE(G,s)    // 对所有结点的d值和pi值进行初始化    for i=1 to |G.V|-1        for each edge(u,v) in G.E            RELAX(u,v,w)    for each edge(u,v) in G.E        if v.d &gt; u.d+w(u,v)            return FALSE    return TRUE</code></pre><ol><li>3~5行对图的每条边进行$|V|-1$次处理，每次处理对应一次循环，每次循环对每条边进行一次松弛操作。</li><li>6~8行检查图中是否存在权重为负值的环路并返回与之相适应的布尔值。</li></ol><p><img src="http://note.lizhihao999.cn/notes/20200823230510.png" alt="《算法导论》Bellman-Ford算法示例"></p><h2 id="运行时间"><a href="#运行时间" class="headerlink" title="运行时间"></a>运行时间</h2><ol><li>初始化时间：$\Theta(V)$</li><li>3~5行循环运行时间：一次循环的时间为$\Theta(E)$，一共进行$|V|-1$次循环</li><li>6~8行for循环：$O(E)$</li></ol><p>Bellman-Ford算法的总运行时间：$O(VE)$</p><h1 id="Dijkstra算法"><a href="#Dijkstra算法" class="headerlink" title="Dijkstra算法"></a>Dijkstra算法</h1><p>Dijkstra算法解决的是带权重的有向图上单源最短路径问题，该算法要求<strong>所有边的权重都为非负值</strong>，因此，我们假定对于所有的边$(u,v)\in E$，都有$w(u,v)\ge 0$。</p><p>Dijkstra算法在运行过程中维持的关键信息是一组结点集合$S$。从源结点s到该集合每个结点之间的最短路径已经被找到。算法重复从结点集$V-S$中选择最短路径估计最小的结点$u$，将$u$加入到集合$S$，然后对所有从$u$出发的边进行松弛。</p><p>在下面给出的方法中我们使用一个最小优先队列$Q$来保持结点集合，每个结点的关键值为其d值。</p><pre><code class="c">DIJKSTRA(G,w,s)    INITIALIZE-SINGLE-SOURCE(G,s)    // 对所有结点的d值和pi值进行初始化    S = Empty    // 将集合S初始化为一个空集    Q = G.V        // 对最小优先队列Q进行初始化，将所有结点V放入队列    while Q != Empty        u = EXTRACT-MIN(Q)        S = S + {u}        for each vertex v in G.Adj[u]            RELAX(u,v,w)</code></pre><ol><li>2行：对所有结点的d值和pi值进行初始化</li><li>3行：将集合S初始化为一个空集</li><li>4行：对最小优先队列Q进行初始化，将所有结点V放入队列</li><li>5~9行：始终维持不变式$Q=V-S$<ol><li>6行：从$Q=V-S$集合中抽取结点u，<strong>结点u为集合$V-S$中所有结点的最小最短路径估计</strong></li><li>7行：将结点u加入集合S，继续保持不变式</li><li>8~9行：对所有结点u发出的边$(u,v)$进行<strong>松弛操作</strong></li></ol></li></ol><h2 id="算法正确性"><a href="#算法正确性" class="headerlink" title="算法正确性"></a>算法正确性</h2><p>因为Dijkstra算法总是选择集合V-S中“最轻”或“最近”的结点加入集合S，所以该算法使用的是<strong>贪心策略</strong>。可以证明：使用贪心策略的Dijkstra算法确实可以计算出最短路径。</p><p>关键是证明这样一个事实：<strong>该算法在每次选择结点u加入集合S时，有$u.d=\delta(s,u)$.</strong></p><blockquote><p><strong>定理1</strong></p><p>Dijkstra算法运行在带权重的有向图$G=(V,E)$时，如果所有权重为非负值，则在算法终止时，对于所有结点$u\in V$，我们有$u.d=\delta(s,u)$</p></blockquote><p>证明：</p><blockquote><p>我们在算法中使用下面的循环不变式：</p><p>在算法5~9行while语句的每次循环开始前，对于每个结点$v\in S$，有$v.d=\delta(s,v)$</p></blockquote><p>只需要证明对于每个结点$u\in V$，当结点u被加入到集合S时，有$u.d=\delta(s,u)$。一旦证明，则可以使用上界欸性质来证明该等式在后续的所有时间内保持成立。</p><ol><li><p><strong>初始化</strong></p><p>初始时，$S=\empty$，因此循环不变式直接成立</p></li><li><p><strong>保持</strong></p><p>反证法证明：当结点u被加入到集合S时，有$u.d=\delta(s,u)$。</p><p>假设结点u是第一个加入到集合S时使得该方程不成立的结点，即$u.d\ne \delta(s,u)$</p><p>首先，初始结点s是第一个加入集合S的点，并且$s.d=\delta(s,s)=0$，所以结点s与结点u不同，即$s\ne u$</p><p>所以，当结点u加入集合S时，$S\ne\empty$。此时，一定存在某条从结点s到结点u的路径，否则根据非路径性质，有$u.d=\delta(s,u)=\infin$，违背假设$u.d\ne \delta(s,u)$。因为存在某条从结点s到结点u的路径，所以也存在一条从结点s到结点u的最短路径p。</p><p>将结点u加入集合S之前，路径p连接集合S中的结点s和集合$V-S$中的结点u；假设结点y是路径p上第一个满足$y\in V-S$的结点，设$x\in S$是结点y的前驱结点，如图所示，可以将路径p分解为$s\rightsquigarrow^{p_1}x\to y\rightsquigarrow^{p_2}u$（<strong>路径$p_1$或者$p_2$可能不包含任何边</strong>）</p><img src="http://note.lizhihao999.cn/notes/20200824104537.png" alt="定理1证明" style="zoom:80%;"><p>因为选择的结点u是第一个加入集合S并且$u.d\ne \delta(s,u)$的结点，所以当结点x加入集合S时，有$x.d=\delta(s,x)$，之后边$(x,y)$会被松弛，根据收敛性质可以得到：结点u加入集合S时，有$y.d=\delta(s,y)$</p><p>因为结点y是最短路径p上位于结点u之前的一个点，并且所有边的权重非负，所以有$\delta(s,y)\le\delta(s,u)$，因此<br>$$<br>y.d=\delta(s,y)\le\delta(s,u)\le u.d（上界性质）<br>$$<br>又因为，在选择结点u时，结点u和结点y都在集合$V-S$中，选中结点u，说明$u.d\le y.d$，所以上式的两个不等式都是等式成立，即<br>$$<br>y.d=\delta(s,y)=\delta(s,u)=u.d<br>$$<br>得到$u.d=\delta(s,u)$，与假设矛盾。因此，推断在结点u加入到集合S时，有$u.d=\delta(s,u)$，并且该等式在随后的所有时间内都保持成立。</p></li><li><p><strong>终止</strong></p><p>算法终止时，$Q=\empty$，又因为$Q=V-S$，说明$S=V$。因此，对于所有结点$u\in V$，有$u.d=\delta(s,u)$</p></li></ol><blockquote><p><strong>推论1</strong></p><p>如果在带权重的有向图$G=(V,E)$上运行Dijkstra算法，其中权重皆为非负值，源结点为s，则在算法终止时，前驱子图$G_{\pi}$是一棵根结点为s的最短路径树。</p></blockquote><h2 id="运行时间-1"><a href="#运行时间-1" class="headerlink" title="运行时间"></a>运行时间</h2><p>该算法执行三种优先队列操作来维持最小优先队列：</p><ul><li><code>INSERT</code>：$O(1)$</li><li><code>EXTRACT-MIN</code>：$O(V)$，需要搜索整个数组</li><li><code>DECREASE-KEY</code>：$O(1)$</li></ul><p>该算法对每个结点调用一次<code>INSERT</code>和<code>EXTRACT-MIN</code>操作，。因为每个结点仅被加入到集合S一次，邻接表<code>Adj[u]</code>中的每条边在整个算法运行期间也只被检查一次（<strong>for循环中</strong>）。所有邻接表中的边的总数为$|E|$，该for循环一共执行$|E|$次，即最多调用<code>DECREASE-KEY</code>$|E|$次。</p><p>Dijkstra算法的运行时间依赖于最小优先队列的实现。</p><p>如果利用编号$1\to|V|$来维持最小优先队列。这种情况下，我们将<code>v.d</code>的值存放在数组的第v个记录里。算法总运行时间为：$O(V^2+E)=O(V^2)$</p><p>实际上，我们可以将Dijkstra算法的运行时间改善到$O(V\lg{V}+E)$，方法是斐波那契堆来实现最小优先队列。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最小生成树</title>
      <link href="2020/05/06/suan-fa-bi-ji/zui-xiao-sheng-cheng-shu/"/>
      <url>2020/05/06/suan-fa-bi-ji/zui-xiao-sheng-cheng-shu/</url>
      
        <content type="html"><![CDATA[<p>用$G=(V,E)$表示连通无向图，并且对于每条边$(u,v)\in E$，为其赋予权重$w(u,v)$。我们希望找到一个无环子集$T\subseteq E$，既能够将所有的节点连接起来，又具有最小的权重。由于T是无环的，并且连通所有结点，因此T是一棵树，称T为（图G的）<strong>生成树</strong>。称求取该生成树的问题为<strong>最小生成树问题</strong>。</p><p>讨论的两种解决最小生成树问题的两种算法：Kruskal算法和Prim算法都是贪心算法。贪心算法的每一步必须在多个可能的选择中选择一种。贪心算法推荐选择在当前看来最好的选择。这种策略一般并不能保证找到一个全局最优的解决方案。但是，对于最小生成树问题来说，可以证明某些贪心策略确实能够找到一棵权重最小的生成树。</p><h1 id="最小生成树的形成"><a href="#最小生成树的形成" class="headerlink" title="最小生成树的形成"></a>最小生成树的形成</h1><p>假设有一个连通无向图$G=(V,E)$和权重函数$w:E\to R$，两种算法都采用贪心策略，但方式不同。贪心策略可以用下面的通用方式来表示。</p><p>该通用方式在每个时刻生长最小生成树的一条边，并在整个策略的实施过程中，管理一个遵守下述循环不变式的边集合A：<br>$$<br>在每遍循环之前，A是某棵最小生成树的一个子集<br>$$<br>在每一步，选择一条边$(u,v)$，将其加入到集合A中，使得A不违反循环不变式，即$A\bigcup{(u,v}$也是某棵最小生成树的子集。由于可以安全地将这种边加入到集合A而不会破坏A的循环不变式，因此称这样的边为集合A的<strong>安全边</strong>。</p><pre><code class="c">GENERIC-MST(G,w)    A = Ø    while A does not form a spanning tree        find an edge(u,v) that is safe for A        A = A∪{(u,v)}    return A</code></pre><p>使用循环不变式的方式：</p><ul><li><p><strong>初始化</strong></p><p>在算法第2行之后，集合A直接满足循环不变式。</p></li><li><p><strong>保持</strong></p><p>算法第3~5行循环通过只加入安全边来维持循环不变式。</p></li><li><p><strong>终止</strong></p><p>所有加入到集合A的边都属于某棵最小生成树，因此，算法第5行所返回的集合A必然是一颗最小生成树。</p></li></ul><p>该算法最关键的是第3行：找到一条安全边。这条安全边必然存在，因为在执行算法第3行时，循环不变式告诉我们存在一棵生成树T，满足$A\subseteq T$。在第2~4行的while循环体内，集合A一定是T的真子集，因此，必然存在一条边$(u,v)\in T$，使得$(u,v)\in T$，使得$(u,v)\in T$，使得$(u,v)\notin A$，并且$(u,v)$对于集合A是安全的。</p><p>Kruskal算法和Prim算法就是如何快速找到安全边的算法。</p><h1 id="Kruskal算法"><a href="#Kruskal算法" class="headerlink" title="Kruskal算法"></a>Kruskal算法</h1><p>也称“加边法”，初始时，最小生成树集合里面包含所有顶点，但不包含任何边，每迭代一次就选择一条满足要求的边加入到集合里。</p><pre><code class="c">MST-KRUSKAL(G,w)    A = Ø    for each vertex v∈G.V        MAKE-SET(v)    sort the edges of G.E into nondecreasing orger by weight w    // 按升序对边进行排序    for each edge(u,v)∈G.E, taken in nondecreasing order by weight        if FIND-SET(u)≠FIND-SET(v)    // 判断结点u，v是否属于同一棵树            A=A∪{(u,v)}            UNION(u,v)    // 合并两棵树    return A</code></pre><ol><li>2~4行将集合A初始化为一个空集合，并创建$|V|$棵树，每棵树包含一个结点。</li><li>5~9行的<strong>for循环</strong>按照权重从低到高的次序对每条边逐一进行检查。对于每条边$(u,v)$来说，该循环将检查端点u和端点v是否属于同一棵树。<ul><li>如果是，该条边不能加入到森林里，否则会形成环路；</li><li>如果不是，两个端点分别属于不同的树，算法第8行将该条边加入集合A，第9行将两棵树中的结点进行合并。</li></ul></li></ol><p><img src="http://note.lizhihao999.cn/notes/20200823140749.png" alt="《算法导论》示例"></p><h2 id="运行时间"><a href="#运行时间" class="headerlink" title="运行时间"></a>运行时间</h2><ol><li>第2行对集合A进行初始化：$O(1)$</li><li>第5行对边进行排序：$O(E\lg{E})$</li><li>第6~9行的for循环，执行$O(E)$个FIND-SET和UNION操作以及$|V|$个MAKE-SET操作，总运行时间为：$O((V+E)\alpha(V))$</li></ol><p>$\alpha$是定义的一个增长非常缓慢的函数，假定图G是连通的，则有$|E|\ge |V|-1$，所以不相交集合操作的时间代价为$O(E\alpha(V))$。而且，由于$\alpha(|V|)=O(\lg{V})=O(\lg{E})$，Kruskal算法的总运行时间为$O(E\lg{E})$。</p><h2 id="正确性证明"><a href="#正确性证明" class="headerlink" title="正确性证明"></a>正确性证明</h2><h3 id="贪心选择性"><a href="#贪心选择性" class="headerlink" title="贪心选择性"></a>贪心选择性</h3><p>只需证明每一步得到的边的集合，都是最小生成树的子集。</p><blockquote><p><strong>定理1</strong></p><p>设$(u,v)$是G中权值最小的边，则必有一棵最小生成树包含边$(u,v)$</p></blockquote><p>证明：</p><p>设T是G的一棵最小生成树，若$(u,v)\in T$，结论成立；</p><p>否则如图所示，在T中添加$(u,v)$边，产生环，删除环中不同于$(u,v)$的权值最小的边$(x,y)$，得到T’<br>$$<br>w(T’)=w(T)-w(x,y)+w(u,v)\le w(T)<br>$$<br>与假设中T为最小生成树矛盾</p><p>所以定理1成立</p><img src="http://note.lizhihao999.cn/notes/20200823150547.png" alt="变换" style="zoom:50%;"><h3 id="优化子结构"><a href="#优化子结构" class="headerlink" title="优化子结构"></a>优化子结构</h3><blockquote><p><strong>定理2</strong></p><p>给定连通无向图$G=(V,E)$和权重函数$w:E\to R$，$(u,v)\in E$是G中权值最小的边。设T是G的包含$(u,v)$的一棵最小生成树，则$T-(u,v)$是$G-(u,v)$的一棵最小生成树。</p></blockquote><p>证明：</p><p>由于$T-(u,v)$是不含回路的连通图且包含了$G-(u,v)$的所有顶点，因此，$T-(u,v)$是$G-(u,v)$的一棵生成树。</p><p>假设$T-(u,v)$不是$G-(u,v)$生成代价最小的一棵生成树，则存在$G-(u,v)$的生成树T’，使得$w(T’)&lt;w(T-(u,v))$。</p><p>其中，T’包含顶点$G-(u,v)$且是连通的，因此$T’’=T’+(u,v)$包含G的所有顶点且不含回路，所以T’’是G的一棵生成树<br>$$<br>w(T’’)=w(T’)+w(u,v)&lt;w(T-(u,v))+w(u,v)=w(T)<br>$$<br>与T是G的最小生成树的假设矛盾，所以定理2成立。</p><h1 id="Prim算法"><a href="#Prim算法" class="headerlink" title="Prim算法"></a>Prim算法</h1><p>也称“加点法”，每次迭代选择代价最小的边对应的点，加入到最小生成树中， 算法从某一顶点开始，逐渐长大直到覆盖整个连通网的所有顶点。</p><p>连通图G和最小生成树的根结点r将作为算法的输入。算法执行过程中，所有不在树A中的结点都存放在一个基于<code>key</code>属性的<strong>最小优先队列Q</strong>中，对于每个结点v，属性<code>v.key</code>保存的是连接v和树中结点的所有边中最小边的权重，如果不存在这样的边，则<code>v.key=∞</code>。属性<code>v.Π</code>给出的是结点v在树中的父节点。Prim算法将GENERIC-MST中的集合A维持在<br>$$<br>A={(v,v.\pi):v\in V-{r}-Q}<br>$$<br>的状态下。</p><p>当Prim算法终止时，最小优先队列Q将为空，而G的最小生成树A则是：<br>$$<br>A={(v,v.\pi):v\in V-{r}}<br>$$</p><pre><code class="c">MST-PRIM(G,w,r)    for each u∈G.V        u:key=∞        u:Π=NIL    r:key=0    Q=G.V    while Q≠Ø        u=EXTRACT-MIN(Q)        for each v∈D.Adj[u]        if v∈Q and w(u,v)&lt;v.key            v.Π=u            v.key=w(u,v)</code></pre><ol><li><p>2~6行将每个结点的<code>key</code>值设置为∞（除根结点r外，根结点r的<code>key</code>值设置为0，以便使该结点成为第一个被处理的结点），将每个结点的父节点设置为<code>NIL</code>，并对最小优先队列Q进行初始化，使其包含图中所有结点。</p></li><li><p>7~12行的每遍循环之前：</p><ol><li>$A={(v,v.\pi):v\in V-{v}-Q}$</li><li>已经加入到最小生成树的结点为集合$V-Q$</li><li>对于所有的结点$v\in Q$，如果$v.\pi\ne NIL$，则$v.key&lt;∞$并且$v.key$是连接结点v和最小生成树中某个结点的边$(v,v.\pi)$的权重</li></ol><p>算法第8行将找出结点$u\in Q$，该结点是某条横跨切割$(V-Q,Q)$的轻量级边的一个端点（第1次循环时例外，此时因为算法第5行，所以有u=r）。接着将结点u从队列Q中删除，并将其加入到集合V-Q中，也就是将边$(u,u.\pi)$加入到集合A中。</p><p>9~12行的for循环将每个与u邻接但不在树中的结点v的key和Π值进行更新，从而维持循环不变式的第3部分成立。</p></li></ol><p><img src="http://note.lizhihao999.cn/notes/20200823172032.png" alt="《算法导论》示例"></p><h2 id="运行时间-1"><a href="#运行时间-1" class="headerlink" title="运行时间"></a>运行时间</h2><p>Prim算法的运行时间取决于最小优先队列Q的实现方式。</p><ol><li><strong>while循环</strong>：一共执行$|V|$次</li><li><strong>EXTRACT-MIN操作：</strong>单次操作$O(\lg{V})$，总时间为$O(V\lg{V})$</li><li><strong>for循环：</strong>$O(E)$</li></ol><p>总时间代价为：<br>$$<br>O(V\lg{V}+E\lg{V})=O(E\lg{V})<br>$$<br>从渐进意义上来说，Prim算法与Kruskal算法的运行时间相同。</p><h2 id="算法正确性"><a href="#算法正确性" class="headerlink" title="算法正确性"></a>算法正确性</h2><h3 id="贪心选择性-1"><a href="#贪心选择性-1" class="headerlink" title="贪心选择性"></a>贪心选择性</h3><blockquote><p><strong>定理3</strong></p><p>设$(u,v)$是G中与顶点u关联的权值最小的边，则必有一棵最小生成树包含边$(u,v)$</p></blockquote><p>证明：</p><p>设T是G的一棵最小生成树，若$(u,v)\in T$，结论成立；</p><p>否则，如图所示，在T中添加$(u,v)$边，产生环，环中顶点u的度为2，即存在$(u,v’)\in T$，删除环中的边$(u,v’)$得到T’<br>$$<br>w(T’)=w(T)-w(u,v’)+w(u,v)\le w(T)<br>$$<br>与T为最小生成树的假设矛盾，所以定理3成立。</p><h3 id="最优子结构"><a href="#最优子结构" class="headerlink" title="最优子结构"></a>最优子结构</h3><p>与Kruskal算法最优子结构的证明相同。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>哈夫曼编码</title>
      <link href="2020/05/05/suan-fa-bi-ji/ha-fu-man-bian-ma/"/>
      <url>2020/05/05/suan-fa-bi-ji/ha-fu-man-bian-ma/</url>
      
        <content type="html"><![CDATA[<p>哈夫曼编码可以很有效地压缩数据，通常可以节省20%-90%的空间，具体压缩率依赖于数据的特性。我们将带压缩数据看作字符序列，根据每个字符的出现频率，哈夫曼贪心算法构造出字符串的最优二进制表示。</p><blockquote><p><strong>变长编码</strong></p><p>变长编码可以达到比定长编码好得多的压缩率，其思想是赋予高频字符短码字，赋予低频字符长码字。</p><p><strong>前缀码</strong></p><p>即没有任何码字是其他码字的前缀。前缀码的作用是简化解码过程。</p></blockquote><p>解码过程需要前缀码的一种方便的表示方式，以便我们可以容易地截取开始码字。一种二叉树表示可以满足这种要求，其叶节点为给定的字符。字符的二进制码字用从根节点</p><p>到该字符节点的简单路径表示。其中<strong>“0”表示转向“左孩子”，“1”表示转向“右孩子”</strong>。</p><p>文件的最优编码方案总是对应一棵<strong>满二叉树</strong>，即每个非叶节点都有两个孩子节点。所以，若C为字母表且所有字符的出现频率均为正数，则最优前缀码对应的树恰有$|C|$个叶节点，每个叶节点对应字母表中的一个字符，且恰有$|C|-1$个内部节点。</p><p>给定一棵对应前缀码的树T，可以轻易计算出编码一个文件需要多少个二进制位。对于字母表C中的每个字符c，令属性<code>c.freq</code>表示c在文件中出现的频率， 令$d_T(c)$（$d_T(c)$也是字符c的码字长度）表示c的叶节点在树中的深度。则编码文件需要：<br>$$<br>B(T)=\sum_{c\in C}{c.freq*d_{T}(c)}<br>$$<br>个二进制位，将$B(T)$定义为<strong>T的代价</strong>。</p><h1 id="构建哈夫曼编码"><a href="#构建哈夫曼编码" class="headerlink" title="构建哈夫曼编码"></a>构建哈夫曼编码</h1><p>假定C是一个n个字符的集合，其中每个字符$c\in C$都是一个对象，其属性<code>c.freq</code>给出字符的出现频率。算法自底向上地构造出对应最优编码地二叉树T。从$|C|$个叶节点开始，执行$|C|-1$个<strong>合并</strong>操作，创建出最终的二叉树。算法使用一个以$freq$为关键字的最小优先队列Q，以识别两个最低频率的对象将其合并。当合并两个对象时，得到的新对象的频率设置为原来两个对象的频率之和。</p><pre><code class="c">HUFFMAN(C)n = |C|Q = Cfor i=1 to n-1    allocate a new node z    z.left = x = EXTRACT-MIN(Q)    z.right = y = EXTRACT-MIN(Q)    z.freq = x.freq + y.freq    INSERT(Q,z)return EXTRACT-MIN(Q)</code></pre><p><img src="http://note.lizhihao999.cn/notes/20200822164521.png" alt="算法过程——《算法导论》"></p><h1 id="算法正确性"><a href="#算法正确性" class="headerlink" title="算法正确性"></a>算法正确性</h1><p>为了证明贪心HUFFMAN算法正确，需要证明确定最优前缀码的问题具有贪心选择和最优子结构性质。</p><h2 id="1-贪心选择性质"><a href="#1-贪心选择性质" class="headerlink" title="1. 贪心选择性质"></a>1. 贪心选择性质</h2><blockquote><p><strong>引理1</strong></p><p>令C为一个字母表，其中每个字符$c\in C$都有一个频率<code>c.freq</code>。令x和y是C中频率最低的两个字符。那么存在C的一个最优前缀码，x和y的码字长度相同，且只有最后一个二进制位不同。</p></blockquote><p>证明思路：令T表示任意一个最优前缀码所对应的编码树（最优前缀码编码树不唯一），对其进行修改，得到表示另外一个最优前缀码的编码树，使得在新树种，x和y是深度最大的兄弟叶结点。这样构造出的树，x和y的码字长度相同，且只有最后一位不同。</p><p>证明：</p><p>令a，b是T中深度最大的兄弟叶结点。不失一般性，假定$a.freq\le b.freq,\quad x.freq\le y.freq$。又因为x，y的频率最低，所以$a.freq\ge x.freq,\quad b.freq\ge y.freq$</p><p>存在可能性，$x.freq=a.freq或y.freq=b.freq$；如果$x.freq=b.freq$，则$x.freq=b.freq=a.freq=y.freq$，此时引理显然成立；故假设$x.freq\ne b.freq$，也即$a.freq=b.freq和a.freq=x.freq$不同时成立。</p><p>在T中交换x和a得到一棵新树T‘，在T’中交换y和b得到新树T”，则在T”中x和y是深度最深的两个兄弟节点。计算T和T’的代价差：</p><p>$B(T)-B(T’)=\sum_{c\in C}{c.freq\cdot d_{T}(c)}-\sum_{c\in C}{c.freq\cdot d_{T’}(c)}$</p><p>​                                   $=[x.freq\cdot d_{T}(x)+a.freq\cdot d_{T}(a)]-[x.freq\cdot d_{T’}(x)+a.freq\cdot d_{T’}(a)]$</p><p>​                                   $=[x.freq\cdot d_{T}(x)+a.freq\cdot d_{T}(a)]-[x.freq\cdot d_{T}(a)+a.freq\cdot d_{T}(x)]$    <strong>(x在T’中的位置就是a在T中的位置)</strong></p><p>​                                   $=[x.freq\cdot d_{T}(x)-a.freq\cdot d_{T}(x)]-[x.freq\cdot d_{T}(a)-a.freq\cdot d_{T}(a)]$</p><p>​                                   $=(a.freq-x.freq)(d_{T}(a)-d_{T}(x))$</p><p>​                                   $\ge 0$    ($a.freq-x.freq和d_{T}(a)-d_{T}(x)$都非负)</p><p>类似，$B(T’)-B(T’’)\ge 0$，又因为<strong>T是最优的</strong>，所以$B(T)=B(T’)=B(T’’)$，即<strong>T’’也是最优的</strong>，引理成立。</p><p><img src="http://note.lizhihao999.cn/notes/20200822175055.png" alt="《算法导论》图例说明"></p><p>引理1说明，不失一般性，通过合并来构造最优树的过程，可以从合并出现频率最低的两个字符的贪心选择开始。</p><h2 id="2-最优子结构性质"><a href="#2-最优子结构性质" class="headerlink" title="2. 最优子结构性质"></a>2. 最优子结构性质</h2><blockquote><p><strong>引理2</strong></p><p>令C为一个给定的字母表，其中每个字符$c\in C$都定义了一个频率<code>c.freq</code>。令x和y是C中频率最低的两个字符。令C’为C去掉字符x和y，加入一个新字符z后得到的字母表，即$C’=C-{x,y}\bigcup{z}$。类似C，也为C’定义<code>freq</code>，不同之处只是<code>z.freq=x.freq+y.freq</code>。令T’为字母表C’的任意一个最优前缀码对应的编码树。将T’中叶结点z替换为一个以x和y为孩子的内部节点，得到树T，T表示字母表C的一个最优前缀码。</p></blockquote><p>证明：</p><p>首先表示:<br>$$<br>B(T’)=B(T)-x.freq-y.freq<br>$$<br>使用反证法进行证明。假定T对应的前缀码并不是C的最优前缀码。存在最优编码树T’’满足$B(T’’)&lt;B(T)$。不失一般性（引理1），T’’包含兄弟节点x和y。令T’’’为将T’’中x、y及他们的父节点替换为叶结点z得到的树，其中<code>z.freq=x.freq+y.freq</code>。于是<br>$$<br>B(T’’’)=B(T’’)-x.freq-y.freq&lt;B(T)-x.freq-y.freq=B(T’)<br>$$<br>与T’对应C’的一个最优前缀码的假设矛盾。因此，T必然表示字母表C的一个最优前缀码。</p><h2 id="3-最优性质"><a href="#3-最优性质" class="headerlink" title="3. 最优性质"></a>3. 最优性质</h2><blockquote><p><strong>定理1</strong></p><p>过程HUFFMAN会生成一个最优前缀码。</p></blockquote><p>证明： 由引理1、2可得到。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>活动选择问题</title>
      <link href="2020/05/04/suan-fa-bi-ji/huo-dong-xuan-ze-wen-ti/"/>
      <url>2020/05/04/suan-fa-bi-ji/huo-dong-xuan-ze-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>有一个n个活动的集合，$S={a_1,a_2,…,a_n}$，这些活动使用同一个资源（一个教室），而这个资源在某个时刻只能供一个活动使用。</p><p>每个活动都有一个$开始时间s_i$和一个$结束时间f_i$，其中$0\le s_i&lt;f_i&lt;\infin$。如果被选中。任务$a_i$发生在半开时间区间$[s_i,f_i)$期间。</p><p>如果两个活动$a_i$和$a_j$满足$[s_i,f_i)$和$[s_j,f_j)$不重叠，则称它们是<strong>兼容的</strong>。</p><p>在<strong>活动选择问题</strong>中，我们希望选出一个<strong>最大兼容活动集</strong>。</p><h1 id="问题假设"><a href="#问题假设" class="headerlink" title="问题假设"></a>问题假设</h1><p>活动已经按<strong>结束时间的单调递增顺序</strong>排序：<br>$$<br>f_1\le f_2\le f_3\le …\le f_{n-1}\le f_n<br>$$</p><h1 id="设计算法"><a href="#设计算法" class="headerlink" title="设计算法"></a>设计算法</h1><h2 id="最优子结构"><a href="#最优子结构" class="headerlink" title="最优子结构"></a>最优子结构</h2><ul><li>$S_{ij}$：在$a_i$活动结束之后，且在$a_j$开始之前结束的所有活动的集合</li><li>$A_{ij}$：$S_{ij} $的最大相互兼容的活动子集</li></ul><p>设$A_{ij}$包含活动$a_k$，$S_{ij}$中最大兼容任务子集</p><ul><li> $A_{ij}$包含$|A_{ij}|=|A_{ik}|+|A_{kj}|+1$个活动</li><li> $A_{ij}=A_{ik}\bigcup{a_k}\bigcup A_{kj}$</li></ul><h2 id="贪心选择"><a href="#贪心选择" class="headerlink" title="贪心选择"></a>贪心选择</h2><ul><li><p><strong>选择所有可选活动中，最早结束的活动</strong></p><p><strong>证明：</strong><br>$$<br>考虑任意非空子问题S_k，令a_m是S_k种结束时间最早的活动，则a_m在S_k的某个最大兼容活动子集中<br>$$<br>令$A_k$是$S_k$的一个最大兼容活动子集，且$a_m$是$A_k$中结束时间最早的活动。</p><ul><li><p>若$a_j=a_m$，则已经证明$a_m$在$S_k$的某个最大兼容活动子集中</p></li><li><p>若$a_j\ne a_m$，令集合$A’_k=A_k-{a_j}\bigcup{a_m}$，即：将$A_k$中的$a_j$替换为$a_m$。</p><p>$\because A_k$中的活动都是不相交的，$a_j$是$A_k$中结束时间最早的活动，并且$f_m\le f_j$</p><p>$\therefore A’_{k}$中的活动都是不相交的</p><p>$\because |A’_k|=|A_k|$</p><p>$\therefore A’_k$也是$S_k$的一个最大兼容活动子集</p></li></ul></li><li><p>选择所有可选活动中，最晚开始的活动</p><p><strong>证明</strong>：<br>$$<br>考虑任意非空子问题S_k，令a_m是S_k种开始时间最晚的活动，则a_m在S_k的某个最大兼容活动子集中<br>$$<br>令$A_k$是$S_k$的一个最大兼容活动子集，且$a_m$是$A_k$中开始时间最晚的活动。</p><ul><li><p>若$a_j=a_m$，则已经证明$a_m$在$S_k$的某个最大兼容活动子集中</p></li><li><p>若$a_j\ne a_m$，令集合$A’_k=A_k-{a_j}\bigcup{a_m}$，即：将$A_k$中的$a_j$替换为$a_m$。</p><p>$\because A_k$中的活动都是不相交的，$a_j$是$A_k$中开始时间最晚的活动，并且$s_m\ge s_j$</p><p>$\therefore A’_{k}$中的活动都是不相交的</p><p>$\because |A’_k|=|A_k|$</p><p>$\therefore A’_k$也是$S_k$的一个最大兼容活动子集</p></li></ul></li></ul><h2 id="递归贪心算法"><a href="#递归贪心算法" class="headerlink" title="递归贪心算法"></a>递归贪心算法</h2><pre><code class="pseudocode">RECURSIVE-ACTIVITY-SELECTOR(s,f,k,n)    m = k+1    while m&lt;=n and s[m]&lt;f[k] do        m = m+1        if m &lt;= n do            return {a[m]} and RECURSIVE-ACTIVITY-SELECTOR(s,f,m,n)        else             return</code></pre><h2 id="迭代贪心算法"><a href="#迭代贪心算法" class="headerlink" title="迭代贪心算法"></a>迭代贪心算法</h2><pre><code class="pseudocode">GREEDY-ACTIVITY-SELECTOR(s,f)    n = s.length    A={a[1]}    k=1    for m=2 to n do        if s[m]&gt;=f[k] do            A.append{a[m]}            k = m    return A</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>贪心算法</title>
      <link href="2020/05/03/suan-fa-bi-ji/tan-xin-suan-fa/"/>
      <url>2020/05/03/suan-fa-bi-ji/tan-xin-suan-fa/</url>
      
        <content type="html"><![CDATA[<p>贪心算法通过做出一系列选择来求出问题的最优解。在每个决策点，它做出在当时看来最佳的选择。这种启发式策略不能保证总能找到最优解，但对某些问题确实能够得到最优解。</p><h1 id="设计步骤"><a href="#设计步骤" class="headerlink" title="设计步骤"></a>设计步骤</h1><ol><li><p>转换最优化问题形式：对其做出一次选择后，只剩下一个子问题需要求解</p></li><li><p>证明做出贪心选择后，原问题总是存在最优解，即贪心选择总是安全的</p></li><li><p>证明做出贪心选择后，剩余的子问题，满足性质：其最优解与贪心选择组合即可得到原问题的最优解</p></li></ol><h1 id="贪心选择性质"><a href="#贪心选择性质" class="headerlink" title="贪心选择性质"></a>贪心选择性质</h1><p><strong>我们可以通过做出局部最优选择来构造全局最优解</strong>，即直接做出在当前问题看来最优的选择，不必考虑子问题的解。</p><h1 id="最优子结构"><a href="#最优子结构" class="headerlink" title="最优子结构"></a>最优子结构</h1><p>当应用贪心算法时，我们只需要论证：将子问题的最优解与贪心选择组合在一起就可以得到原问题的最优解。这种方法隐含地对子问题使用了数学归纳法，证明了在每个步骤进行贪心选择都会生成原问题地最优解。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最长公共子序列</title>
      <link href="2020/05/02/suan-fa-bi-ji/zui-chang-gong-gong-zi-xu-lie/"/>
      <url>2020/05/02/suan-fa-bi-ji/zui-chang-gong-gong-zi-xu-lie/</url>
      
        <content type="html"><![CDATA[<h1 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h1><ul><li><p><strong>子序列</strong><br>$$<br>对于给定序列X=&lt;x_1,x_2,…,x_m&gt;，Z=&lt;z_1,z_2,…z_k&gt;<br>$$<br>$$<br>存在一个严格递增的X的下标序列&lt;i_1,i_2,…,i_k&gt;，对所有j=1,2,…,k<br>$$</p><p>$$<br>满足x_{i_j}=z_j<br>$$</p><p>则称Z为X的子序列</p></li><li><p><strong>公共子序列</strong></p><p>Z既是X的子序列，也是Y的子序列</p></li><li><p><strong>问题描述</strong></p><p>给定两个序列<br>$$<br>X=&lt;x_1,x_2,…,x_m&gt;,Y=&lt;y_1,y_2,…,y_n&gt;<br>$$<br>求X和Y的<strong>长度最长</strong>的公共子序列</p></li></ul><h1 id="应用动态规划算法"><a href="#应用动态规划算法" class="headerlink" title="应用动态规划算法"></a>应用动态规划算法</h1><h2 id="1-刻画最长公共子序列的特征"><a href="#1-刻画最长公共子序列的特征" class="headerlink" title="1. 刻画最长公共子序列的特征"></a>1. 刻画最长公共子序列的特征</h2><h3 id="LCS最优子结构"><a href="#LCS最优子结构" class="headerlink" title="LCS最优子结构"></a>LCS最优子结构</h3><p>令$$X=&lt;x_1,x_2,…,x_m&gt;,Y=&lt;y_1,y_2,…,y_n&gt;$$为两个序列，$$Z=&lt;z_1,z_2,…,z_k&gt;$$是X和Y的任意LCS</p><ul><li>如果$x_m=y_n，则z_k=x_m=y_n且Z_{k-1}是X_{m-1}和Y_{n-1}的一个LCS$</li><li>如果$x_m\ne y_n，那么z_k\ne x_m\implies Z是X_{m-1}和Y的一个LCS$</li><li>如果$x_m\ne y_n，那么z_k\ne y_n\implies Z是X和Y_{n-1}的一个LCS$</li></ul><h2 id="2-一个递归解"><a href="#2-一个递归解" class="headerlink" title="2. 一个递归解"></a>2. 一个递归解</h2><p><img src="http://note.lizhihao999.cn/notes/20200819163534.png" alt="递归解形式"></p><h2 id="3-计算LCS的长度"><a href="#3-计算LCS的长度" class="headerlink" title="3. 计算LCS的长度"></a>3. 计算LCS的长度</h2><pre><code class="pseudocode"> LCS-LENGTH(X,Y) m &lt;- X.length n &lt;- Y.lengthlet c[0...m][0...n] be new tablefor i&lt;-1 to m do    c[i,0] &lt;- 0for i&lt;-1 to n do    c[0,j] &lt;- 0for i&lt;-1 to m do    for j&lt;-1 to n do        if X[i]==Y[j] do            c[i][j] &lt;- c[i-1][j-1] + 1        else             c[i][j] &lt;- max{c[i-1][j], c[i][j-1]} return c</code></pre><h2 id="4-构造LCS"><a href="#4-构造LCS" class="headerlink" title="4. 构造LCS"></a>4. 构造LCS</h2><p>这里没有使用多余的表来存储顺序，而是通过$c[i-1][j],c[i][j-1],c[i-1][j-1]$的大小关系来判断顺序</p><ul><li>如果$c[i][j]==0$，则结束</li><li>如果$c[i-1][j]==c[i][j]$，则对$i=i-1,j=j$继续</li><li>如果$c[i][j-1]==c[i][j]$，则对$i=1,j=j-1$继续</li><li>如果$c[i-1][j-1]+1==c[i][j]$，则对$i=i-1,j=j-1$继续，并输出$X[i]$</li></ul><pre><code class="pseudocode">PRINT-LCS(X, c, i, j)if c[i][j] == 0 do    return/* 如果c[i-1][j]==c[i][j]，则对i=i-1,j=j继续 */if c[i-1][j] == c[i][j] do    PRINT-LCS(X, c, i-1, j)/* 如果c[i][j-1]==c[i][j]，则对i=i,j=j-1继续 */else if c[i][j-1] == c[i][j] do    PRINT-LCS（X, c, i, j-1)/* 如果c[i-1][j-1]+1==c[i][j]，则对i=i-1,j=j-1继续 */else    PRINT-LCS(X, c, i-1, j-1)    print(X[i])</code></pre><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;int my_max(int a, int b) {    return (a &gt;= b) ? a : b;}vector&lt;vector&lt;int&gt;&gt; lcs_length(string X, string Y){    int m = X.size();    int n = Y.size();    vector&lt;vector&lt;int&gt;&gt;c(m+1);    for (int i = 0; i &lt;= m; i++) {        c[i].resize(n+1);    }    for (int i = 1; i &lt;= m; i++) {        c[i][0] = 0;    }    for (int j = 1; j &lt;= n; j++) {        c[0][j] = 0;    }    for (int i = 1; i &lt;= m; i++) {        for (int j = 1; j &lt;= n; j++) {            /* 注意对应X和Y的索引 */            if (X[i-1] == Y[j-1]) {                c[i][j] = c[i - 1][j - 1] + 1;            }            else {                c[i][j] = my_max(c[i][j - 1], c[i - 1][j]);            }        }    }    return c;}void print_lcs(string X, vector&lt;vector&lt;int&gt;&gt; c, int i, int j){    if (c[i][j] == 0) {        return;    }    if (c[i-1][j] == c[i][j]) {        print_lcs(X, c, i - 1, j);    }    else if (c[i][j - 1] == c[i][j]) {        print_lcs(X, c, i, j - 1);    }    else {        print_lcs(X, c, i - 1, j - 1);        cout &lt;&lt; X[i - 1];    }}int main(){    string X;    string Y;    cin &gt;&gt; X;    cin &gt;&gt; Y;    int m = X.size();    int n = Y.size();    vector&lt;vector&lt;int&gt;&gt; c = lcs_length(X, Y);    cout &lt;&lt; c[m][n] &lt;&lt; endl;    print_lcs(X, c, m, n);}</code></pre><h1 id="算法改进"><a href="#算法改进" class="headerlink" title="算法改进"></a>算法改进</h1><h2 id="二维数组"><a href="#二维数组" class="headerlink" title="二维数组"></a>二维数组</h2><p>对于计算某个位置的$c[i][j]$只需要三个表项：$c[i-1][j-1],c[i-1][j],c[i][j-1]$，所以其实只需要当前一行和上一行的表项数值，故利用利用一个二维数组记录当前行和上一行的数值即可</p><table><thead><tr><th align="center">$c[i-1][j-1]$</th><th align="center">$c[i-1][j] $</th></tr></thead><tbody><tr><td align="center">$c[i][j-1]$</td><td align="center">$c[i][j] $</td></tr></tbody></table><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><pre><code class="pseudocode">/* 假设X长度m&lt;=Y长度n */LCS-LENGTH(X, Y)m &lt;- X.lengthn &lt;- Y.lengthlet c[2][m] be new tablefor i&lt;-1 to n do    for j&lt;-1 to m do        if X[j] == Y[i] do            c[(i+1)%2][j] &lt;- c[i%2][j-1]+1        else            c[(i+1)%2][j] &lt;- max{c[(i+1)%2][j-1], c[i%2][j]}return c[n%2][m]</code></pre><h3 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h3><pre><code class="cpp">int lcs_pro(string X, string Y){    int m = X.size();    int n = Y.size();    vector&lt;vector&lt;int&gt;&gt; c(2);    c[1].resize(m + 1);    c[0].resize(m + 1);    for (int i = 1; i &lt;= n; i++) {        for (int j = 1; j &lt;= m; j++) {            if (X[j - 1] == Y[i - 1]) {                c[i%2][j] = c[(i-1)%2][j - 1] + 1;            }            else {                c[i%2][j] = my_max(c[i%2][j - 1], c[(i-1)%2][j]);            }        }    }    return c[(n-1)%2][m];}</code></pre><h2 id="一维数组"><a href="#一维数组" class="headerlink" title="一维数组"></a>一维数组</h2><p>对于计算某个位置的$c[i][j]$需要三个表项：<br>$$<br>c[i-1][j-1],c[i-1][j],c[i][j-1]<br>$$<br>如果在一行中表示，对于某个待计算的$c[j]$其中：<br>$$<br>c[i-1][j]=未覆盖前的c[j]<br>$$<br>$$<br>c[i][j-1]=c[j]<br>$$</p><p>$$<br>c[i-1][j-1]=覆盖之前的c[j-1]<br>$$</p><p>所以在一行中$c[i-1][j]和c[i]][j-1]$已经存在，只需要额外一个空间保存被覆盖的$c[i-1][j-1]$即可</p><table><thead><tr><th align="center">被覆盖$c[i-1,j-1]=pre$</th><th align="center"></th></tr></thead><tbody><tr><td align="center">$c[i][j-1]=c[j-1]$</td><td align="center">$c[i-1][j]=c[j]$</td></tr><tr><td align="center"></td><td align="center"><strong>待写入</strong>$c[i,j]$</td></tr></tbody></table><h3 id="伪代码-1"><a href="#伪代码-1" class="headerlink" title="伪代码"></a>伪代码</h3><pre><code class="pseudocode">/* 假设X长度m&lt;=Y长度n */LCS-LENGTH(X, Y)m &lt;- X.lengthn &lt;- Y.lengthlet c[m] be new table/* pre记录被前一个覆盖的值 */pre &lt;- 0for i&lt;-1 to n do    for j&lt;-1 to m do        /* tmp临时记录被覆盖的值 */        tmp &lt;- c[j]        if X[j] == Y[i] do            c[j] = pre+1        else            c[j] = max{c[j], c[j-1]}        pre &lt;- tmpreturn c[m]</code></pre><h3 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h3><pre><code class="c++">int lcs_plus(string X, string Y){    int m = X.size();    int n = Y.size();    int pre = 0;    vector&lt;int&gt; c(m + 1);    for (int i = 1; i &lt;= n; i++) {        for (int j = 1; j &lt;= m; j++) {            int tmp = c[j];            if (X[j - 1] == Y[i - 1]) {                c[j] = pre + 1;            }            else {                c[j] = my_max(c[j - 1], c[j]);            }            pre = tmp;        }    }    return c[m];}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>矩阵链乘法</title>
      <link href="2020/05/01/suan-fa-bi-ji/ju-zhen-lian-cheng-fa/"/>
      <url>2020/05/01/suan-fa-bi-ji/ju-zhen-lian-cheng-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>给定n个矩阵的链$&lt;A_1,A_2,…,A_n&gt;$，矩阵$A_i$的规模为$p_{i-1}\times p_{i}(1\le i\le n)$，求完全括号化方案，使得计算乘积$A_1A_2…A_n$所需标量乘法次数最少</p><ul><li><p><strong>完全括号化</strong></p><p>单一矩阵或者两个完全括号化的矩阵乘积链的积，且已外加括号</p><ul><li>例：$（A_1(A_2)(A_3A_4)）$</li></ul></li></ul><h1 id="应用动态规划方法"><a href="#应用动态规划方法" class="headerlink" title="应用动态规划方法"></a>应用动态规划方法</h1><h2 id="1-最优括号化方案的结构特征"><a href="#1-最优括号化方案的结构特征" class="headerlink" title="1. 最优括号化方案的结构特征"></a>1. 最优括号化方案的结构特征</h2><ul><li><p>假设$A_iA_{i+1}…A_j$的最优括号化方案的分割点在$A_k$和$A_{k+1}$之间</p></li><li><p>将问题划分为两个子问题（$A_iA_{i+1}…A_k$和$A_{k+1}A_{k+2}…A_j$的最优化括号问题），求出子问实例的最优解，然后将子问题的最优解组合起来</p></li><li><p>需要在分割点的时候考察完<strong>所有可能的划分点</strong>，保证不会遗漏最优解</p></li></ul><h2 id="2-一个递归求解方案"><a href="#2-一个递归求解方案" class="headerlink" title="2. 一个递归求解方案"></a>2. 一个递归求解方案</h2><ul><li><p>对所有$1\le i\le j\le n$确定$A_iA_{i+1}…A_j$的最小代价括号方案作为子问题</p></li><li><p>$m[i,j]$表示计算矩阵$A_{i…j}$所需标量乘法次数的最小值</p></li><li><p>计算$A_{1…n}$所需的最低代价为$m[1,n]$</p></li><li><p>递归定义$m[i,j]$：</p><ul><li><p>平凡问题：$i=j$的平凡问题，矩阵链只包含唯一的矩阵$A_{i,i}=A_i$，不需要多余计算</p><p>$\implies$所有$i=1,2…,n,\quad m[i,i]=0$</p></li><li><p>$i&lt;j$：利用<strong>最优子结构</strong>计算$m[i,j]$<br>$$<br>m[i,j]=m[i,k]+m[k+1,j]+p_{i-1}p_kp_j<br>$$</p></li><li><p>假设最优分割点k已知，可能取值有$j-i$种，$k=i,i+1,…,j-1$，遍历所有情况找到最优值<br>$$<br>m[i,j]=\begin{cases}<br>0\quad i=j\<br>\min_{i\le k&lt;j}{m[i,k]+m[k+1,j]+p_{i-1}p_kp_j}\quad i&lt;j<br>\end{cases}<br>$$</p></li></ul></li><li><p>$s[i,j]$保存$A_iA_{i+1}…A_j$最优括号化方案的分割点位置k<br>$$<br>m[i,j]=m[i,k]+m[k+1,j]+p_{i-1}p_{k}p_{j}成立的k值<br>$$</p></li></ul><h2 id="3-计算最优代价"><a href="#3-计算最优代价" class="headerlink" title="3. 计算最优代价"></a>3. 计算最优代价</h2><ul><li><p>首先计算所有$m[i,i]=0\quad i=1,2…,n$</p></li><li><p>以此计算链长度$l+1$的$m[i,j]$，仅依赖于$m[i,k],m[k+1,j]$</p></li><li><p>按<strong>对角线</strong>顺序进行计算</p><p><img src="http://note.lizhihao999.cn/notes/20200819160530.png" alt="计算顺序"></p></li></ul><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><pre><code class="pseudocode">MATRIX-CHAIN-ORDER(p)n = p.length-1let m[1..n,1..n]and s[1..n-1,2..n] be new tablesfor i = 1 to n    m[i,i] = 0for l = 2 to n    for i = 1 to n-l+1        j = i+l-1        m[i,j] = ∞        for k = i to j-1            q = m[i,k]+m[k+1,j]+p_{i-1}p_{k}p_{j}            if q &lt; m[i,j]                m[i,j] = q                s[i,j] = kreturn m and s</code></pre><h2 id="4-构造最优解"><a href="#4-构造最优解" class="headerlink" title="4. 构造最优解"></a>4. 构造最优解</h2><ul><li>$s[1..n-1,2..n]$记录了构造最优解所需的信息<ul><li>$s[i,j]$记录一个k值，指出$A_iA_{i+1}…A_j$的最优括号化方案的分割点位置</li><li>$s[1,s[1,n]]$指出计算$A_{1..s[1,n]}$时进行的最后一次运算</li><li>$s[s[1,n]+1,n]$指出计算$A_{s[1,n]+1..n}$时应进行的最后一次运算</li></ul></li><li>递归可输出最优括号法方案</li></ul><h3 id="伪代码-1"><a href="#伪代码-1" class="headerlink" title="伪代码"></a>伪代码</h3><pre><code class="pseudocode">PRINT-OPTIMAT-PARENS(s,i,j)if i==j    print("A")else    print("(")    PRINT-OPTIMAT_PARENS(s,i,s[i,j])    PRINT_OPTIMAT_PARENS(s,s[i,j]+1,j)    print(")")</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态规划</title>
      <link href="2020/04/30/suan-fa-bi-ji/dong-tai-gui-hua/"/>
      <url>2020/04/30/suan-fa-bi-ji/dong-tai-gui-hua/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Those who cannot remember the past are condemned to repeat it.</strong></p></blockquote><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>动态规划同常用来求解<strong>最优化问题</strong>。这类问题通常有很多可行解，每个解都有一个值，我们希望寻找最优值的解。</p><h2 id="动态规划与分治算法"><a href="#动态规划与分治算法" class="headerlink" title="动态规划与分治算法"></a>动态规划与分治算法</h2><p>动态规划与分治算法有相似与不同之处，相似之处为都通过组合子问题的解来求解原问题。不同之处为动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题。这种情况下，分治算法会做很多重复的工作（重复求子问题的解），而动态规划对每个子问题只求解一次，将结果保存在表格当中，避免不必要的计算工作。</p><table><thead><tr><th align="center"></th><th align="center">分治法</th><th align="center">动态规划</th></tr></thead><tbody><tr><td align="center">算法思想</td><td align="center">组合子问题</td><td align="center">组合子问题</td></tr><tr><td align="center">计算方式</td><td align="center">自顶向下</td><td align="center">自底向上</td></tr><tr><td align="center">相同要素</td><td align="center">具有最优子结构</td><td align="center">具有最优子结构</td></tr><tr><td align="center">不同要素</td><td align="center">不包含公共子问题（独立）</td><td align="center">重叠子问题</td></tr></tbody></table><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li><p><strong>保存已求解子问题的解</strong></p></li><li><p><strong>将原始问题划分为一系列子问题</strong></p></li><li><p><strong>自底向上计算</strong></p></li></ul><h2 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h2><ul><li><h4 id="给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解"><a href="#给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解" class="headerlink" title="给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解"></a>给定一组约束条件和一个代价函数，在解空间中搜索具有最小或最大代价的优化解</h4></li><li><h4 id="很多优化问题可分为多个子问题，子问题相互关联，子问题的解被重复使用"><a href="#很多优化问题可分为多个子问题，子问题相互关联，子问题的解被重复使用" class="headerlink" title="很多优化问题可分为多个子问题，子问题相互关联，子问题的解被重复使用"></a>很多优化问题可分为多个子问题，子问题相互关联，子问题的解被重复使用</h4></li></ul><h2 id="使用条件"><a href="#使用条件" class="headerlink" title="使用条件"></a>使用条件</h2><ul><li><h4 id="优化子结构"><a href="#优化子结构" class="headerlink" title="优化子结构"></a>优化子结构</h4><ul><li><strong>一个问题的优化解包含了子问题的优化解</strong></li></ul></li><li><h4 id="重叠子问题"><a href="#重叠子问题" class="headerlink" title="重叠子问题"></a>重叠子问题</h4><ul><li><strong>在问题的求解过程中，很多子问题的解将被多次使用</strong></li></ul></li></ul><h2 id="设计步骤"><a href="#设计步骤" class="headerlink" title="设计步骤"></a>设计步骤</h2><ul><li><h4 id="刻画一个最优解的结构特征"><a href="#刻画一个最优解的结构特征" class="headerlink" title="刻画一个最优解的结构特征"></a>刻画一个最优解的结构特征</h4><p>寻找最优子结构，利用这种子结构从子问题的最优解构造出原问题的最优解</p></li><li><h4 id="递归定义最优解的值"><a href="#递归定义最优解的值" class="headerlink" title="递归定义最优解的值"></a>递归定义最优解的值</h4></li><li><h4 id="自底向上计算最优解的值"><a href="#自底向上计算最优解的值" class="headerlink" title="自底向上计算最优解的值"></a>自底向上计算最优解的值</h4></li><li><h4 id="根据构造最优解的信息构造优化解"><a href="#根据构造最优解的信息构造优化解" class="headerlink" title="根据构造最优解的信息构造优化解"></a>根据构造最优解的信息构造优化解</h4></li></ul><h2 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h2><ul><li><h4 id="带备忘的自顶向下法"><a href="#带备忘的自顶向下法" class="headerlink" title="带备忘的自顶向下法"></a>带备忘的自顶向下法</h4><ul><li>递归求解</li><li>保存每个子问题的解（数组或散列表）</li></ul></li><li><h4 id="自底向上法"><a href="#自底向上法" class="headerlink" title="自底向上法"></a>自底向上法</h4><ul><li>恰当定义子问题的<strong>规模</strong></li><li>任何子问题的求解都只依赖于<strong>更小的</strong>子问题的解</li><li>按子问题规模<strong>由小到大进行求解</strong></li><li>第一次求解一个问题时，它的所有前提子问题都已求解完成且<strong>保存结果</strong></li></ul></li></ul><p>两种方法的算法的<strong>渐进运行时间相同</strong>，<strong>自底向上的时间复杂性</strong>函数通常具有更小的系数，某些情况下自顶向下无法真正递归考察所有可能的子问题。</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="最优子结构"><a href="#最优子结构" class="headerlink" title="最优子结构"></a>最优子结构</h2><ul><li><p><strong>发掘最优子结构的通用模式</strong></p><ol><li>证明问题最优解的第一个组成部分是做出一个选择，做出这次选择会产生一个或多个待解的子问题</li><li>对于一个给定问题，在其可能的第一步选择中，你<strong>假定已经知道</strong>哪种选择才会得到最优解。并<strong>不关心如何得到，只是假定已经知道</strong></li><li>给定可获得最优解的选择后，你确定这次选择会产生哪些<strong>子问题</strong>，以及如何<strong>最好地刻画子问题空间</strong></li></ol></li><li><p><strong>保持子问题空间尽可能简单，只在必要时才扩展它</strong></p></li><li><p><strong>不同问题领域，最优子结构的不同</strong>：</p><ul><li>原问题的最优解中涉及多少个子问题</li><li>再确定最优解使用哪些子问题时，我们需要考虑多少种选择</li></ul></li><li><p><strong>粗略分析算法的运行时间：</strong><br>$$<br>O(m\times n)<br>$$</p></li></ul><p>$$<br>\Theta(n):子问题个数\quad\quad m:考察的选择个数<br>$$</p><h2 id="重叠子问题-1"><a href="#重叠子问题-1" class="headerlink" title="重叠子问题"></a>重叠子问题</h2><p>如果递归算法反复求解相同的子问题，则称最优化问题具有<strong>重叠子问题</strong>。一般来讲， 不同子问题的总数最好是输入规模的多项式函数。</p><h2 id="重构最优解"><a href="#重构最优解" class="headerlink" title="重构最优解"></a>重构最优解</h2><p><strong>将每个子问题所做的选择存在一个表中</strong>：重构每次选择只需$O(1)$时间</p><h2 id="备忘"><a href="#备忘" class="headerlink" title="备忘"></a>备忘</h2><p>维护一个表记录子问题的解，保持递归算法的控制流程：</p><ul><li>每个表项的初值设为一个特殊值，表示尚未填入子问题的解</li><li>当递归调用过程中第一次遇到子问题时，计算其解，并存入对应表项</li><li>每次遇到同一个子问题，查表返回解</li></ul><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><ul><li><strong>通常情况</strong>：每个子问题必须至少求解一次<ul><li>自底向上动态规划算法比自顶向下备忘算法快（都是$O(n^3)$，相差常量系数）</li><li>自底向上算法没有递归调用的开销，表的维护开销更小</li></ul></li><li><strong>某些问题：</strong>可利用表的访问模式进一步降低时空代价</li><li><strong>某些子问题完全不必求解：</strong>备忘方法更有优势（只求解必要子问题）</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速排序</title>
      <link href="2020/04/28/suan-fa-bi-ji/kuai-su-pai-xu/"/>
      <url>2020/04/28/suan-fa-bi-ji/kuai-su-pai-xu/</url>
      
        <content type="html"><![CDATA[<p><strong>快速排序能够实现原址排序，而且平均性能很好。最基本的快速排序基于分治思想。</strong></p><h1 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h1><ol><li><p>选定分界值，将原数组划分为两个部分</p></li><li><p>左边的值都小于分界值，右边的值都大于等于分界值</p></li><li><p>对左右两侧数组再次进行1、2步骤</p></li><li><p>直到所有数据排序完成</p></li></ol><h1 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h1><pre><code class="pseudocode">QUICKSORT(A,low,high)if low &lt; high    q = PARTITION(A,low,high)    QUICKSORT(A,low,q-1)    QUICKSORT(A,q+1,high)PRTITION(A,low,high)x = A[high]i = low-1for j=low -&gt; high-1    if A[j] &lt;= x        i++        exchange A[i] with A[j]exchange A[i+1] with A[high]return i+1</code></pre><h1 id="划分-PARTITION"><a href="#划分-PARTITION" class="headerlink" title="划分(PARTITION)"></a>划分(PARTITION)</h1><ul><li><p>选定一个分界值x（此例中为数组最后一个元素）</p></li><li><p>整个数组分为三个部分：</p><ul><li><p>小于x的部分</p></li><li><p>大于等于x的部分</p></li><li><p>未确定的部分</p><p><img src="http://note.lizhihao999.cn/notes/20200819111943.png" alt="排序过程中的四个部分"></p></li></ul></li><li><p>循环开始时<code>i=low-1</code>,<code>j=low</code></p></li><li><p>考虑当前<code>A[j]</code>与分界值<code>x</code>的大小关系</p><ul><li>如果<code>A[j]</code>小于<code>x</code>，则<code>i++</code>，同时交换<code>A[i]</code>和<code>A[j]</code>$\implies$保证<code>i</code>之前为小于<code>x</code>的值</li><li>否则<code>j++</code>，继续遍历</li></ul></li><li><p>最后交换<code>A[i+1]</code>和<code>x</code></p><p><img src="http://note.lizhihao999.cn/notes/20200819114038.png" alt="划分过程中的两种情况"></p></li></ul><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>使用最基本的快速排序对$&lt;13,19,9,5,12,4,7,8&gt;$进行一次划分</p><img src="http://note.lizhihao999.cn/notes/20200819111516.png" style="zoom:50%;"><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code class="cpp">void swap(int *a, int *b){    int temp = *a;    *a = *b;    *b = temp;}int partition(int *A, int low, int high){    int x = A[high];    int i = low - 1;    for (int j = low; j &lt;= high - 1; j++)    {        if (A[j] &lt;= x)        {            i++;            swap(&amp;A[i], &amp;A[j]);        }    }    swap(&amp;A[i+1], &amp;A[high]);    return i+1;}void quicksort(int *A, int low, int high){    if (low &lt; high)    {        int q = partition(A, low, high);        quicksort(A, low, q - 1);        quicksort(A, q + 1, high);    }}</code></pre><h2 id="随机化版本"><a href="#随机化版本" class="headerlink" title="随机化版本"></a>随机化版本</h2><p>输入的数组的元素分布不一定是均衡的，采用<strong>随机取样</strong>的方法期望在平均情况下划分是比较均衡的，即随机选取主元元素。</p><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;ctime&gt;#include &lt;cstdlib&gt;using namespace std;//随机选择一个分界值int random(int low, int high){    srand(1);    int len = high - low + 1;    return rand() % len + low;}void swap(int* a, int* b){    int temp = *a;    *a = *b;    *b = temp;}int partition(int* A, int low, int high){    int i = low - 1;    int x = A[high];    for (int j = low; j &lt; high; j++)    {        if (A[j] &lt;= x)        {            i++;            swap(&amp;A[i], &amp;A[j]);        }    }    swap(&amp;A[i + 1], &amp;A[high]);    return i + 1;}int random_partition(int* A, int low, int high){    int i = random(low, high);    //将分界值交换到最后一位    swap(&amp;A[high], &amp;A[i]);    return partition(A, low, high);}void random_quicksort(int* A, int low, int high){    if (low &lt; high)    {        int q = random_partition(A, low, high);        random_quicksort(A, low, q - 1);        random_quicksort(A, q + 1, high);    }}</code></pre><h1 id="快速排序的性能"><a href="#快速排序的性能" class="headerlink" title="快速排序的性能"></a>快速排序的性能</h1><p>快速排序的运行时间依赖于<strong>划分是否平衡</strong>，平衡与否依赖于<strong>划分的元素</strong>。</p><h2 id="划分的复杂度"><a href="#划分的复杂度" class="headerlink" title="划分的复杂度"></a>划分的复杂度</h2><p>$$<br>T(n)=\Theta(n)<br>$$</p><p>$$<br>n=high-low+1<br>$$</p><h2 id="最坏情况的划分"><a href="#最坏情况的划分" class="headerlink" title="最坏情况的划分"></a>最坏情况的划分</h2><p>当划分产生的两个子问题分别包含<code>n-1</code>个元素和<code>0</code>个元素时，快速排序的最坏情况发生。不妨假设算法的每一次递归调用中都出现这种不平衡划分，其中划分操作的时间复杂度为$\Theta(n)$。由于，对一个大小为0的数组进行递归调用会直接返回，因此$T(0)=\Theta(1)$，于是算法运行时间的递归式可以表示为：<br>$$<br>T(n)=T(n-1)+T(0)+\Theta(n)=T(n-1)+\Theta(n)<br>$$<br>利用代入法证明：</p><p><strong>猜想假设</strong>：$T(n)=O(n^2)\quad c&gt;0$</p><ol><li>首先归纳假设：$\exist c &gt; 0,使得T(n)\le cn^2$</li></ol><p>则$T(n-1)\le c(n-1)^2$</p><p>$\implies T(n)\le c(n-1)^2+\Theta(n)$</p><p>$=c(n^2-2n+1)+\Theta(n)$</p><p>$=cn^2-c\times2n+c+\Theta(n)$</p><p>当$-2cn+c+\Theta(n)\le 0$时，</p><p>$T(n)\le cn^2$</p><p>$\therefore T(n)=O(n^2)$</p><ol start="2"><li>归纳假设：$\exist c &gt; 0,使得T(n)\ge cn^2$</li></ol><p>则$T(n-1)\ge c(n-1)^2$</p><p>$\implies T(n)\ge c(n-1)^2+\Theta(n)$</p><p>$=c(n^2-2n+1)+\Theta(n)$</p><p>$=cn^2-c\times2n+c+\Theta(n)$</p><p>当$-2cn+c+\Theta(n) \ge 0$时，</p><p>$T(n)\ge cn^2$</p><p>$\therefore T(n)=\Theta(n^2)$</p><h2 id="最坏运行时间"><a href="#最坏运行时间" class="headerlink" title="最坏运行时间"></a>最坏运行时间</h2><p>在最坏情况下，快速排序的每一层递归的时间复杂度为$\Theta(n^2)$，从直观上来看，这就是最坏情况下的运行时间$\Theta(n^2)$。</p><h2 id="期望运行时间"><a href="#期望运行时间" class="headerlink" title="期望运行时间"></a>期望运行时间</h2><p>随机化快速排序的期望运行时间为$O(n\lg{n})$；如果每一层递归上随机化算法都将任意常数比例的元素划分到一个子数组中，则算法的递归树的深度为$\Theta(\lg{n})$，并且每一层上的工作量都是$O(n)$。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分治算法</title>
      <link href="2020/04/27/suan-fa-bi-ji/fen-zhi-suan-fa/"/>
      <url>2020/04/27/suan-fa-bi-ji/fen-zhi-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="一-分治算法的设计"><a href="#一-分治算法的设计" class="headerlink" title="一. 分治算法的设计"></a>一. 分治算法的设计</h1><ul><li><h3 id="划分"><a href="#划分" class="headerlink" title="划分"></a>划分</h3><p>将整个问题划分为多个子问题</p></li><li><h3 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h3><p>求解各个子问题</p></li><li><h3 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h3><p>合并子问题的解，形成原始问题的解</p></li></ul><h1 id="二-分治算法的分析"><a href="#二-分治算法的分析" class="headerlink" title="二. 分治算法的分析"></a>二. 分治算法的分析</h1><ul><li><h3 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h3><ul><li>建立递归方程</li><li>求解</li></ul></li><li><h3 id="递归方程的建立方法"><a href="#递归方程的建立方法" class="headerlink" title="递归方程的建立方法"></a>递归方程的建立方法</h3><ul><li>设输入大小为n,T(n)为时间复杂性</li><li>当$n&lt;c, T(n)=\Theta(1)$</li></ul></li><li><h3 id="划分阶段的时间复杂性"><a href="#划分阶段的时间复杂性" class="headerlink" title="划分阶段的时间复杂性"></a>划分阶段的时间复杂性</h3><ul><li>划分问题为a个子问题</li><li>每个子问题大小为$\frac{n}{b}$</li><li>划分时间可直接得到=$D(n)$</li></ul></li><li><h3 id="递归求解阶段的时间复杂性"><a href="#递归求解阶段的时间复杂性" class="headerlink" title="递归求解阶段的时间复杂性"></a>递归求解阶段的时间复杂性</h3><ul><li>递归调用</li><li>求解时间=$aT(\frac{n}{b})$</li></ul></li><li><h3 id="合并阶段的时间复杂性"><a href="#合并阶段的时间复杂性" class="headerlink" title="合并阶段的时间复杂性"></a>合并阶段的时间复杂性</h3><ul><li>时间可以直接得到=$C(n)$</li></ul></li></ul><p>$$<br>T(n)=\Theta(1)\quad if;;n&lt;c<br>$$</p><p>$$<br>T(n)=aT(\frac{n}{b})+D(n)+C(n)\quad if\quad n\ge c<br>$$</p><h1 id="三、实际应用"><a href="#三、实际应用" class="headerlink" title="三、实际应用"></a>三、实际应用</h1><h2 id="1-大整数乘法"><a href="#1-大整数乘法" class="headerlink" title="1. 大整数乘法"></a>1. 大整数乘法</h2><ul><li><p>输入：ｎ位二进制整数Ｘ和Y</p></li><li><p>输出：X和Y的乘积</p></li><li><p>通常时间复杂度：$O(n^2)$</p></li><li><p>简单分治算法：$O(n^{1.59})$</p></li></ul><h3 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h3><ol><li>划分产生$A,B,C,D$</li><li>计算$A-B$和$C-D$</li><li>计算$\frac{n}{2}$位乘法$AC,BD,(A+B)(C+D)$</li><li>计算$(A+B)(C+D)-AC-BD$</li><li>AC左移n位，$(A+B)(C+D)-AC-BD$左移$\frac{n}{2}$位</li><li>计算XY</li></ol><p><img src="http://note.lizhihao999.cn/notes/20200818112253.png" alt="计算流程"></p><h3 id="时间复杂性"><a href="#时间复杂性" class="headerlink" title="时间复杂性"></a>时间复杂性</h3><ul><li><p>建立递归方程</p><p>$$<br>T(n)=\Theta(1)\quad if;;n=1<br>$$</p><p>$$<br>T(n)=3T(\frac{n}{2})+O(n)\quad if;;n&gt;1<br>$$</p></li></ul><ul><li>Master定理<br>$$<br>T(n)=O(n^{\log{3}})=O(n^{1.59})<br>$$</li></ul><h2 id="2-棋盘覆盖问题"><a href="#2-棋盘覆盖问题" class="headerlink" title="2. 棋盘覆盖问题"></a>2. 棋盘覆盖问题</h2><blockquote><p>参考<a href="http://blog.chinaunix.net/uid/26548237.html">梦醒潇湘love</a>博客</p></blockquote><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>在一个2^k ×2^k （k≥0）个方格组成的棋盘中，恰有一个方格与其他方格不同，称该方格为特殊方格。显然，特殊方格在棋盘中可能出现的位置有4^k 种，因而有4^k种不同的棋盘。棋盘覆盖问题（chess cover problem）要求用图所示的4种不同形状的L型骨牌覆盖给定棋盘上除特殊方格以外的所有方格，且任何2个L型骨牌不得重叠覆盖。</p><p><img src="http://blog.chinaunix.net/attachment/201303/1/26548237_1362125215RWwI.png" alt="棋盘样例和骨牌样式"></p><h3 id="算法描述-1"><a href="#算法描述-1" class="headerlink" title="算法描述"></a>算法描述</h3><p>将2^k * 2^k的棋盘，先分成相等的四块子棋盘，其中特殊方格位于四个中的一个，构造剩下没特殊方格的三个字棋盘，将它们中的也假设一个方格为特殊方格。如果是：</p><p>左上角的子棋盘（若不存在特殊方格）：则将该子棋盘右下角的那个方格假设为特殊方格；</p><p>右上角的子棋盘（若不存在特殊方格）：则将该子棋盘左下角的那个方格假设为特殊方格；</p><p>左下角的子棋盘（若不存在特殊方格）：则将该子棋盘右上角的那个方格假设为特殊方格；</p><p>右下角的子棋盘（若不存在特殊方格）：则将该子棋盘左上角的那个方格假设为特殊方格；</p><p>上面四种情况，只可能且必定只有三种成立，那三个假设的特殊方格刚好构成一个L型骨牌，我们可以给它们作上相同的标志。这样四个子棋盘就分别都和原来的大棋盘类似，就可以用递归的算法解决。</p><p><img src="http://blog.chinaunix.net/attachment/201303/1/26548237_136212550647ax.png" alt="分割样例"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法分析的数学基础</title>
      <link href="2020/04/26/suan-fa-bi-ji/suan-fa-fen-xi-de-shu-xue-ji-chu/"/>
      <url>2020/04/26/suan-fa-bi-ji/suan-fa-fen-xi-de-shu-xue-ji-chu/</url>
      
        <content type="html"><![CDATA[<h1 id="2-1-计算复杂性函数的阶"><a href="#2-1-计算复杂性函数的阶" class="headerlink" title="2.1 计算复杂性函数的阶"></a>2.1 计算复杂性函数的阶</h1><h2 id="增长的阶"><a href="#增长的阶" class="headerlink" title="增长的阶"></a>增长的阶</h2><p>算法的实际运行时间受除算法设计本身以外很多其他因素的影响，如：指令集、操作系统、编译器…… </p><ul><li>如何描述算法的效率$\to$只与<strong>输入问题的规模</strong>有关<ul><li>增长率</li><li>时间复杂度</li></ul></li><li>忽略低阶项</li><li>保留最高阶项</li><li>忽略常系数</li><li>常见增长阶：$\Theta(1)$, $\Theta(lg,n)$, $\Theta(\sqrt[]{n})$, $\Theta(n)$, $\Theta(nlg,n)$, $\Theta(n^2)$, $\Theta(n^3)$, $\Theta(2^n)$, $\Theta(n!)$<ul><li>利用$\Theta(n^2)$表示插入排序的<strong>最坏</strong>运行时间</li></ul></li><li>增长记号$O, \Theta, \Omega, o, \omega$<ul><li>$O$表示<strong>渐进上界</strong></li><li>$\Theta$表示<strong>渐进紧界</strong></li><li>$\Omega$表示<strong>渐进下界</strong></li></ul></li></ul><h2 id="同阶函数集合-Theta"><a href="#同阶函数集合-Theta" class="headerlink" title="同阶函数集合 $\Theta$"></a>同阶函数集合 $\Theta$</h2><p>$$<br>\Theta(g(n))={,f(n)|\exists c_1,c_2 &gt;0,\forall n&gt;n_0,c_1g(n)\le f(n) \le c_2g(n) ,}<br>$$</p><p>称为与g(n)<strong>同阶的函数集合</strong></p><ul><li>若$f(n)\in \Theta(g(n))$, $g(n)$与$f(n)$同阶, 记作$f(n) = \Theta(g(n))$</li></ul><p>$\Theta(g(n))$例子：</p><ul><li>通常$f(n)=an^2+bn+c=\Theta(n^2)$，其中a,b,c是常数且$a&gt;0$</li><li>若$p(n)=\sum_{i=0}^{d}a_in^i$，其中$a_i$是常数且$a_d&gt;0$，则$p(n)=\Theta(n^d)$</li><li>$\Theta(n^0)$或者$\Theta(1)$为<strong>常数时间复杂性</strong></li></ul><h2 id="低阶函数集合-O"><a href="#低阶函数集合-O" class="headerlink" title="低阶函数集合 $O$"></a>低阶函数集合 $O$</h2><p>对于给定函数$g(n)$:<br>$$<br>O(g(n))=f{(n) 存在正常数c和n_0 满足对于所有n\ge n_0, 0 \le f(n) \le cg(n),}<br>$$<br>记作$f(n)\in O(g(n))$, 或简记为$f(n)=O(g(n))$</p><p>$\Theta(g(n))$与$O(g(n))$的关系：</p><ul><li>$f(n)=\Theta(g(n))\implies f(n)=O(g(n))$</li><li>$\Theta$强于$O$</li><li>$\Theta(g(n)) \subseteq O(g(n))$<ul><li>$an^2+bn+c=\Theta(n^2)$并且$an^2+bn+c=O(n^2)$</li><li>$an+b=O(n^2)$</li><li>$n=O(n^2)$</li></ul></li></ul><p><strong>如果 $f(n)=O(n^k)$ ，则称$f(n)$是多项式界限的​</strong></p><h2 id="严格低阶函数-o"><a href="#严格低阶函数-o" class="headerlink" title="严格低阶函数 $o$"></a>严格低阶函数 $o$</h2><p>对于给定函数$g(n)$:<br>$$<br>o(g(n))=f{(n) 存在任意正常数c,存在一个正数n_0 满足对于所有n\ge n_0, 0 \le f(n) &lt; cg(n),}<br>$$<br>记作$f(n)\in o(g(n))$, 或简记为$f(n)=o(g(n))$</p><p>$o$<strong>与$O$的关系：</strong></p><ul><li>$O$<strong>可能</strong>是或不是紧的<pre><code>- $2n^2=O(n^2)$是紧的，但$2n=O(n^2)$不是紧的</code></pre></li><li>$o$标记上界且<strong>不紧</strong><pre><code>- $2n=o(n^2)$，但是$2n^2\ne o(n^2)$</code></pre><ul><li>区别：$\cases{O:\exist,c,某个正常数\o:\forall,c,任意正常数}$</li></ul></li></ul><h2 id="高阶函数集合-Omega"><a href="#高阶函数集合-Omega" class="headerlink" title="高阶函数集合 $\Omega$"></a>高阶函数集合 $\Omega$</h2><p>对于给定函数$g(n)$:<br>$$<br>\Omega(g(n))=f{(n) ,存在正常数c和n_0 满足对于所有n\ge n_0, 0 \le cg(n) \le f(n),}<br>$$<br>记作$f(n)\in \Omega(g(n))$, 或简记为$f(n)=\Omega(g(n))$</p><p>$\Omega$用来描述运行时间的<strong>最好情况</strong>，对<strong>所有输入</strong>都正确</p><p>例如，对于插入排序：</p><ul><li>最好运行情况为$\Omega(n)$</li><li>运行时间为$\Omega(n)$ ($\Omega(n^2)$[<strong>x</strong>])</li><li>最坏运行时间为$\Omega(n^2)$</li></ul><p>也可以用来<strong>描述问题</strong>：</p><p>​    - 排序问题的时间复杂性为$\bold{\Omega(n)}$ $\to$ <strong>最好情况</strong></p><p><strong>$\bold{O,\Theta,\Omega}$的关系：</strong><br>$$<br>对于f(n)和g(n),f(n)=\Theta(g(n))当且仅当<br>f(n)=O(g(n))且f(n)=\Omega(g(n))<br>$$</p><h2 id="严格高阶函数集合-omega"><a href="#严格高阶函数集合-omega" class="headerlink" title="严格高阶函数集合 $\omega$"></a>严格高阶函数集合 $\omega$</h2><p>对于给定函数$g(n)$:<br>$$<br>\omega(g(n))=f{(n) \quad对于任意正常数c，存在正数n_0 满足对于所有n\ge n_0, 0 \le cg(n) \le f(n),}<br>$$<br>记作$f(n)\in \omega(g(n))$, 或简记为$f(n)=\omega(g(n))$</p><p>$$<br>\lim_{n\to \infty}\frac{f(n)}{g(n)}=\infty<br>$$</p><p>$\omega$表示<strong>不紧</strong>的下界</p><p>$$<br>\frac{n^2}{2}=\omega(n)，但\frac{n^2}{2}\ne \omega(n^2)<br>$$</p><p><strong>$\omega$与 $\Omega$ 的区别</strong>:$\cases{ \omega:,\exists,c存在正常数\ \Omega:,\forall,c,任意正常数 }$</p><p><strong>$\omega$与$o$的关系：</strong><br>$$<br>f(n)=\omega(g(n)) \iff g(n)=o(f(n))<br>$$</p><h2 id="渐进符号的性质"><a href="#渐进符号的性质" class="headerlink" title="渐进符号的性质"></a>渐进符号的性质</h2><ul><li><p><strong>传递性</strong>：$O, \Theta, \Omega, o, \omega$<br>$$<br>f(n)=\Theta(g(n))\and g(n)=\Theta(h(n)) \implies f(n)=\Theta(h(n))<br>$$</p></li><li><p><strong>自反性</strong>：$O,\Theta,\Omega $<br>$$<br>f(n)=\Theta(f(n))<br>$$</p></li><li><p><strong>对称性</strong>：$\Theta$<br>$$<br>f(n)=\Theta(g(n)) \iff g(n)=\Theta(f(n))<br>$$</p></li><li><p><strong>反对称性</strong>：$O, \Omega, o, \omega$<br>$$<br>f(n)=O(g(n)) \iff g(n)=\Omega(f(n))<br>$$</p></li></ul><p>$$<br>  f(n)=o(g(n)) \iff g(n)=\omega(f(n))<br>$$</p><ul><li><p><strong>等价性</strong>$\cases{\text{传递性}\自反性\对称性} $$\implies $ $\Theta$</p></li><li><p><strong>并非所有函数都可比</strong></p></li></ul><h1 id="2-2-和式的估计与界限"><a href="#2-2-和式的估计与界限" class="headerlink" title="2.2 和式的估计与界限"></a>2.2 和式的估计与界限</h1><h2 id="求和公式"><a href="#求和公式" class="headerlink" title="求和公式"></a>求和公式</h2><ol><li>线性和<br>$$<br>\sum_{k=1}^{n}(ca_k+b_k) = c\sum_{k=1}^{n}a_k+\sum_{k=1}^{n}b_k<br>$$</li></ol><p>   线性性质对于无限收敛级数同样适用。</p><p>   线性性质可以用来对项中包含渐进符号的和式求和，例如：</p><p>$$<br>\sum_{k=1}^{n}\Theta(f(k))=\Theta(\sum_{k=1}^{n}f(k))<br>$$</p><pre><code>       等式中，左边的\Theta符号作用于变量k，而右边的\Theta则作用于n。这种处理方法同样适用于无限收敛级数。</code></pre><ol start="2"><li>级数</li></ol><ul><li>等差级数：$\sum_{i=1}^{n}i=\frac{n(n+1)}{2}=\Theta(n^2)$</li><li>几何级数：$\sum_{k=0}^{n}x^k=1+x+x^2+…+x^n=\frac{x^{n+1}-1}{x-1}\quad(x\ne1)$</li><li>无限递减几何级数：$\sum_{k=0}^{\infin}x^k=\frac{1}{1-x}\quad|x|&lt;1$</li><li>裂项级数：$\sum_{k=1}^{n}(a_k-a_{k-1})=a_n-a_0$<ul><li>$\sum_{k=0}^{n-1}(a_k-a_{k+1})=a_0-a_n$</li><li> $\sum_{k=1}^{n-1}\frac{1}{k(k+1)}=\sum_{k=1}^{n-1}(\frac{1}{k}-\frac{1}{k+1})=1-\frac{1}{n}$</li></ul></li><li>调和级数：$H_n=\sum_{k=1}^{n}\frac{1}{k}=\ln{n}+O(1)$</li></ul><ol start="3"><li><p>常用公式</p><p>乘积：$lg(\prod_{k=1}^{n}a_k)=\sum_{k=1}^{n}\lg{a_k}$<br>平方和：$\sum_{k=0}^{n}k^2=\frac{n(n+1)(2n+1)}{6}$<br>立方和：$\sum_{k=0}^{n}=\frac{n^2(n+1)^2}{4}$</p></li></ol><ol start="4"><li><p>和的界限</p><p><strong>利用公式和定义</strong></p><p>例1：证明$\sum_{k=0}^{n}3^k=O(3^n)$<br>证：证明对于$c\ge\frac{3}{2}$存在一个$n_0，当n\ge n_0时\sum_{k=0}^{n}3^k\le c3^n$<br>当n=0时，$\sum_{k=0}^{n}3^k=1\le c=c3^n$<br>设$n\le m$时成立,令n=m+1,则<br>$\sum_{k=0}^{m+1}3^k=\sum_{k=0}^{m}3^k+3^{m+1}\le c3^m+3^{m+1}=c3^{m+1}(\frac{1}{3}+\frac{1}{c})\le c3^{m+1}$</p></li></ol><h2 id="求和的界限"><a href="#求和的界限" class="headerlink" title="求和的界限"></a>求和的界限</h2><ol><li><h4 id="放大法"><a href="#放大法" class="headerlink" title="放大法"></a>放大法</h4><p>例1：$\sum_{k=1}^{n}k\le\sum_{k=1}^{n}n=n^2$ $\impliedby\bold{\sum_{k=1}^{n}a_i\le n\times \max{a_k}}$</p></li></ol><ol start="2"><li><h4 id="前后项之比"><a href="#前后项之比" class="headerlink" title="前后项之比"></a>前后项之比</h4></li></ol><p>例2：设对于所有$k\ge0,\frac{a_{k+1}}{a_k}\le r\le1,求\sum_{k=0}^{n}a_k$的上界.<br>   解：$\frac{a_1}{a_0}\le r \implies a_1 \le a_0r,$<br>   $\frac{a_2}{a_1} \le r\implies a_2\le a_1r\le a_0r^2,$<br>   $\frac{a_3}{a_2}\le r\implies a_3\le a_2r \le a_0r^3,……$<br>   $\frac{a_k}{a_{k-1}}\le r\implies a_k\le a_{k-1}r \le a_0r^k$<br>   $\therefore \sum_{k=0}^{n}a_k\le \sum_{k=0}^{\infin}a_0r^k=a_0\sum_{k=0}^{\infin}r^k=\frac{a_0}{1-r}$</p><ol start="3"><li><h4 id="分裂和"><a href="#分裂和" class="headerlink" title="分裂和"></a>分裂和</h4><p>例4：用分裂和的方法求$\sum_{k=1}^{n}k$的下界.<br>解：$\sum_{k=1}^{n}k=\sum_{k=1}^{\frac{n}{2}}k+\sum_{k=\frac{n}{2}+1}^{n}k\ge\sum_{k=1}^{\frac{n}{2}}0+\sum_{k=\frac{n}{2}+1}^{n}\frac{n}{2}\ge(\frac{n}{2})^2=\Omega(n^2)$</p></li></ol><p>例5：求$\sum_{k=0}^{\infin}\frac{k^2}{2^k}$的上界.<br>   解：当$k\ge3$时，$\frac{\frac{(k+1)^2}{2^{k+1}}}{\frac{k^2}{2^k}}=\frac{(k+1)^2}{2k^2}\le\frac{8}{9}$<br>   于是$\quad \sum_{k=0}^{\infin}\frac{k^2}{2^k}=\sum_{k=0}^{2}\frac{k^2}{2^k}+\sum_{k=3}^{\infin}\frac{k^2}{2^k}\le\theta(1)+\sum_{k=3}^{\infin}\frac{9}{8}\cdot(\frac{8}{9})^k=O(1)$</p><p> (调和级数上界)例6：求$H_n=\sum_{k=1}^{n}\frac{1}{k}$的上界.<br>   解：$\sum_{k=1}^{n}\frac{1}{k}=\frac{1}{1}+(\frac{1}{2}+\frac{1}{3})+(\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7})+…$<br>                       $\le \sum_{i=1}^{\lceil\log{n}\rceil}\sum_{j=0}^{2^i-1}\frac{1}{2^i+j}\le\sum_{i=0}^{\lceil\log{n}\rceil}1\le\log{n}+1=O(\log{n})$</p><ol start="4"><li><h4 id="单调函数"><a href="#单调函数" class="headerlink" title="单调函数"></a>单调函数</h4></li></ol><p>f(k)单调递增，则$\int_{m-1}^{n}f(x)dx\le\sum_{k=m}^{n}f(k)\le\int_{m}^{n+1}f(x)dx$<br>f(k)单调递减，则$\int_{m}^{n+1}f(x)dx\le\sum_{k=m}^{n}f(k)\le\int_{m-1}^{n}f(x)dx$</p><p>例7：调和级数：<br>$\sum_{k=1}^{n}\frac{1}{k}\ge\int_{1}^{n+1}\frac{dx}{x}=\ln{(n+1)}$ </p><p>$\quad\sum_{k=2}^{n}\cdot\frac{1}{k}\le\int_{1}^{n}\frac{dx}{x}=\ln{n}$</p><ol start="5"><li><h4 id="分割求和"><a href="#分割求和" class="headerlink" title="分割求和"></a>分割求和</h4></li></ol><p>$$<br>\sum_{k=1}^{n}k=\sum_{k=0}^{k_0-1}a_k+\sum_{k=k_0}^{n}a_k=\Theta(1)+\sum_{k=k_0}^{n}a_k<br>$$</p><p>对于算法分析中的和式，通常可以将和式分割。并忽略其常数个起始项。</p><p>一般情况下，该技巧适用于和式$\sum_{k=0}^{n}a_k$中每一项$a_k$均独立于n的情况。之后，对于任意常数k_0&gt;0，有<br>$$<br>\sum_{k=k_0}^{n}a_k=\sum_{k=0}^{k_0-1}a_k+\sum_{k=k_0}^{n}a_k=\Theta(1)+\sum_{k=k_0}^{n}a_k<br>$$</p><p>​    </p><h1 id="2-3-递归方程"><a href="#2-3-递归方程" class="headerlink" title="2.3 递归方程"></a>2.3 递归方程</h1><p>递归方程是使用小的输入值来描述一个函数的方程或不等式</p><h2 id="替换法"><a href="#替换法" class="headerlink" title="替换法"></a>替换法</h2><ol><li><strong>首先猜想</strong></li><li><strong>数学归纳法证明</strong></li></ol><h4 id="替换方法："><a href="#替换方法：" class="headerlink" title="替换方法："></a>替换方法：</h4><ul><li><p><strong>联想已知的$T(n)$</strong></p><p>例1：求解$2T(\frac{n}{2}+17)+n$</p><p>解：猜测：$T(n)=2T(\frac{n}{2}+17)+n$与$T(n)=2T(\frac{n}{2})+n$只相差一个$17$</p><p>​    当n充分大时$T(\frac{n}{2}+17)$与$T(\frac{n}{2})$的差别并不大，因为$\frac{n}{2}+17$与$\frac{n}{2}$相差小</p><p>​    我们可以猜$T(n)=O(n\lg{n})$</p><hr></li><li><p><strong>猜测上下界，减少不确定性范围</strong></p><p>例2：求解$T(n)=2T(\frac{n}{2})+n$</p><p>解：首先证明$T(n)=\Omega(n),T(n)=O(n^2)$</p><p>​    然后逐阶降低上界，提高上界</p><p>​    $\Omega(n)$的上一个阶是$\Omega(n\lg(n))$</p><p>​    $O(n^2)$的下一个阶是$O(n\lg{n})$</p><hr><p><strong>细微差别的处理</strong></p><ul><li>问题：猜测正确，数学归纳法的归纳步骤似乎证不出来</li><li>解决方法：从“猜想”中减去一个低阶项，可能会成功</li></ul><p>例3：求解$T(n)=T(\lfloor\frac{n}{2}\rfloor)+T(\lceil\frac{n}{2}\rceil)+1$</p><p>解：（1）我们猜$T(n)=O(n)$</p><p>​        证：$T(n)\le c\lfloor\frac{n}{2}\rfloor+c\lceil\frac{n}{2}\rceil+1=cn+1\ne cn$</p><p>​        <strong>证不出</strong>$T(n)=O(cn)$</p><p>​       （2）减去一个低阶项，猜$T(n)\le cn-b$，$b\ge0$是常数</p><p>​        证：设当$\le n-1$时成立<br>$$<br>T(n)=T(\lfloor\frac{n}{2}\rfloor+T(\lceil\frac{n}{2}\rceil)+1\le c\lfloor\frac{n}{2}\rfloor-b+c\lfloor\frac{n}{2}\rfloor-b+1)<br>$$</p><p>$$<br>=cn-2b+1=cn-b-b+1\le cn-b（只要b\ge1）<br>$$</p></li></ul><hr><p>  <strong>避免陷阱</strong></p><p>  例4：求解$T(n)=2T(\lfloor\frac{n}{2}\rfloor)+n$</p><p>  解：猜$T(n)=O(n)$</p><p>  ​    证：用数学归纳法证明$T(n)\le cn$<br>  $$<br>  T(n)\le2(c\lfloor\frac{n}{2}\rfloor)+n\le cn+n=O(n)\quad\color{red}{错误}<br>  $$<br>  错误之处：过早地使用了$O(n)$而陷入了陷阱应该在证明了$T(n)\le cn$才可用。从$T(n)\le cn+n$不可能得到$T(n)\le cn$，因为对于任何$c&gt;0$，我们都得不到$cn+n\le cn$</p><hr><ul><li><p>变量替换法：<strong>经变量替换把递归方程变换为熟悉的方程</strong></p><p>例5：求解$T(n)=2T(\sqrt{n})+\lg{n}$</p><p>解：令$m=\lg{n}$，则$n=2^m$，$T(2^m)=2T(2^{\frac{m}{2}})+m$</p><p>​        令$S(m)=T(2^m)$，则$T(2^{\frac{m}{2}})=S(\frac{m}{2})$</p><p>​        于是，$S(m)=2S(\frac{m}{2})+m$</p><p>​        显然，$S(m)=O(m\lg{m})$，即$T(2^m)=\Theta(m\lg{m})$</p><p>​        由于$2^m=n$，$m=\lg{n}$，$T(n)=\Theta(\lg{n}\times\lg(\lg{n}))$</p></li></ul><h2 id="迭代方法"><a href="#迭代方法" class="headerlink" title="迭代方法"></a>迭代方法</h2><ol><li>循环地展开递归方程（画出递归树）</li><li>将递归方程转化为和式</li><li>使用求和技术解之</li></ol><hr><p><strong>递归树</strong></p><ul><li>根结点表示递归调用顶层的代价</li><li>内部节点，表示合并其子问题的代价</li><li>树的分支数量取决于子问题的数量</li><li>叶节点表示边界条件值</li></ul><p>例：$T(n)=3T(\frac{n}{4})+cn^2$，用递归法确定一个渐近上界，画出递归树。</p><p>解：</p><p>$T(n)=3T(\frac{n}{4})+cn^2$</p><p>$=cn^2+3[c\frac{n^2}{16}+3T(\frac{n}{16})]$</p><p>$=cn^2+3[c\frac{n^2}{16}+3[c\frac{n^2}{256}+3T(\frac{n}{64})]]$</p><p>……</p><p>$=3^0cn^2+3^1(\frac{n}{4})^2+3^2c(\frac{n}{4^2})^2+…+3^iT(\frac{n}{4^i})$</p><p>令$\frac{n}{4^i}=1\implies4^i=n\implies i=\log_4{n}$</p><p>$=3^0cn^2+3^1(\frac{n}{4})^2+3^2c(\frac{n}{4^2})^2+…+3^iT(1)$</p><p>$\le\sum_{i=0}^{\log_4{n}}{3^i(\frac{n}{4^i})^2+O(n)}\le n^2\sum_{i=0}^{\infin}{(\frac{3}{16})^i}$</p><p>$=n^2\times\frac{1}{1-\frac{3}{16}}=\frac{16}{13}n^2=O(n^2)$</p><p><img src="http://note.lizhihao999.cn/notes/20200818113634.png" alt="递归树"></p><hr><p>例6：$T(n)=n+3T(\lfloor\frac{n}{4}\rfloor)$</p><p>解：</p><img src="http://note.lizhihao999.cn/notes/20200819093653.png" style="zoom: 80%;"><h2 id="Master定理法"><a href="#Master定理法" class="headerlink" title="Master定理法"></a>Master定理法</h2><ul><li><strong>目的</strong>：求解$T(n)=aT(\frac{n}{b})+f(n)$型方程，$a\ge1,b&gt;0$是常数，$f(n)$是正函数</li><li><strong>方法</strong>：记住三种情况，不用纸笔直接求解</li></ul><hr><p><strong>Master定理</strong></p><p>设$a\ge1$和$b\ge1$是常数，$f(n)$是一个函数，$T(n)$是定义在非负整数集上的函数$T(n)=aT(\frac{n}{b})+f(n)$. $T(n)$可以如下求解：</p><ol><li>若$f(n)=O(n^{\log_b{a}-\epsilon}),\epsilon&gt;0$是常数，则$T(n)=\Theta(n^{\log_b{a}})$</li><li>若$f(n)=\Theta(n^{\log_b{a}})$，则$T(n)=\Theta(n^{\log_b{a}}\lg{n})$</li><li>若$f(n)=\Omega(n^{\log_b{a}+\epsilon}),\epsilon&gt;0$是常数，且对所有充分大的$n,af(\frac{n}{b})\le cf(n),c&gt;1$是常数，则$T(n)=\Theta(f(n))$</li></ol><p><strong>直观地：</strong>用$f(n)$与$n^{\log_b{a}}$比较</p><ol><li><p>若$n^{\log_b{a}}$大，则$T(n)=\Theta(n^{\log_b{a}})$</p><ol start="2"><li>若$f(n)$大，则$T(n)=\Theta(f(n))$</li><li>若$f(n)$与$n^{\log_b{a}}$同阶，则$T(n)=\Theta(n^{\log_b{a}}\lg{n})=\Theta(f(n)\lg{n})$</li></ol></li></ol><p><img src="http://note.lizhihao999.cn/notes/20200818115456.png"><br>$$<br>\color{red}{对于红色部分，Master定理无能为力}<br>$$<br><strong>更进一步</strong>：</p><ol><li><p>在第一种情况，$f(n)$不仅小于$n^{\log_b{a}}$，必须多项式地小于，即对于一个常数$\epsilon&gt;0,;f(n)=O(\frac{n^{\log_b{a}}}{n^\epsilon})$</p></li><li><p>在第三种情况，$f(n)$不仅大于$n^{\log_b{a}}$，必须多项式地大于，即对于一个常数$\epsilon&gt;0,;f(n)=\Omega(n^{\log_b{a}}\cdot n^\epsilon)$</p></li></ol><hr><p>例7：求解$T(n)=9T(\frac{n}{3})+n$</p><p>解：$a=9,;b=3,;f(n)=n,;n^{\log_b{a}}=\Theta(n^2)$</p><p>​        $\because f(n)=n=O(n^{\log_b{a}-\epsilon}),;\epsilon=1$</p><p>​        $\therefore T(n)=\Theta(n^{\log_b{a}})=\Theta(n^2)$</p><p>例8：求解$T(n)=T(\frac{2n}{3})+1$</p><p>解：$a=1,;b=\frac{3}{2},;f(n)=1,;n^{log_{\frac{3}{2}}1}=n^0=1$</p><p>​        $f(n)=1=\Theta(1)=\Theta(n^{\log_b{a}}),;T(n)=\Theta(n^{\log_b{a}}\cdot\lg{n})=\Theta(\lg{n})$</p><p>例9：求解$T(n)=3T(\frac{n}{4})+n\lg{n}$</p><p>解：$a=3,;b=4,;f(n)=n\lg{n},;n^{\log_b{a}}=n^{\log_4{3}}=O(n^{0.793})$</p><p>​        （1）$f(n)=n\lg{n}\ge n=n^{\log_b{a}+\epsilon},;\epsilon\approx0.2$</p><p>​        （2）对所有$n,;af(\frac{n}{b})=3\times\frac{n}{4}\lg{\frac{n}{4}}=\frac{3}{4}n\lg{\frac{n}{4}}\le\frac{3}{4}n\lg{n}=cf(n),;c=\frac{3}{4}$</p><p>​        于是，$T(n)=\Theta(f(n))=\Theta(n\lg{n})$</p><p>例10：求解$T(n)=2T(\frac{n}{2})+n\lg{n}$</p><p>解：$a=2,;b=2,;f(n)=n\lg{n},;n^{log_b{a}}=n$</p><p>​        $f(n)=n\lg{n}$大于$n^{\log_b{a}}=n$</p><p>​        但<strong>不是多项式地大于</strong>，Master定理<strong>不适用</strong>于该$T(n)$</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法概论</title>
      <link href="2020/04/25/suan-fa-bi-ji/suan-fa-gai-lun/"/>
      <url>2020/04/25/suan-fa-bi-ji/suan-fa-gai-lun/</url>
      
        <content type="html"><![CDATA[<h1 id="1-1-算法"><a href="#1-1-算法" class="headerlink" title="1.1 算法"></a>1.1 算法</h1><h2 id="（1）计算"><a href="#（1）计算" class="headerlink" title="（1）计算"></a>（1）计算</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>可由一个<strong>给定计算模型</strong>机械地<strong>执行的规则</strong>或<strong>计算步骤序列</strong>称为该计算模型的一个计算</p><ul><li>一个计算机程序是一个计算</li><li>计算可能永远不会停止</li><li>不是算法</li></ul><h2 id="（2）算法"><a href="#（2）算法" class="headerlink" title="（2）算法"></a>（2）算法</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><ol><li>算法是满足下列条件的计算：</li></ol><ul><li><strong>有穷性/终止性</strong>：有限步内必须停止</li><li><strong>确定性</strong>：每一步都是严格定义和确定的动作</li><li><strong>可行性</strong>：每一个动作都能够被精确地机械执行</li><li><strong>输入</strong>：有一个满足给定约束条件的输入<ul><li>函数可以没有输入</li><li>算法必须有输入</li></ul></li><li><strong>输出</strong>：满足给定约束条件地结果</li></ul><ol><li>算法的目的是求解问题</li><li>一个算法<strong>面向一个问题</strong>，而不是仅求解一个问题的一个或几个实例</li></ol><h3 id="算法的描述"><a href="#算法的描述" class="headerlink" title="算法的描述"></a>算法的描述</h3><ol><li><p>伪代码</p></li><li><p>实例</p><pre><code class="pseudocode">Input: A[1, ..., n] = n个数Output: A[1, ..., n] = n个sorted数FOR j=2 To n Do    key &lt;- A[j];    i &lt;- j-1    WHILE i&gt;0 AND A[i]&gt;key Do        A[i+1] &lt;- A[i];        i &lt;- i-1;    A[i+1] &lt;- key;</code></pre></li></ol><h2 id="（3）问题"><a href="#（3）问题" class="headerlink" title="（3）问题"></a>（3）问题</h2><h3 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h3><p>设Input和Output是两个<strong>集合</strong>。一个问题是一个<strong>关系R $\subseteq$ Input × Output</strong></p><ul><li><p><strong>Input</strong>称为问题R的<strong>输入集合</strong><br>$$<br>Input = { &lt;a_1,….,a_n&gt; | a_i是整数 }<br>$$</p><ul><li>Input的每个元素称为R的一个输入</li></ul></li><li><p><strong>Output</strong>称为问题R的<strong>输出或结果集合</strong><br>$$<br>Output = { &lt;b_1,….,b_n&gt; | b_i是整数，且b_i  \le…\le b_n}<br>$$</p><ul><li>Output的每个元素称为R的一个结果</li></ul></li><li><p><strong>问题</strong>定义了<strong>输入和输出的关系</strong> $\to$ </p></li></ul><p>$$<br>R = {<br>( &lt; a_1, … ,a_n &gt;, &lt; b_1, …, b_n &gt; ) | &lt; a_1, … , a_n &gt; \in Input, \<br>&lt; b_1, … ,b_n &gt; \in Output,<br>{a_1, … ,a_n} = {b_1, … ,b_n}<br>}<br>$$</p><h1 id="1-2-计算机科学中算法的位置"><a href="#1-2-计算机科学中算法的位置" class="headerlink" title="1.2 计算机科学中算法的位置"></a>1.2 计算机科学中算法的位置</h1><hr><h2 id="（1）算法是计算机科学基础的重要主题"><a href="#（1）算法是计算机科学基础的重要主题" class="headerlink" title="（1）算法是计算机科学基础的重要主题"></a>（1）算法是计算机科学基础的重要主题</h2><h2 id="（2）计算机科学的体系"><a href="#（2）计算机科学的体系" class="headerlink" title="（2）计算机科学的体系"></a>（2）计算机科学的体系</h2><h3 id="解决一个计算问题的过程"><a href="#解决一个计算问题的过程" class="headerlink" title="解决一个计算问题的过程"></a>解决一个计算问题的过程</h3><ol><li>可计算否</li><li>能行计算否</li><li>算法设计与分析</li><li>用计算机语言实现算法</li><li>软件系统</li></ol><h3 id="可计算理论"><a href="#可计算理论" class="headerlink" title="可计算理论"></a>可计算理论</h3><ul><li>计算模型</li><li>可计算问题／不可计算问题</li><li>计算模型的等价性$\to$ 图灵/Church命题</li></ul><h3 id="计算复杂性理论"><a href="#计算复杂性理论" class="headerlink" title="计算复杂性理论"></a>计算复杂性理论</h3><ul><li>在给定的计算模型夏研究问题的复杂性<ul><li>固有复杂性</li><li>上界</li><li>下界</li><li>平均</li><li>复杂性问题的分类 $\to$ P/NP</li><li>抽象复杂性研究</li></ul></li></ul><h3 id="算法设计与分析"><a href="#算法设计与分析" class="headerlink" title="算法设计与分析"></a>算法设计与分析</h3><ul><li>可计算问题的算法的设计与分析</li><li>设计算法的理论、方法和技术</li><li>分析算法的理论、方法和技术</li></ul><h3 id="计算机软件"><a href="#计算机软件" class="headerlink" title="计算机软件"></a>计算机软件</h3><ul><li>系统软件</li><li>工具软件</li><li>应用软件</li></ul><h1 id="1-3-算法分析引论"><a href="#1-3-算法分析引论" class="headerlink" title="1.3 算法分析引论"></a>1.3 算法分析引论</h1><hr><h2 id="（1）算法的正确性"><a href="#（1）算法的正确性" class="headerlink" title="（1）算法的正确性"></a>（1）算法的正确性</h2><ul><li><p>一个算法是正确 $\to$ 对于每一个输入都最终停止，而且产生正确的输出</p></li><li><p>不正确算法</p><ul><li>不停止</li><li>对所有输入都停止，但对输入产生不正确结果</li></ul></li><li><p>近似算法</p><ul><li>对所有输入都停止</li><li>产生近似正确的解或产生不多的不正确解</li></ul></li></ul><h2 id="（2）算法正确性的证明"><a href="#（2）算法正确性的证明" class="headerlink" title="（2）算法正确性的证明"></a>（2）算法正确性的证明</h2><ul><li>证明算法对所有输入都停止</li><li>证明对每个输入都产生正确结果</li><li>调试程序 $\ne$ 程序正确性证明</li></ul><h2 id="（3）算法复杂性分析"><a href="#（3）算法复杂性分析" class="headerlink" title="（3）算法复杂性分析"></a>（3）算法复杂性分析</h2><ul><li><p>目的</p><ul><li>预测算法对不同输入所需资源量</li></ul></li><li><p>复杂性测度 $\to$ <strong>输入大小的函数</strong></p><ul><li>时间</li><li>空间</li><li>I/O</li></ul></li><li><p>用途</p><ul><li>为求解一个问题选择最佳算法、最佳设备</li></ul></li><li><p>需要的数学基础</p><ul><li>离散数学</li><li>组合数学</li><li>概率论</li><li>代数</li></ul></li><li><p>需要的数学能力</p><ul><li>建立算法复杂性的数学模型</li><li>数学模型化简</li></ul></li></ul><h2 id="（4）算法复杂性分析的度量"><a href="#（4）算法复杂性分析的度量" class="headerlink" title="（4）算法复杂性分析的度量"></a>（4）算法复杂性分析的度量</h2><h3 id="输入的大小（输入规模）"><a href="#输入的大小（输入规模）" class="headerlink" title="输入的大小（输入规模）"></a>输入的大小（输入规模）</h3><ul><li>设Input是问题R的输入集合</li><li>R的<strong>输入大小</strong>是一个函数<strong>F：Input $\to$ N, N是正整数集合</strong></li><li>输入规模量度<ul><li>最自然的量度：<strong>输入中的项数</strong></li><li>对于研究的每个问题将指出所使用的输入规模量度</li></ul></li></ul><h3 id="时间复杂性"><a href="#时间复杂性" class="headerlink" title="时间复杂性"></a>时间复杂性</h3><ul><li>一个算法对特定输入的时间复杂性是该算法对该输入产生结果需要的<strong>原子(基本)操作数</strong>或<strong>步数</strong></li><li><strong>注意</strong><ul><li>时间复杂性是输入大小的函数</li><li>我们假设每一步的执行需要常数时间，实际上每步需要的时间量可能不同</li></ul></li></ul><h3 id="空间复杂性"><a href="#空间复杂性" class="headerlink" title="空间复杂性"></a>空间复杂性</h3><ul><li>一个算法对特定输入的空间复杂性是该算法对该输入产生结果所需要的存储空间大小</li></ul><h3 id="最坏复杂性"><a href="#最坏复杂性" class="headerlink" title="最坏复杂性"></a>最坏复杂性</h3><p>设Input是问题R的输入集合，$Complexity(X)$是求解R的算法A的复杂性函数，$size(y)$是确定R中输入大小的函数，A的最坏复杂性是<br>$$<br>Max{ Complexity,(size(y)),|,y\in Input }<br>$$<br>我们往往集中于只求<strong>最坏情况运行时间</strong>：</p><ul><li>最坏复杂性给出任何输入的运行时间的一个<strong>上界</strong>，能够确保该算法绝不需要更长的时间</li><li>对某些算法，最坏情况经常出现<ul><li>例：在数据库中检索一条不存在的信息</li></ul></li><li>平均复杂性往往与最坏复杂性大致一样差<ul><li>例：随机选择n个数并应用插入排序</li></ul></li></ul><h3 id="最小复杂性"><a href="#最小复杂性" class="headerlink" title="最小复杂性"></a>最小复杂性</h3><p>$$<br>Min{ Complexity,(size(y)),|,y\in Input }<br>$$</p><h3 id="平均复杂性"><a href="#平均复杂性" class="headerlink" title="平均复杂性"></a>平均复杂性</h3><p>设 $y\in Input$, y作为算法A的输入出现的概率是$p_y$，A的平均复杂性为</p><p>$$<br> \sum_{y\in Input} p_y \times complexity(size(y))<br>$$</p><h3 id="增长量级"><a href="#增长量级" class="headerlink" title="增长量级"></a>增长量级</h3><ul><li><strong>抽象</strong>：<ul><li><strong>只考虑公式中最重要的项</strong></li><li>忽略<strong>低阶项</strong></li><li>忽略<strong>最重要项</strong>的<strong>常系数</strong></li></ul></li><li>记作：**$\Theta(n^2)$**</li><li>如果一个算法的最坏情况运行时间具有比另一个算法更低的增长量级，通常认为前者比后者有效</li></ul><h2 id="（5）算法分析的模型"><a href="#（5）算法分析的模型" class="headerlink" title="（5）算法分析的模型"></a>（5）算法分析的模型</h2><h3 id="随机访问模型-Random-Access-Model-RAM"><a href="#随机访问模型-Random-Access-Model-RAM" class="headerlink" title="随机访问模型(Random-Access-Model, RAM)"></a>随机访问模型(Random-Access-Model, RAM)</h3><ul><li>单处理机<ul><li>串行执行</li><li>无并发</li></ul></li><li>指令（所需时间为<strong>常量</strong>）<ul><li>算术指令<ul><li>加减乘除</li><li>向上/向下取整</li><li>取余</li></ul></li><li>数据移动指令<ul><li>装入</li><li>存储</li><li>复制</li></ul></li><li>控制指令<ul><li>条件/无条件转移</li><li>子程序调用/返回</li></ul></li></ul></li><li>基本数据类型<ul><li>整数型</li><li>浮点实数型</li></ul></li><li>基本操作 $\to$ 每个操作常数的时间</li></ul><h3 id="并行多处理机模型-PRAM"><a href="#并行多处理机模型-PRAM" class="headerlink" title="并行多处理机模型(PRAM)"></a>并行多处理机模型(PRAM)</h3><p>暂不涉及</p><h1 id="1-4-算法设计引论"><a href="#1-4-算法设计引论" class="headerlink" title="1.4 算法设计引论"></a>1.4 算法设计引论</h1><hr><h2 id="（1）算法设计模式"><a href="#（1）算法设计模式" class="headerlink" title="（1）算法设计模式"></a>（1）算法设计模式</h2><ul><li>暴力搜索</li><li>分治法</li><li>图搜索与枚举<ul><li>分支界限</li><li>回溯</li></ul></li><li>随机化方法</li></ul><h2 id="（2）算法实现方法"><a href="#（2）算法实现方法" class="headerlink" title="（2）算法实现方法"></a>（2）算法实现方法</h2><ul><li>递归与迭代</li><li>顺序、并行与分布式</li><li>确定性与非确定性</li><li>近似求解与精确求解</li><li>量子算法</li></ul><h2 id="（3）最优化设计方法"><a href="#（3）最优化设计方法" class="headerlink" title="（3）最优化设计方法"></a>（3）<strong>最优化设计方法</strong></h2><ul><li>线性规划</li><li>动态规划</li><li>贪心法</li><li>启发式方法</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gunicorn基本使用</title>
      <link href="2020/04/03/tuo-keng-ji-lu/gunicorn-ji-ben-shi-yong/"/>
      <url>2020/04/03/tuo-keng-ji-lu/gunicorn-ji-ben-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="开启Gunicorn任务"><a href="#开启Gunicorn任务" class="headerlink" title="开启Gunicorn任务"></a>开启Gunicorn任务</h1><pre><code class="shell">gunicorn --bind unix:/tmp/域名.socket projectname.wsgi:application</code></pre><h1 id="查找masterpid"><a href="#查找masterpid" class="headerlink" title="查找masterpid"></a>查找masterpid</h1><p>首先获取Gunicorn进程树，获取进程pid</p><pre><code class="shell">pstree -ap|grep gunicorn</code></pre><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200402234636.png"></p><p>可以看到，29585为主进程</p><h1 id="重启Gunicorn任务"><a href="#重启Gunicorn任务" class="headerlink" title="重启Gunicorn任务"></a>重启Gunicorn任务</h1><pre><code class="shell">kill -HUP pid</code></pre><h1 id="退出Gunicorn任务"><a href="#退出Gunicorn任务" class="headerlink" title="退出Gunicorn任务"></a>退出Gunicorn任务</h1><pre><code class="shell">kill -9 pid</code></pre><p>再次查看Gunicorn进程树，可以看到主进程已经停止</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200402234859.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu服务器安装Anaconda</title>
      <link href="2020/04/03/tuo-keng-ji-lu/ubuntu-fu-wu-qi-an-zhuang-anaconda/"/>
      <url>2020/04/03/tuo-keng-ji-lu/ubuntu-fu-wu-qi-an-zhuang-anaconda/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Anaconda 是一个用于科学计算的 Python 发行版，支持 Linux, Mac, Windows, 包含了众多流行的科学计算、数据分析的 Python 包。</p></blockquote><h1 id="Anaconda-下载"><a href="#Anaconda-下载" class="headerlink" title="Anaconda 下载"></a>Anaconda 下载</h1><ul><li><h2 id="Anaconda官网"><a href="#Anaconda官网" class="headerlink" title="Anaconda官网"></a><a href="https://www.anaconda.com/">Anaconda官网</a></h2><p>如果有梯子的话速度会比较快，如果没有梯子的话，速度可能会<strong>很慢</strong>。</p></li><li><h2 id="清华大学开源软件镜像站"><a href="#清华大学开源软件镜像站" class="headerlink" title="清华大学开源软件镜像站"></a><a href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/">清华大学开源软件镜像站</a></h2><p>建议使用这种方式下载（<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">下载地址</a>），按时间排序，选择合适的最新版：<code>64位Linux版</code></p><p>可以先下载到本地，通过<code>Xftp</code>传到Ubuntu服务器，也可以直接下载到服务器端。</p></li></ul><h1 id="Anaconda-安装"><a href="#Anaconda-安装" class="headerlink" title="Anaconda 安装"></a>Anaconda 安装</h1><ol><li><p>在终端中进到<code>.sh</code>文件所在文件夹</p></li><li><p>运行<code>.sh</code>文件</p><pre><code class="shell">bash Anaconda3-2020.02-Linux-x86_64.sh</code></pre></li><li><p>一路<code>Enter</code>，然后输入<code>yes</code>，接受协议</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/%E6%89%B9%E6%B3%A8%202020-04-02%20230506.png"></p></li><li><p>选择安装路径，<code>Enter</code>选择默认路径，也可以自己更改</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200402231106.png"></p><p>选择完成后，开始安装</p></li><li><p>安装完成后，选择使用<code>conda</code></p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200402232510.png"></p></li><li><p>安装成功</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200402232718.png"></p></li></ol><h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><ol><li><p>打开配置文件</p><pre><code class="shell">vim ~/.bashrc</code></pre></li><li><p>添加环境路径</p><pre><code>export PATH=/home/XXX/anaconda3/bin:$PATH</code></pre><p>填入自己的安装路径</p></li><li><p>激活环境</p><pre><code class="shell">source ~/.bashrc</code></pre></li><li><p>查看Anaconda和python版本</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200402233509.png"></p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux配置虚拟环境</title>
      <link href="2020/03/29/tuo-keng-ji-lu/linux-pei-zhi-xu-ni-huan-jing/"/>
      <url>2020/03/29/tuo-keng-ji-lu/linux-pei-zhi-xu-ni-huan-jing/</url>
      
        <content type="html"><![CDATA[<h1 id="安装Python"><a href="#安装Python" class="headerlink" title="安装Python"></a>安装Python</h1><p>版本在这个[网址](<a href="https://www.python.org/ftp/python/">Index of /ftp/python/</a>)里面进行选择，例如选择<code>3.7.0</code>版本，可通过以下操作实现：</p><pre><code class="shell">wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgzsudo tar zxvf Python-3.7.0.tgz -C /usr/local/cd /usr/local/Python-3.7.0sudo ./configure --prefix=/usr/local/python3.7sudo makesudo make install</code></pre><p>可以自定义安装路径和该版本Python的前缀，如果是多版本Python，注意区分路径和前缀。</p><h1 id="安装虚拟环境"><a href="#安装虚拟环境" class="headerlink" title="安装虚拟环境"></a>安装虚拟环境</h1><p>输入命令：</p><pre><code class="shell">sudo pip install virtualenvsudo pip install virtualenvwrapper</code></pre><ul><li><strong>virtualenv</strong>是虚拟环境的软件工具，可以在系统中建立多个互不干扰的虚拟环境</li><li><strong>virtualenvwrapper</strong>对<strong>virtualenv</strong>进行封装，更加方便管理虚拟环境</li></ul><h1 id="virtualenv的使用"><a href="#virtualenv的使用" class="headerlink" title="virtualenv的使用"></a>virtualenv的使用</h1><ul><li><p>新建虚拟环境</p><pre><code class="shell">mkdir Myprojectcd Myprojectvirtualenv --python=python3 venvvirtualenv --no-site-packages --python=python3.7 venv</code></pre><ul><li><code>--python=python3</code>指定python环境</li><li><code>--no-site-packages</code>指定获取独立第三方包的环境</li><li><code>venv</code>为虚拟环境名称</li></ul></li><li><p>激活虚拟环境</p><pre><code class="shell">source venv/bin/activate</code></pre></li><li><p>退出虚拟环境</p><pre><code class="shell">deactivate</code></pre></li></ul><h1 id="配置一致的开发环境"><a href="#配置一致的开发环境" class="headerlink" title="配置一致的开发环境"></a>配置一致的开发环境</h1><ul><li><p>导出当前python环境的包</p><pre><code class="shell">pip freeze &gt; requirements.txt</code></pre><p>当前环境所有依赖的包及其版本都会收集到<code>requiements.txt</code>中</p></li><li><p>在新环境中安装项目所需的包</p><pre><code class="shell">pip install -r requirements.txt</code></pre></li></ul><h1 id="使用virtualenvwrapper管理虚拟环境"><a href="#使用virtualenvwrapper管理虚拟环境" class="headerlink" title="使用virtualenvwrapper管理虚拟环境"></a>使用virtualenvwrapper管理虚拟环境</h1><h2 id="设置Linux环境变量"><a href="#设置Linux环境变量" class="headerlink" title="设置Linux环境变量"></a>设置Linux环境变量</h2><ul><li><p>将<strong>virtualenvwrapper</strong>添加到当前的环境变量中，先打开<strong>bashrc</strong>文件（针对当前用户）</p><pre><code class="shell">sudo vim ~/.bashrc</code></pre></li><li><p>写入以下代码</p><pre><code class="shell">export WORKON_HOME=~/Envs #设置virtualenv的统一管理目录export VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages'   export VIRTUALENVWRAPPER_PYTHON=/home/admin/anaconda3/bin/python3 #指定python解释器</code></pre></li><li><p>执行<strong>virtualenvwrapper</strong>安装脚本</p><pre><code class="shell">source /home/admin/anaconda3/bin/virtualenvwrapper.sh</code></pre></li><li><p>激活设置</p><pre><code class="shell">source ~/.bashrc</code></pre></li></ul><h2 id="virtualenvwrapper的使用"><a href="#virtualenvwrapper的使用" class="headerlink" title="virtualenvwrapper的使用"></a>virtualenvwrapper的使用</h2><p><strong>virtualenvwrapper</strong>能够将所有的虚拟环境目录集中起来，能够对所有的虚拟环境进行统一管理，不需要自己去找对应的虚拟环境目录去激活。</p><ul><li><p>创建虚拟环境</p><pre><code class="shell">mkvirtualenv [-a project_path] [-i package] [-r requirements_file] [virtualenv options] ENVNAMEmkvirtualenv dataadmin</code></pre></li><li><p>激活虚拟环境</p><pre><code class="shell">worken dataadmin</code></pre></li><li><p>退出当前虚拟环境</p><pre><code class="shell">deactivate</code></pre><p>也可以直接切换到另外的环境</p><pre><code class="shell">worken anothervenv</code></pre></li><li><p>删除虚拟环境（需要先退出）</p><pre><code class="shell">rmvirtualenv dataadmin</code></pre></li><li><p>所有虚拟环境列表</p><pre><code class="shell">lsvirtualenv</code></pre></li><li><p>导航到当前环境的目录</p><pre><code class="shell">cdvirtualenv</code></pre></li><li><p>导航到当前环境的<strong>site-packages</strong>目录</p><pre><code class="shell">cdsitepackages</code></pre></li><li><p><strong>site-packages</strong>列表</p><pre><code class="shell">lssitepackages</code></pre></li></ul><p>更多操作见<a href="https://virtualenvwrapper.readthedocs.io/en/latest/command_ref.html">官网</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pycharm远程调试</title>
      <link href="2020/03/28/tuo-keng-ji-lu/pycharm-yuan-cheng-diao-shi/"/>
      <url>2020/03/28/tuo-keng-ji-lu/pycharm-yuan-cheng-diao-shi/</url>
      
        <content type="html"><![CDATA[<blockquote><p>IDE：PyCharm 2021.1.3 (Professional Edition)<br>ECS：Ubuntu 16.04.4 LTS</p><p><em>该功能需要专业版PyCharm</em></p></blockquote><p>利用PyCharm进行远程调试，即利用云服务器端的环境调试本地代码，实现本地开发，Linux云端调试。为了在本地的PyCharm连接上云服务器的环境，首先需要先配置好服务器端的环境。</p><h2 id="一-配置远程连接"><a href="#一-配置远程连接" class="headerlink" title="一. 配置远程连接"></a>一. 配置远程连接</h2><h4 id="1-进入Pycharm菜单栏，如下图依次点击Tools-gt-Deployment-gt-Configuration…"><a href="#1-进入Pycharm菜单栏，如下图依次点击Tools-gt-Deployment-gt-Configuration…" class="headerlink" title="1. 进入Pycharm菜单栏，如下图依次点击Tools->Deployment->Configuration…"></a>1. 进入Pycharm菜单栏，如下图依次点击Tools-&gt;Deployment-&gt;Configuration…</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328204451.png" alt="菜单栏"></p><h4 id="2-右侧点击-添加SFTP"><a href="#2-右侧点击-添加SFTP" class="headerlink" title="2. 右侧点击+添加SFTP"></a>2. 右侧点击+添加SFTP</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328213703.png"></p><h4 id="3-设置Name（自己设置）"><a href="#3-设置Name（自己设置）" class="headerlink" title="3. 设置Name（自己设置）"></a>3. 设置Name（自己设置）</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328213919.png"></p><h4 id="4-填写连接配置"><a href="#4-填写连接配置" class="headerlink" title="4. 填写连接配置"></a>4. 填写连接配置</h4><ul><li><strong>Host（外网IP）</strong></li><li><strong>端口</strong></li><li><strong>用户名</strong></li><li><strong>密码</strong></li></ul><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/1.png" style="zoom:80%;"><p>填好之后可以<strong>测试连接</strong></p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/2.png"></p><p>之后点击<strong>Autodetect</strong>确定根目录</p><h4 id="5-点击OK结束"><a href="#5-点击OK结束" class="headerlink" title="5. 点击OK结束"></a>5. 点击OK结束</h4><h2 id="二-配置远程解释器"><a href="#二-配置远程解释器" class="headerlink" title="二. 配置远程解释器"></a>二. 配置远程解释器</h2><h4 id="1-进入Pycharm菜单栏，如下图依次点击File-gt-Settings…"><a href="#1-进入Pycharm菜单栏，如下图依次点击File-gt-Settings…" class="headerlink" title="1. 进入Pycharm菜单栏，如下图依次点击File->Settings…"></a>1. 进入Pycharm菜单栏，如下图依次点击File-&gt;Settings…</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328223125.png"></p><h4 id="2-选择Project-gt-Project-Interpreter"><a href="#2-选择Project-gt-Project-Interpreter" class="headerlink" title="2. 选择Project->Project Interpreter"></a>2. 选择Project-&gt;Project Interpreter</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328223329.png"></p><h4 id="3-点击添加解释器"><a href="#3-点击添加解释器" class="headerlink" title="3. 点击添加解释器"></a>3. 点击添加解释器</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328223536.png"></p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328223554.png"></p><h4 id="4-选择SSH-Interpreter-gt-Existing-server-configuration-gt-刚刚新建的Deployment"><a href="#4-选择SSH-Interpreter-gt-Existing-server-configuration-gt-刚刚新建的Deployment" class="headerlink" title="4. 选择SSH Interpreter->Existing server configuration->刚刚新建的Deployment"></a>4. 选择SSH Interpreter-&gt;Existing server configuration-&gt;刚刚新建的Deployment</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/4.png"></p><h4 id="5-选择Move-gt-Next"><a href="#5-选择Move-gt-Next" class="headerlink" title="5. 选择Move ->Next"></a>5. 选择Move -&gt;Next</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200331105544.png"></p><h4 id="6-设置远端解释器"><a href="#6-设置远端解释器" class="headerlink" title="6. 设置远端解释器"></a>6. 设置远端解释器</h4><p>我在这里设置为虚拟环境中的解释器，是否需要<strong>sudo</strong>权限根据自己的实际需要</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/5.png"></p><p>可以看到pycharm在<code>tmp</code>文件夹下新建了<code>pycharm_project_xxx</code>文件夹用于放置本地的同步项目代码</p><p>点击<strong>Finish</strong>结束配置</p><h4 id="7-成功后可以看到环境中的安装的依赖包"><a href="#7-成功后可以看到环境中的安装的依赖包" class="headerlink" title="7. 成功后可以看到环境中的安装的依赖包"></a>7. 成功后可以看到环境中的安装的依赖包</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328224945.png"></p><p>点击<strong>Apply</strong>完成配置</p><h4 id="8-检查Mappings"><a href="#8-检查Mappings" class="headerlink" title="8. 检查Mappings"></a>8. 检查Mappings</h4><ul><li><strong>Tools-&gt;Deployment-&gt;Configuration…</strong></li><li><strong>查看之前Deployment的Mappings下的Deployment path</strong></li></ul><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200331111651.png"></p><ul><li><strong>如果没有自动定位可以手动设置</strong></li></ul><h2 id="三-远程调试本地代码"><a href="#三-远程调试本地代码" class="headerlink" title="三.远程调试本地代码"></a>三.远程调试本地代码</h2><blockquote><p>以<strong>Django</strong>项目为例</p></blockquote><h4 id="1-设置ALLOWED-HOSTS"><a href="#1-设置ALLOWED-HOSTS" class="headerlink" title="1. 设置ALLOWED_HOSTS"></a>1. 设置ALLOWED_HOSTS</h4><p>允许所有的host访问</p><pre><code class="python"># DataAdmin/settings.py...ALLOWED_HOSTS = ["*"]...</code></pre><h4 id="2-自动同步代码"><a href="#2-自动同步代码" class="headerlink" title="2. 自动同步代码"></a>2. 自动同步代码</h4><p>实际的运行过程是：pycharm将本地代码<strong>自动同步</strong>到服务器上对应的的<code>tmp/pycharm_projectXXX</code>文件夹中，实际运行时也是运行的服务器端的代码。</p><ul><li><strong>可以通过File Transfer查看同步情况</strong></li></ul><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200331112257.png"></p><ul><li><strong>可以通过Tools-&gt;Deployment-&gt;Browse Remote Host查看服务器端目录结构</strong></li></ul><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200331112330.png"></p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200331112502.png"></p><h4 id="3-调试运行项目"><a href="#3-调试运行项目" class="headerlink" title="3. 调试运行项目"></a>3. 调试运行项目</h4><ul><li><strong>Run manage.py-&gt;Edit  Configurations…</strong></li></ul><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200331110847.png"></p><ul><li><strong>检查Script path是否对应自己的项目地址</strong></li><li><strong>添加Parameters：<code>runserver 0.0.0.0:8000</code></strong></li><li><strong>Apply-&gt;OK</strong></li><li><strong>Run</strong></li></ul><p>打开<strong>IP:8000</strong>，可以看到自己的网页</p><h2 id="四-远程调试云端代码"><a href="#四-远程调试云端代码" class="headerlink" title="四. 远程调试云端代码"></a>四. 远程调试云端代码</h2><h4 id="1-连接到服务器Tools-gt-Start-SSH-session…"><a href="#1-连接到服务器Tools-gt-Start-SSH-session…" class="headerlink" title="1. 连接到服务器Tools->Start SSH session…"></a>1. 连接到服务器Tools-&gt;Start SSH session…</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328231327.png"></p><h4 id="2-选择对应的HOST"><a href="#2-选择对应的HOST" class="headerlink" title="2.选择对应的HOST"></a>2.选择对应的HOST</h4><p>连接成功后，会有终端显示</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/7.png"></p><h4 id="3-显示服务器目录结构Tools-gt-Deployment-gt-Browse-Remote-Host"><a href="#3-显示服务器目录结构Tools-gt-Deployment-gt-Browse-Remote-Host" class="headerlink" title="3. 显示服务器目录结构Tools->Deployment->Browse Remote Host"></a>3. 显示服务器目录结构Tools-&gt;Deployment-&gt;Browse Remote Host</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328231901.png"></p><p>选择后会显示出服务器目录结构，选中项目文件能够打开编辑</p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/9.png"></p><h4 id="4-编辑完成后更新版本"><a href="#4-编辑完成后更新版本" class="headerlink" title="4. 编辑完成后更新版本"></a>4. 编辑完成后更新版本</h4><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328232528.png"></p><p>可以设置自动上传更新<strong>Tools-&gt;Deployment-&gt;Automatic Upload</strong></p><p><img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200328232726.png"></p><h4 id="5-在终端调试运行"><a href="#5-在终端调试运行" class="headerlink" title="5. 在终端调试运行"></a>5. 在终端调试运行</h4><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 脱坑实录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用Channels实现WebSocket协议</title>
      <link href="2020/03/08/li-yong-channels-shi-xian-websocket-xie-yi/"/>
      <url>2020/03/08/li-yong-channels-shi-xian-websocket-xie-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="HTTP协议与WebSocket协议"><a href="#HTTP协议与WebSocket协议" class="headerlink" title="HTTP协议与WebSocket协议"></a>HTTP协议与WebSocket协议</h1><h2 id="HTTP协议简介"><a href="#HTTP协议简介" class="headerlink" title="HTTP协议简介"></a>HTTP协议简介</h2><p>​    HTTP协议指超文本传输协议（<strong>H</strong>yper<strong>T</strong>ext <strong>T</strong>ransfer <strong>P</strong>rotocol），是用于从万维网服务器传输超文本到本地浏览器的传送协议，是基于TCP/IP协议之上的应用层协议。</p><h3 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h3><ol><li><strong>简单快速</strong>：客户向服务器请求服务时，只需传送请求方法和路径，通信速度很快。</li><li><strong>灵活</strong>：HTTP允许传输任意类型的数据对象。</li><li><strong>无连接</strong>：限制每次连接只处理<strong>一个</strong>请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。</li><li><strong>无状态</strong>：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。</li><li><strong>支持客户端/服务器模型</strong></li></ol><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>HTTP是基于客户/服务器模式，且面向连接的。典型的HTTP事务处理有如下的过程：</p><ol><li>客户与服务器建立连接；</li><li>客户向服务器提出请求；</li><li>服务器接受请求，并根据请求返回相应的文件作为应答；</li><li>客户与服务器关闭连接。</li></ol><h2 id="WebSocket协议简介"><a href="#WebSocket协议简介" class="headerlink" title="WebSocket协议简介"></a>WebSocket协议简介</h2><p>​    现在，很多网站为了实现推送技术，所用的技术都是 Ajax 轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。</p><p>​    HTML5 定义的 WebSocket 协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。    </p><p>​    <strong>WebSocket</strong>是一种在单个TCP连接上进行全双工通信的协议。WebSocket使得客户端和服务器之间的数据交换变得更加简单，<strong>允许服务端主动向客户端推送数据</strong>。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建<strong>持久性的连接</strong>，并进行<strong>双向数据传输</strong>。</p><h1 id="Django-Channels实现WebSocket实时通讯"><a href="#Django-Channels实现WebSocket实时通讯" class="headerlink" title="Django Channels实现WebSocket实时通讯"></a>Django Channels实现WebSocket实时通讯</h1><blockquote><p><a href="https://channels.readthedocs.io/en/latest/">官方文档</a></p></blockquote><p>​    <strong>Channels</strong>是一个采用Django并将其功能拓展到HTTP以外的项目，以处理WebSocket协议。它基于称为<a href="http://asgi.readthedocs.io/">ASGI</a>的Python规范构建。</p><p>​    接下来基于官方Tutorial1-2简单介绍Channels的使用。</p><p>​    首先需要安装Django和Channels</p><pre><code class="powershell">pip install djangopip install channels</code></pre><p>​    创建一个Django项目，并进入项目根目录：</p><pre><code class="powershell">django-admin startproject mysitecd mysite</code></pre><p>​    接下来创建Channels的根路由<code>routing.py</code>，channels的路由配置与Django URLconf相似，它告诉Channels当Channels服务器接收到HTTP请求时要运行什么代码。</p><p>​    首先从一个空的路由配置开始，创建文件<code>mysite/routing.py</code>，包含以下代码：</p><pre><code class="python"># mysite/routing.pyfrom channels.routing import ProtocolTypeRouterapplication = ProtocolTypeRouter({    # (http-&gt;django views is added by default)})</code></pre><p>​    然后将Channels库在应用列表中进行注册：</p><pre><code class="python"># mysite/settings.pyINSTALLED_APPS = [    'django.contrib.admin',    'django.contrib.auth',    'django.contrib.contenttypes',    'django.contrib.sessions',    'django.contrib.messages',    'django.contrib.staticfiles',    # 新添加    'channels',]</code></pre><p>​    继续编辑<code>mtsite/settings.py</code>将Channels指向根路由配置，添加以下代码：</p><pre><code class="python"># mysite/settings.py# ChannelsASGI_APPLICATION = 'mysite.routing.application'</code></pre><p>​    此时Channels可以控制<code>runserver</code>命令，用Channels开发服务器代替标准的Django开发服务器。</p><p>​    运行Django项目：</p><pre><code class="powershell">py manage.py runserver</code></pre><p>​    将会看到以下输出：</p><pre><code class="powershell">Performing system checks...System check identified no issues (0 silenced).You have 17 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions.Run 'python manage.py migrate' to apply them.March 07, 2020 - 22:45:04Django version 3.0.2, using settings 'mysite.settings'Starting ASGI/Channels version 2.4.0 development server at http://127.0.0.1:8000/Quit the server with CTRL-BREAK.HTTP GET / 200 [0.04, 127.0.0.1:54871]</code></pre><p>​    可以看到<code>Starting ASGI/Channels development server at http://127.0.0.1:8000/</code>，说明Channels开发服务器已从Django开发服务器接管项目。打开<a href="http://127.0.0.1:8000/">初始界面</a>，你将看到熟悉的小火箭：<img src="https://raw.githubusercontent.com/Thooooor/NoteImg/master/20200307225354.png" style="zoom: 80%;"></p><p>​    关闭服务器，创建app<code>event</code>：</p><pre><code class="powershell">py manage.py startapp event</code></pre><p>​    注册app：</p><pre><code class="python"># mysite/settings.pyINSTALLED_APPS = [    'django.contrib.admin',    'django.contrib.auth',    'django.contrib.contenttypes',    'django.contrib.sessions',    'django.contrib.messages',    'django.contrib.staticfiles',    'channels',    # 新添加    'event',]</code></pre><p>​    在<strong>根目录</strong>新建文件夹<code>templates</code>以及<code>templates/event</code>文件夹放置html文件，在<code>mysite/settings.py</code>中添加路径：</p><pre><code class="python"># mysite/settings.pyTEMPLATES = [    {        'BACKEND': 'django.template.backends.django.DjangoTemplates',        # 修改        'DIRS': [os.path.join(BASE_DIR, 'templates').replace('\\', '/')],        'APP_DIRS': True,        'OPTIONS': {            'context_processors': [                'django.template.context_processors.debug',                'django.template.context_processors.request',                'django.contrib.auth.context_processors.auth',                'django.contrib.messages.context_processors.messages',            ],        },    },]</code></pre><p>​    在<code>templates</code>中添加视图文件<code>event/list.html</code>，其中WebSocket请求部分模板如下：</p><pre><code class="html">&lt;script type="text/javascript"&gt;    function Filter() {        if ("WebSocket" in window) {            //alert("您的浏览器支持WebSocket!");            // 重定向URL            let ws = new WebSocket("ws://"+ window.location.host + "/ws/event/list/");            ws.onopen = function () {                ws.send(JSON.stringify({                    'message': "测试",                    // 需要传输的数据                }));            }            ws.onmessage = function (evt) {                let received_msg = JSON.parse(evt.data);                let feed_back = received_msg['feedback'];                alert(feedback);                // 处理接受数据            }            ws.onclose = function () {                //alert("WebSocket连接已关闭...");            }        }        else {            alert("你的浏览器不支持WebSocket!");        }    }&lt;/script&gt;</code></pre><p>​    创建视图功能<code>event/views.py</code>：</p><pre><code class="python"># event/views.pyfrom django.shortcuts import renderdef list(request):    return render(request, 'event/list.html', {})</code></pre><p>​    创建路由<code>event/urls.py</code>：</p><pre><code class="python"># event/urls.pyfrom django.urls import pathfrom . import viewsurlpatterns = [    path('list/', views.list, name='list'),]</code></pre><p>​    将<code>event app</code>的路由添加到项目的根路由中：</p><pre><code class="python"># mysite/urls.pyfrom django.conf.urls import includefrom django.urls import pathfrom django.contrib import adminurlpatterns = [    path('admin/', admin.site.urls),    path('event/', include('event.urls', namespace='event')),]</code></pre><p>Channels处理请求过程：</p><pre><code>1. Channels接受HTTP请求 2. 查询根URLconf查找**消费者(consumer)** 3. 在**消费者(consumer)**中调用各种功能来处理连接的事件</code></pre><p>创建**消费者(consumer)**文件<code>event/consumers.py</code>：</p><pre><code class="powershell">event/    __init__.py    ……    consumers.py    ……    urls.py    views.py</code></pre><p>​    代码模板如下：</p><pre><code class="python"># event/consumers.pyfrom channels.generic.websocket import WebsocketConsumerimport jsonclass ListDataConsumer(WebsocketConsumer):    def connect(self):        self.accept()    def disconnect(self, close_code):        pass    def receive(self, text_data):        # 字典化接收数据        text_data_json = json.loads(text_data)        message = text_data_json['message']        # 数据处理        self.send(text_data=json.dumps({        'feedback': "Accept",        # 返回数据    }))</code></pre><p>​    为<code>consumers.py</code>配置路由，新建<code>event/routing.py</code>：</p><pre><code class="python"># event/routing.pyfrom django.urls import re_pathfrom . import consumerswebsocket_urlpatterns = [    re_path(r'ws/event/list/$', consumers.ListDataConsumer),]</code></pre><p>​    接下来将根路由指向<code>event/routing.py</code>文件：</p><pre><code class="python"># mysite/routing.pyfrom channels.auth import AuthMiddlewareStackfrom channels.routing import ProtocolTypeRouter, URLRouterimport event.routingapplication = ProtocolTypeRouter({    # (http-&gt;django views is added by default)    'websocket': AuthMiddlewareStack(        URLRouter(            event.routing.websocket_urlpatterns        )    ),})</code></pre><p>​    此根路由配置指定当与Channels开发服务器建立连接时，<code>ProtocolTypeRouter</code>将首先检查连接的类型。如果它是WebSocket连接（<strong>ws：//**或</strong>wss：//**），则该连接将分配给<code>AuthMiddlewareStack</code>。</p><p>​    在<code>AuthMiddlewareStack</code>将填充的连接的<strong>范围</strong>覆盖到当前认证的用户，然后将连接到<code>URLRouter</code>。该<code>URLRouter</code>会研究基础上，提供连接到路由到特定消费者的HTTP路径，基于<code>url</code>模式。</p><p>​    之后进行数据库模型迁移：</p><pre><code class="powershell">py manage.py makemigrationspy manage.py migrate</code></pre><p>​    运行项目：</p><pre><code class="powershell">py manage.py runserver</code></pre><p>​    如果连接建立成功，后台应该有如下显示：</p><pre><code class="powershell">HTTP GET /event/list/ 200 [0.06, 127.0.0.1:58855]WebSocket HANDSHAKING /ws/event/list/ [127.0.0.1:58906]WebSocket CONNECT /ws/event/list/ [127.0.0.1:58906]</code></pre><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>​    使用Channels的一般流程如上，在配置ASGI之后，Channels的服务器会替代原有的Django服务器处理请求。</p><p>​    只有在需要使用WebSocket协议进行实时通信时需要配置<code>routing.py</code>和<code>consumers.py</code>，由<code>routing.py</code>指向<code>consumers.py</code>处理WebSocket请求，其余仅使用HTTP协议请求的使用方式与之前并<strong>没有任何区别</strong>。</p><p>​    因为只是在一个项目中的某个app中使用了Channels，可以参考该<a href="https://github.com/Thooooor/GovermentDataAdmin">项目代码</a>中的<code>event</code>.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 技术实战 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
