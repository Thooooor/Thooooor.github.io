<!DOCTYPE html>
<html lang='en' ><meta charset="utf-8">
<meta name="viewport" content="width=device-width">


<title>A Joint Neural Model for Information Extraction with Global Features | 若虚杂记</title>

<meta name="generator" content="Hugo Eureka 0.8.4" />
<link rel="stylesheet" href="/css/eureka.min.css">
<script defer src="/js/eureka.min.js"></script>

<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
  href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&family=Noto+Serif+SC:wght@400;600;700&display=swap"
  as="style" onload="this.onload=null;this.rel='stylesheet'">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/styles/solarized-light.min.css"
   media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/highlight.min.js"
   crossorigin></script>

  <script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/languages/dart.min.js"
     crossorigin></script>

<script defer src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/js/all.min.js"
   integrity="sha256-uNYoXefWRqv&#43;PsIF/OflNmwtKM4lStn9yrz2gVl6ymo="  crossorigin></script>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
   integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3&#43;Aro6EYUG4&#43;cU&#43;KJWu/X"  media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" 
  integrity="sha384-g7c&#43;Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI&#43;sEnkvrMWph2EDg4"  crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
   integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC&#43;Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"  crossorigin></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\(", right: "\\)", display: false },
        { left: "\\[", right: "\\]", display: true }
      ],
    });
  });
</script>


<script defer src="https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js" 
  integrity="sha256-Zmpaaj&#43;GXFsPF5WdPArSrnW3b30dovldeKsW00xBVwE="  crossorigin></script>


<link rel="icon" type="image/png" sizes="32x32" href="/images/icon_hu64421c6c7700f606f0ad45d807017b09_5843_32x32_fill_box_center_3.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/icon_hu64421c6c7700f606f0ad45d807017b09_5843_180x180_fill_box_center_3.png">

<meta name="description"
  content="2020 ACL会议《A Joint Neural Model for Information Extraction with Global Features》论文笔记">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position": 1 ,
      "name":"Posts",
      "item":"/posts/"},{
      "@type": "ListItem",
      "position": 2 ,
      "name":"A Joint Neural Model for Information Extraction with Global Features",
      "item":"/posts/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ner/a-joint-neural-model-for-information-extraction-with-global-features/"}]
}
</script>



<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/posts/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ner/a-joint-neural-model-for-information-extraction-with-global-features/"
    },
    "headline": "A Joint Neural Model for Information Extraction with Global Features | 若虚杂记","datePublished": "2020-10-18T22:58:00+00:00",
    "dateModified": "2020-10-18T22:58:00+00:00",
    "wordCount":  3200 ,
    "author": {
        "@type": "Person",
        "name": ["lizhihao"]
    },
    "publisher": {
        "@type": "Person",
        "name": "Li Zhihao",
        "logo": {
            "@type": "ImageObject",
            "url": "/images/icon.png"
        }
        },
    "description": "2020 ACL会议《A Joint Neural Model for Information Extraction with Global Features》论文笔记"
}
</script><meta property="og:title" content="A Joint Neural Model for Information Extraction with Global Features | 若虚杂记" />
<meta property="og:type" content="article" />


<meta property="og:image" content="/images/icon.png">


<meta property="og:url" content="/posts/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ner/a-joint-neural-model-for-information-extraction-with-global-features/" />




<meta property="og:description" content="2020 ACL会议《A Joint Neural Model for Information Extraction with Global Features》论文笔记" />




<meta property="og:locale" content="en" />




<meta property="og:site_name" content="若虚杂记" />






<meta property="article:published_time" content="2020-10-18T22:58:00&#43;00:00" />


<meta property="article:modified_time" content="2020-10-18T22:58:00&#43;00:00" />



<meta property="article:section" content="posts" />


<meta property="article:tag" content="NER" />

<meta property="article:tag" content="ACL" />





<body class="flex flex-col min-h-screen">
  <header class="fixed flex items-center w-full min-h-16 pl-scrollbar z-50 bg-secondary-bg shadow-sm">
    <div class="w-full max-w-screen-xl mx-auto"><script>
    let storageColorScheme = localStorage.getItem("lightDarkMode")
    if (((storageColorScheme == 'Auto' || storageColorScheme == null) && window.matchMedia("(prefers-color-scheme: dark)").matches) || storageColorScheme == "Dark") {
        document.getElementsByTagName('html')[0].classList.add('dark')
    }
</script>
<nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0">
    <a href="/" class="mr-6 text-primary-text text-xl font-bold">若虚杂记</a>
    <button id="navbar-btn" class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
        <i class="fas fa-bars"></i>
    </button>

    <div id="target"
        class="hidden block md:flex md:flex-grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20">
        <div class="md:flex md:h-16 text-sm md:flex-grow pb-4 md:pb-0 border-b md:border-b-0">
            <a href="/posts/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  selected-menu-item  mr-4">Posts</a>
            <a href="/docs/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  mr-4">Docs</a>
            <a href="/#about" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  mr-4">About</a>
        </div>

        <div class="flex">
            <div class="relative pt-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="lightDarkMode">
                    <i class="fas fa-adjust"></i>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open">
                </div>
                <div class="absolute flex flex-col left-0 md:left-auto right-auto md:right-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='lightDarkOptions'>
                    <span class="px-4 py-1 hover:text-eureka" name="Light">Light</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Dark">Dark</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Auto">Auto</span>
                </div>
            </div>
        </div>
    </div>

    <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id="is-open-mobile">
    </div>

</nav>
<script>
    
    let element = document.getElementById('lightDarkMode')
    if (storageColorScheme == null || storageColorScheme == 'Auto') {
        document.addEventListener('DOMContentLoaded', () => {
            window.matchMedia("(prefers-color-scheme: dark)").addEventListener('change', switchDarkMode)
        })
    } else if (storageColorScheme == "Light") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'sun')
        element.firstElementChild.classList.add('fa-sun')
    } else if (storageColorScheme == "Dark") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'moon')
        element.firstElementChild.classList.add('fa-moon')
    }

    document.addEventListener('DOMContentLoaded', () => {
        getcolorscheme();
        switchBurger();
    });
</script>
</div>
  </header>
  <main class="flex-grow pt-16">
    <div class="pl-scrollbar">
      <div class="w-full max-w-screen-xl lg:px-4 xl:px-8 mx-auto">


<div class="grid grid-cols-2 lg:grid-cols-8 gap-4 lg:pt-12">
    <div
        class="col-span-2  lg:col-span-6 bg-secondary-bg rounded px-6 py-8">
        <h1 class="font-bold text-3xl text-primary-text">A Joint Neural Model for Information Extraction with Global Features</h1>
        <div class="flex flex-wrap flex-row items-center mt-2 text-tertiary-text">
    <div class="mr-6 my-2">
        <i class="fas fa-calendar mr-1"></i>
        <span>2020-10-18</span>
    </div>
    <div class="mr-6 my-2">
        <i class="fas fa-clock mr-1"></i>
        <span>7 min read</span>
    </div>
    
    
    <div class="mr-6 my-2">
        <i class="fas fa-folder mr-1"></i>
        
        <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="hover:text-eureka">论文笔记</a>
        
    </div>
    

    
</div>
        
        
        

        <div class="content">
            <blockquote>
<p>2020 ACL会议《A Joint Neural Model for Information Extraction with Global Features》</p>
<p><a href="https://www.aclweb.org/anthology/2020.acl-main.713/">论文地址</a></p>
</blockquote>
<p>该论文提出一个名为ONEIE的信息抽取框架，增加一个全局特征，在实例之间和子任务之间进行联合决策。</p>
<h1 id="1-introduction">1. Introduction</h1>
<p>大多数的信息抽取的联合学习模型使用task-specific分类对独立实体进行标记而不是使用实体之间的交互信息。论文提出名为ONEIE的端到端信息抽取框架，整个过程分为四个操作阶段：</p>
<ol>
<li>对输入语句进行编码（Embedding）；</li>
<li>识别句中的实体（Entity）和事件（Event）并用结点（Node）进行表示；</li>
<li>使用句内信息（Local classifier）计算所有结点及其连接（Link）的标签分数（Label Score）；</li>
<li>解码（Decoding）时使用束搜索（Beam search）找到全局最优图。</li>
</ol>
<p>在解码阶段加入全局特征（Global Feature）捕捉实例之间（cross-instance）和子任务之间（cross-subtask）的联系（Interaction）。同时ONEIE框架没有使用任何特定语言的语法特征（Language-specific feature），所以很容易适应新语言。</p>
<p><img src="http://note.lizhihao999.cn/notes/20201018225620.png" alt="框架示意图"></p>
<h1 id="2-task">2. Task</h1>
<ol>
<li>
<p><strong>Entity Extraction 实体抽取</strong></p>
<p>根据提前定义（Pre-defined）的实体分类识别语句中提及的实体。</p>
</li>
<li>
<p><strong>Relation Extraction 关系抽取</strong></p>
<p>对给定的实体对分配关系类型。</p>
</li>
<li>
<p><strong>Event Extraction 事件抽取</strong></p>
<p>涉及识别非结构语句中的事件触发语（Event trigger: the word or phrases that most clearly express event occurrences）及这些词语和短语的论据（Arguments: the words and phrases for participants in those events），并将这些短语根据类型和语法规则进行分类。</p>
<p>一个Argument可以是一个实体、时间表达式或数值等。</p>
</li>
</ol>
<p>对信息抽取的任务作如下规定：
对于给定的句子，目的是提取一个信息表示图：$G=(V,E)$，其中$V$和$E$分别表示结点集和边集。</p>
<p>对于任意结点$v_i=&lt;a_i, b_i, l_i&gt;\in V$表示一个实体（Entity）或事件触发器（Event trigger），其中$a$和$b$分别表示结点起始和结束词语的索引（indices），$l$表示结点类型标签（Node type label）。</p>
<p>对于任意边$e_{ij}=&lt;i,j,l_{ij}&gt;\in E$表示两个结点之间的关系，其中$i$和$j$分别表示两个相关结点的索引，$l_{ij}$表示关系类型。</p>
<h1 id="3-approach">3. Approach</h1>
<p>ONEIE框架对给定的语句进行信息网络提取，分为以下四步：encoding，identification，classification和decoding。我们使用预训练的BERT模型进行编码，然后对语句中的实体和事件触发器进行识别。之后计算所有的结点和相关的边的类型标签分数（Type label scores）。在解码阶段，我们使用束搜索（Beam Search）探索输入语句可能的信息网络。</p>
<h2 id="31-encoding">3.1 Encoding</h2>
<p>输入一句包含$L$个词的语句，使用预训练的BERT模型将每个词表示为$x_i$。实验发现使用最后三层BERT在大多数的子任务上表现较好。</p>
<h2 id="32-identification">3.2 Identification</h2>
<p>这一阶段将识别句中的实体提及和事件触发器，并表示为信息网络中的结点。我们使用前馈神经网络FFN计算每个词的分数向量$\hat{y}_i=FFN(x_i)$，$\hat{y}_i$表示一个标签在目标标签集（Target tag set）中的分数。</p>
<p>之后使用CRF层捕捉标签之间的联系，计算tag path： $\hat{z}={\hat{z_1},&hellip;,\hat{z}_L}$ 的分数:</p>
<img src="http://note.lizhihao999.cn/notes/20201018231804.png" style="zoom:80%;" />
<p>其中$X={x_1,&hellip;,x_L}$是输入语句中每个词的向量表示，$\hat{y}<em>{i,\hat{z_i}}$ 是分数向量 $\hat{y}<em>i$在第 $\hat{z}<em>i$条路径的组合，$A</em>{\hat{z}</em>{i-1},\hat{z}</em>{i}}$ 是矩阵A中 $\hat{z}_{i-1}$到 $\hat{z}_i$的转移分数。同时，我们在A中添加两个特殊的标签$<start>,<end>$分别作为$\hat{z}<em>0$和$\hat{z}</em>{L+1}$来表示词语序列的开始和结束。</p>
<p>训练阶段时，我们最大化标准标签路径的对数似然估计：
$$
\log{p(z|X)}=s(X,z)-log{\sum_{\hat{z}\in Z}{e^{s(X.\hat{z})}}}
$$</p>
<p>其中$Z$是输入语句中所有可能标签路径的集合。</p>
<p>所以我们定义实体识别阶段的损失函数为：
$$
L^I=-\log{p(z|X)}
$$</p>
<h2 id="33-classification">3.3 Classification</h2>
<p>将每个识别出的结点表示为$v_i$，之后使用分离的针对特定任务的前馈神经网络来计算每个结点的标签分数：
$$
\hat{y}_{i}^{t}=FFN^t(v_i)
$$</p>
<p>其中$t$表示一个特定的任务。</p>
<p>为了获得$i-th$和$j-th$结点之间边的标签分数，我们连接它们的跨度表示（Span Representation），将向量表示为：
$$
\hat{y}_{k}^{t}=FFN^t(v_i,v_j)
$$</p>
<p>对于每个任务，训练目标是最小化以下交叉熵损失：
$$
L^{t}=-\frac{1}{N^t}\sum_{i=1}^{N^t}{y_i^{t}\log{\hat{y}^{t}_{i}}}
$$</p>
<p>其中，$y_i^{t}$是向量的正确标签，$N^t$是任务$t$中的实体数量。</p>
<p>如果忽略结点和边的内在依赖关系（Inter-dependencies），我们可以直接通过每个任务的最高分数来预测标签，之后生成局部的最佳图$\hat{G}$。最佳图$\hat{G}$分数的计算方法为：
$$
s'(\hat{G})=\sum_{t\in T}\sum_{i=1}^{N^t}{\max{\hat{y}_i^t}}
$$</p>
<p>其中，$T$是任务的集合，将$s'(\hat{G})$作为$\hat{G}$的局部分数参考。</p>
<h2 id="34-global-features">3.4 Global Features</h2>
<p>我们考虑框架中的两种类型的内部依赖：</p>
<ol>
<li>
<p>子任务间的作用 Cross-subtask interactions</p>
<p>这种依赖关系存在于实体、关系和事件之间；</p>
</li>
<li>
<p>实体之间的作用 Cross-instance interactions</p>
<p>这种依赖存在于一个句子中多个事件和/或关系的实例之间。</p>
</li>
</ol>
<p><img src="http://note.lizhihao999.cn/notes/20201018225648.png" alt="全局特征类型模板（Event schemas）"></p>
<p>我们设计一套全局特征类型模板（Event schemas）来捕捉以上两类相互作用，模型填充所有可能的类型来生成特征，并在训练过程中学习每个特征的权重。对于给定的一张图，我们将它的全局特征向量描述为：
$$
f_G={f_1(G),&hellip;,f_M(G)}
$$
其中，$M$是全局特征的数量，$f_i(\cdot)$是一个函数，对某个特征求值并返回标量。比如：
$$
f_i(G)=\begin{cases}
1,G,has,multiple,ATTCK,events\
0,otherwise
\end{cases}
$$
之后，ONEIE框架学习到一个权重向量$u\in \R^{M}$并且将$f(G)$和$u$的点乘作为图G的全局特征分数。将图G的局部分数和全局特征分数之和作为G的全局分数：
$$
s(G)=s'(G)+{u}{f}(G)
$$
我们假定一条语句的最佳（Gold-standard）图应该拥有最高的全局分数。所以，我们最小化该损失函数：
$$
L^{G}=s(\hat{G})-s(G)
$$
其中，$\hat{G}$是局部分类得到的图，$G$是最佳图。</p>
<p>最终，我们在训练中最优化如下的联合目标函数：
$$
L=L^I+\sum_{t\in{T}}{L^t}+L^{G}
$$</p>
<h2 id="35-decoding">3.5 Decoding</h2>
<p>ONEIE对所有的结点和成对的边进行联合决策，得到全局的最优图。最基本的方法是计算所有候选图的全局分数，选择分数最高的作为最终结果。为了优化复杂度，我们设计了一个以束搜索为基础的解码器（Beam search-based decoder）。</p>
<p><img src="http://note.lizhihao999.cn/notes/20201018225711.png" alt="解码算法示例"></p>
<p>对于给定的识别出的结点集$V$、所有结点的标签分数（label scores）和他们之间的成对联系执行解码，初始束集（initial beam set）为$B={K_{0}}$，$K_0$是一个零阶图。每一步$i$分为两小步，分别对结点和边进行扩展：</p>
<ol>
<li>
<p><strong>Node Step</strong></p>
<p>选择$v_i\in V$，定义候选集为$V_i={&lt;a_i,b_i,l_i^{(k)}&gt;|1\le K\le\beta_v}$，其中$l_i^{(k)}$表示$v_i$中分数第$k$高的局部标签分数，$\beta_v$是控制候选标签数量的超参数（hyper-parameter）。通过如下公式更新束集（beam set）：
$$
B\leftarrow{G+v|(G,v)\in B\times V_i}
$$</p>
</li>
<li>
<p><strong>Edge Step</strong></p>
<p>迭代地选择一个$i$之前的结点$v_j\in V,j&lt;i$，同时在$v_j$和$v_i$之间添加可能的边。如果$v_i$和$v_j$都是触发器（trigger）则跳过$v_j$。每一次迭代中，我们构造一个候选边集$E_{ij}={&lt;j,i,l_{ij}^{(k)}&gt;|1\le k\le \beta_e}$，其中$l_{ij}^{(k)}$是$e_{ij}$中分数第$k$高的标签，$\beta_e$是候选标签数量的阈值。之后，通过如下函数更新束集：
$$
B\leftarrow {G+e|(G,e)\in B\times E_{ij}}
$$
在每次edge step的最后，如果$|B|$超过束的宽度$\theta$，我们对候选对象按全局分数从高到低进行排序，只保留分数最高的$\theta$个。</p>
</li>
</ol>
<p>最后一步之后，返回全局分数最高的图，作为输入语句中提取的信息网络。</p>
<p>$$
u\in \R^{M}
$$</p>

        </div>
        
        <div class="my-4">
    
    <a href="/tags/ner/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#NER</a>
    
    <a href="/tags/acl/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#ACL</a>
    
</div>
        
        
        


        
        
        <div class="py-2">
    
    <div class="flex flex-col md:flex-row items-center my-8">
        <a href="/authors/lizhihao/" class="w-24 h-24 md:mr-4">
            
            
            <img src="/images/avatar.jpg" class="w-full bg-primary-bg rounded-full" alt="Avatar">
            
        </a>
        <div class="w-full md:w-auto mt-4 md:mt-0">
            <a href="/authors/lizhihao/" class="block font-bold text-lg pb-1 mb-2 border-b">Li Zhihao</a>
            <span class="block pb-2"></span>
            
            
            
            
            
            <a href="mailto:lzh821403039@163.com" class="mr-1">
                <i class="fas fa-envelope"></i>
            </a>
            
            
            
            
            
            <a href="https://example.com/" class="mr-1">
                <i class="fab fa-github"></i>
            </a>
            
        </div>
    </div>
    
</div>
        
        
        
<div class="flex flex-col md:flex-row md:justify-between -mx-2 mt-4 px-2 pt-4 border-t">
    <div>
        
        <span class="block font-bold">Previous</span>
        <a href="/posts/mit-6.s081-fall-2019/%E5%AE%9E%E9%AA%8C1%E7%AC%94%E8%AE%B0/" class="block">MIT 6.S081/Fall 2019 Lab1 Xv6 and Unix utilities</a>
        
    </div>
    <div class="md:text-right mt-4 md:mt-0">
        
        <span class="block font-bold">Next</span>
        <a href="/posts/%E8%84%B1%E5%9D%91%E8%AE%B0%E5%BD%95/gunicorn%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/" class="block">Gunicorn基本使用</a>
        
    </div>
</div>

        



    </div>
    
    <div class="col-span-2">
        
        
        <div class="sticky top-16 z-10 hidden lg:block px-6 py-4  bg-primary-bg ">
    <span class="text-lg font-semibold">On This Page</span>
</div>
<div class="sticky-toc hidden lg:block px-6 pb-6 ">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#31-encoding">3.1 Encoding</a></li>
    <li><a href="#32-identification">3.2 Identification</a></li>
    <li><a href="#33-classification">3.3 Classification</a></li>
    <li><a href="#34-global-features">3.4 Global Features</a></li>
    <li><a href="#35-decoding">3.5 Decoding</a></li>
  </ul>
</nav>
</div>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        enableStickyToc();
    });
</script>
        
    </div>
    

    
    
</div>
<script>
    document.addEventListener('DOMContentLoaded', ()=>{
        hljs.initHighlightingOnLoad();
    })
</script>

      </div>
    </div>
    
  </main>
  <footer class="pl-scrollbar">
    <div class="w-full max-w-screen-xl mx-auto"><div class="text-center p-6 pin-b">
    <p class="text-sm text-tertiary-text">&copy; 2021 <a href="https://beian.miit.gov.cn/">粤ICP备19090631号</a>
 &middot;  Powered by the <a href="https://github.com/wangchucheng/hugo-eureka" class="hover:text-eureka">Eureka</a> theme for <a href="https://gohugo.io" class="hover:text-eureka">Hugo</a></p>
</div></div>
  </footer>
</body>

</html>